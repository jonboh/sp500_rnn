{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "import pydot_ng as pydot\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../financial_utils/')\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import performance as per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Compute Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_table = pd.read_csv('history_files/SPY.csv')\n",
    "vol_table = pd.read_csv('history_files/VIX.csv')\n",
    "\n",
    "# Build Tick Table\n",
    "tick_table = price_table[[\"Date\",\"AdjClose\"]]\n",
    "tick_table.columns = [\"Date\", \"Tick\"]\n",
    "# Get Return Table\n",
    "returns = per.tick2ret(tick_table)\n",
    "returns_table = pd.DataFrame({'Date':tick_table.Date[1:], 'Return': returns[:,0]})\n",
    "returns_table = returns_table.set_index('Date')\n",
    "# Drop columns of Vol Table\n",
    "vol_table = vol_table[[\"Date\", \"Close\"]]\n",
    "vol_table.columns = [\"Date\", \"Vol\"]\n",
    "vol_table.Vol = vol_table.Vol/100\n",
    "vol_table = vol_table.set_index('Date')\n",
    "# InnerJoin\n",
    "retvol_table = pd.concat([returns_table,vol_table], join='inner', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T_x = 14\n",
    "n_fields = retvol_table.shape[1]\n",
    "T_y = 5\n",
    "T_stride = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_dataset(T_x, T_y, T_stride, retvol_table):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    return\n",
    "        x E (m, T_x)\n",
    "        y E (m, T_y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = int(np.floor((returns.shape[0] - T_x) / T_stride))\n",
    "    \n",
    "    x = np.nan * np.ones((m, T_x, retvol_table.shape[1]))\n",
    "    y = np.nan * np.ones((m, T_y, retvol_table.shape[1]))\n",
    "    \n",
    "    for i in range(m):\n",
    "        x[i,:,0] = retvol_table.Return[i*T_stride:i*T_stride+T_x].transpose()\n",
    "        x[i,:,1] = retvol_table.Vol[i*T_stride:i*T_stride+T_x].transpose()\n",
    "        y[i,:,0] = retvol_table.Return[i*T_stride:i*T_stride+T_y].transpose()\n",
    "        y[i,:,1] = retvol_table.Vol[i*T_stride:i*T_stride+T_y].transpose()\n",
    "\n",
    "    return x, y, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_data(x, params=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    return \n",
    "        x_norm\n",
    "        x_norm_param = (mean, std)\n",
    "    \"\"\"\n",
    "    if params == None:\n",
    "        mean = np.mean(x, axis=(0,1)) \n",
    "        std = np.std(x, axis=(0,1))\n",
    "    else:\n",
    "        mean = params[0]\n",
    "        std = params[1]\n",
    "    x_norm_param = (mean, std)\n",
    "    x_norm = (x - mean)/std\n",
    "    \n",
    "    return x_norm, x_norm_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denormalize_data(x_norm, x_norm_param):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    mean = x_norm_param[0]\n",
    "    std = x_norm_param[1]\n",
    "    x = x_norm * std + mean\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x, y, m = gen_dataset(T_x,T_y,T_stride,retvol_table)\n",
    "x, x_norm_param = normalize_data(x)\n",
    "y, _ = normalize_data(y, x_norm_param)\n",
    "print('Training Example: '+str(m))\n",
    "print('X Shape: '+str(x.shape))\n",
    "print('Y Shape: '+str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Val / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_end = int(m * 0.7)\n",
    "\n",
    "val_end = train_end + int(0.15 * m)\n",
    "\n",
    "x_train = x[0:train_end]\n",
    "x_val = x[train_end:val_end]\n",
    "x_test = x[val_end:]\n",
    "\n",
    "y_train = y[0:train_end]\n",
    "y_val = y[train_end:val_end]\n",
    "y_test = y[val_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "n_a = 100\n",
    "\n",
    "encoder_LSTM = keras.layers.LSTM(units = n_a, return_state=True)\n",
    "decoder_LSTM = keras.layers.LSTM(units = n_a, return_state=True, return_sequences=True)\n",
    "\n",
    "flatter = keras.layers.Flatten()\n",
    "dense = keras.layers.Dense(units = 100, activation='relu')\n",
    "relu_out = keras.layers.Dense(units = 2, activation='relu')\n",
    "concatenator = keras.layers.Lambda(lambda x: keras.backend.stack(x, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_model(T_x, T_y, n_fields, n_a):\n",
    "    \n",
    "    x_input = keras.layers.Input(shape=(T_x, n_fields))\n",
    "    output_seq = list()\n",
    "    \n",
    "    decoder_outputs, encoder_h, encoder_c = decoder_LSTM(x_input)\n",
    "    decoder_outputs_flat = flatter(decoder_outputs)\n",
    "    out = dense(decoder_outputs_flat)\n",
    "    out = relu_out(out)\n",
    "    print(out.shape)\n",
    "    #decoder_input = keras.layers.Input(shape=(1,n_a))\n",
    "    deco_input = last_slicor(out)\n",
    "    decoder_h = encoder_h\n",
    "    decoder_c = encoder_c\n",
    "    \n",
    "    for _ in range(T_y):\n",
    "        decoder_outputs, decoder_h, decoder_c = decoder_LSTM(deco_input, initial_state=[decoder_h, decoder_c])\n",
    "        decoder_outputs_flat = flatter(decoder_outputs)\n",
    "        out = dense(decoder_outputs_flat)\n",
    "        out = relu_out(out)\n",
    "        \n",
    "        output_seq.append(out)\n",
    "        deco_input = decoder_outputs\n",
    "        \n",
    "    output_seq = concatenator(output_seq)\n",
    "    model = keras.models.Model(inputs=[x_input, decoder_input], outputs=output_seq)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model(T_x, T_y, n_fields, n_a)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optim = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=optim, loss='mse', metrics=['accuracy'])\n",
    "decoder_in = np.zeros((x_train.shape[0],1,n_a))\n",
    "model.fit(x=[x_train,decoder_in], y=y_train, shuffle=True, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoder_in = np.zeros((x_test.shape[0],1,n_a))\n",
    "model.evaluate(x=[x_test,decoder_in], y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "indexes = np.random.randint(0,x_test.shape[0], size=1)\n",
    "x_in = x_test[indexes,:,:]\n",
    "decoder_in = np.zeros((x_in.shape[0],1,n_a))\n",
    "y_true = y_test[indexes,:,:]\n",
    "y_pred = denormalize_data(model.predict(x=[x_in,decoder_in]), x_norm_param)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNIPPETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norm - Denorm Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a, b , m = gen_dataset(T_x,T_y,T_stride,retvol_table)\n",
    "x, x_norm_param = normalize_data(a)\n",
    "y, _ = normalize_data(b, x_norm_param)\n",
    "x = denormalize_data(x, x_norm_param)\n",
    "y = denormalize_data(y, x_norm_param)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist((b-y).flatten(), 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
