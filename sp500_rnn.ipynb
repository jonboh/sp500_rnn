{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "import pydot_ng as pydot\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../financial_utils/')\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import performance as per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Compute Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_table = pd.read_csv('history_files/SPY.csv')\n",
    "vol_table = pd.read_csv('history_files/VIX.csv')\n",
    "\n",
    "# Build Tick Table\n",
    "tick_table = price_table[[\"Date\",\"AdjClose\"]]\n",
    "tick_table.columns = [\"Date\", \"Tick\"]\n",
    "# Get Return Table\n",
    "returns = per.tick2ret(tick_table)\n",
    "returns_table = pd.DataFrame({'Date':tick_table.Date[1:], 'Return': returns[:,0]})\n",
    "returns_table = returns_table.set_index('Date')\n",
    "# Drop columns of Vol Table\n",
    "vol_table = vol_table[[\"Date\", \"Close\"]]\n",
    "vol_table.columns = [\"Date\", \"Vol\"]\n",
    "vol_table.Vol = vol_table.Vol/100\n",
    "vol_table = vol_table.set_index('Date')\n",
    "# InnerJoin\n",
    "retvol_table = pd.concat([returns_table,vol_table], join='inner', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T_x = 5\n",
    "n_fields = 2\n",
    "T_y = 3\n",
    "T_stride = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_dataset(T_x, T_y, n_fields, T_stride, retvol_table):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    return\n",
    "        x E (m, T_x)\n",
    "        y E (m, T_y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = int(np.floor((returns.shape[0] - T_x) / T_stride))\n",
    "    \n",
    "    x = np.nan * np.ones((m-T_y*T_stride, T_x, n_fields))\n",
    "    y = np.nan * np.ones((m-T_y*T_stride, T_y, n_fields))\n",
    "    \n",
    "    for i in range(m-T_y*T_stride):\n",
    "        x[i,:,0] = retvol_table.Return[i*T_stride:i*T_stride+T_x].transpose()\n",
    "        x[i,:,1] = retvol_table.Vol[i*T_stride:i*T_stride+T_x].transpose()\n",
    "        y[i,:,0] = retvol_table.Return[i*T_stride+T_x:i*T_stride+T_x+T_y].transpose()\n",
    "        y[i,:,1] = retvol_table.Vol[i*T_stride+T_x:i*T_stride+T_x+T_y].transpose()\n",
    "\n",
    "    return x, y, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_data(x, params=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    return \n",
    "        x_norm\n",
    "        x_norm_param = (mean, std)\n",
    "    \"\"\"\n",
    "    if params == None:\n",
    "        mean = np.mean(x, axis=(0,1)) \n",
    "        std = np.std(x, axis=(0,1))\n",
    "    else:\n",
    "        mean = params[0]\n",
    "        std = params[1]\n",
    "    x_norm_param = (mean, std)\n",
    "    x_norm = (x - mean)/std\n",
    "    \n",
    "    return x_norm, x_norm_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denormalize_data(x_norm, x_norm_param):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    mean = x_norm_param[0]\n",
    "    std = x_norm_param[1]\n",
    "    x = x_norm * std + mean\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Example: 6090\n",
      "X Shape: (6087, 5, 2)\n",
      "Y Shape: (6087, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "x, y, m = gen_dataset(T_x,T_y, n_fields, T_stride,retvol_table)\n",
    "x, x_norm_param = normalize_data(x)\n",
    "y, _ = normalize_data(y, x_norm_param)\n",
    "print('Training Example: '+str(m))\n",
    "print('X Shape: '+str(x.shape))\n",
    "print('Y Shape: '+str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Val / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_end = int(m * 0.7)\n",
    "\n",
    "val_end = train_end + int(0.15 * m)\n",
    "\n",
    "x_train = x[0:train_end]\n",
    "x_val = x[train_end:val_end]\n",
    "x_test = x[val_end:]\n",
    "\n",
    "y_train = y[0:train_end]\n",
    "y_val = y[train_end:val_end]\n",
    "y_test = y[val_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder- Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "n_a = 100\n",
    "\n",
    "encoder_LSTM = keras.layers.LSTM(units = n_a, return_state=True)\n",
    "decoder_LSTM = keras.layers.LSTM(units = n_a, return_state=True, return_sequences=True)\n",
    "\n",
    "flatter = keras.layers.Flatten()\n",
    "dense = keras.layers.Dense(units = 100, activation='tanh')\n",
    "relu_out = keras.layers.Dense(units = n_fields, activation='tanh')\n",
    "concatenator = keras.layers.Lambda(lambda x: keras.backend.stack(x, axis=1))\n",
    "last_slicor = keras.layers.Lambda(lambda x: x[:,-2:-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_model(T_x, T_y, n_fields, n_a):\n",
    "    \n",
    "    x_input = keras.layers.Input(shape=(T_x, n_fields))\n",
    "    output_seq = list()\n",
    "    \n",
    "    _, encoder_h, encoder_c = encoder_LSTM(x_input)  \n",
    "    \n",
    "    decoder_input = keras.layers.Input(shape=(1,n_a))\n",
    "    deco_input = decoder_input\n",
    "    decoder_h = encoder_h\n",
    "    decoder_c = encoder_c\n",
    "    \n",
    "    for _ in range(T_y):\n",
    "        decoder_outputs, decoder_h, decoder_c = decoder_LSTM(deco_input, initial_state=[decoder_h, decoder_c])\n",
    "        decoder_outputs_flat = flatter(decoder_outputs)\n",
    "        out = dense(decoder_outputs_flat)\n",
    "        out = relu_out(out)\n",
    "        \n",
    "        output_seq.append(out)\n",
    "        deco_input = decoder_outputs\n",
    "        \n",
    "    output_seq = concatenator(output_seq)\n",
    "    model = keras.models.Model(inputs=[x_input, decoder_input], outputs=output_seq)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 5, 2)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 100), (None, 41200       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 1, 100), (No 80400       input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "                                                                 lstm_2[1][0]                     \n",
      "                                                                 lstm_2[1][1]                     \n",
      "                                                                 lstm_2[1][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 100)          0           lstm_2[0][0]                     \n",
      "                                                                 lstm_2[1][0]                     \n",
      "                                                                 lstm_2[2][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          10100       flatten_1[0][0]                  \n",
      "                                                                 flatten_1[1][0]                  \n",
      "                                                                 flatten_1[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            202         dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_1[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 3, 2)         0           dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 131,902\n",
      "Trainable params: 131,902\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model(T_x, T_y, n_fields, n_a)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optim = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=optim, loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4263/4263 [==============================] - 5s 1ms/step - loss: nan - acc: 1.0000\n",
      "Epoch 2/100\n",
      "4263/4263 [==============================] - 1s 338us/step - loss: nan - acc: 1.0000\n",
      "Epoch 3/100\n",
      "4263/4263 [==============================] - 1s 336us/step - loss: nan - acc: 1.0000\n",
      "Epoch 4/100\n",
      "4263/4263 [==============================] - 1s 337us/step - loss: nan - acc: 1.0000\n",
      "Epoch 5/100\n",
      "4263/4263 [==============================] - 1s 338us/step - loss: nan - acc: 1.0000\n",
      "Epoch 6/100\n",
      "4263/4263 [==============================] - 1s 338us/step - loss: nan - acc: 1.0000\n",
      "Epoch 7/100\n",
      "4263/4263 [==============================] - 1s 337us/step - loss: nan - acc: 1.0000\n",
      "Epoch 8/100\n",
      "4263/4263 [==============================] - 1s 346us/step - loss: nan - acc: 1.0000\n",
      "Epoch 9/100\n",
      "4263/4263 [==============================] - 1s 342us/step - loss: nan - acc: 1.0000\n",
      "Epoch 10/100\n",
      "4263/4263 [==============================] - 1s 339us/step - loss: nan - acc: 1.0000\n",
      "Epoch 11/100\n",
      "4263/4263 [==============================] - 1s 338us/step - loss: nan - acc: 1.0000\n",
      "Epoch 12/100\n",
      "4263/4263 [==============================] - 1s 338us/step - loss: nan - acc: 1.0000\n",
      "Epoch 13/100\n",
      "4263/4263 [==============================] - 1s 344us/step - loss: nan - acc: 1.0000\n",
      "Epoch 14/100\n",
      "4263/4263 [==============================] - 1s 351us/step - loss: nan - acc: 1.0000\n",
      "Epoch 15/100\n",
      " 992/4263 [=====>........................] - ETA: 1s - loss: nan - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-d36fcbcac57d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdecoder_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoder_in\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Jon\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\Jon\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Jon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Jon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Jon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "decoder_in = np.zeros((x_train.shape[0],1,n_a))\n",
    "model.fit(x=[x_train,decoder_in], y=y_train, shuffle=True, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 [==============================] - 0s 496us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2564133430683548, 0.8147540988166475]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_in = np.zeros((x_test.shape[0],1,n_a))\n",
    "model.evaluate(x=[x_test,decoder_in], y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[[0.0118108  0.2199    ]\n",
      "  [0.00970978 0.1857    ]]]\n",
      "Y:\n",
      "[[[ 0.01981085  0.1608    ]\n",
      "  [-0.00711086  0.17870001]]]\n",
      "LSTM Out:\n",
      "[[[-0.11139507 -0.07837891]\n",
      "  [-0.0772531  -0.08006877]]]\n",
      "Y pred:\n",
      "[[[-0.00088692  0.19061824]\n",
      "  [-0.00048694  0.19048061]]]\n"
     ]
    }
   ],
   "source": [
    "indexes = np.random.randint(0,x_test.shape[0], size=1)\n",
    "x_in = x_test[indexes,:,:]\n",
    "decoder_in = np.zeros((x_in.shape[0],1,n_a))\n",
    "y_true = y_test[indexes,:,:]\n",
    "y_pred = model.predict(x=[x_in,decoder_in])\n",
    "y_pred_denorm = denormalize_data(y_pred, x_norm_param)\n",
    "print('X:')\n",
    "print(denormalize_data(x_in,x_norm_param))\n",
    "print('Y:')\n",
    "print(denormalize_data(y_true,x_norm_param))\n",
    "print('LSTM Out:')\n",
    "print(y_pred)\n",
    "print('Y pred:')\n",
    "print(y_pred_denorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.19700148]), array([0.0814408]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNIPPETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norm - Denorm Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a, b , m = gen_dataset(T_x,T_y,T_stride,retvol_table)\n",
    "x, x_norm_param = normalize_data(a)\n",
    "y, _ = normalize_data(b, x_norm_param)\n",
    "x = denormalize_data(x, x_norm_param)\n",
    "y = denormalize_data(y, x_norm_param)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist((b-y).flatten(), 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
