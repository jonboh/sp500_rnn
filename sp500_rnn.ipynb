{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jon\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "import pydot_ng as pydot\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../financial_utils/')\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import performance as per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Compute Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_table = pd.read_csv('history_files/^GSPC.csv')\n",
    "vol_table = pd.read_csv('history_files/VIX.csv')\n",
    "\n",
    "# Build Tick Table\n",
    "tick_table = price_table[[\"Date\",\"Close\"]]\n",
    "tick_table.columns = [\"Date\", \"Tick\"]\n",
    "# Get Return Table\n",
    "returns = per.tick2ret(tick_table)\n",
    "returns_table = pd.DataFrame({'Date':tick_table.Date[1:], 'Return': returns[:,0]})\n",
    "returns_table = returns_table.set_index('Date')\n",
    "# Drop columns of Vol Table\n",
    "vol_table = vol_table[[\"Date\", \"Close\"]]\n",
    "vol_table.columns = [\"Date\", \"Vol\"]\n",
    "vol_table.Vol = vol_table.Vol/100\n",
    "vol_table = vol_table.set_index('Date')\n",
    "# InnerJoin\n",
    "retvol_table = pd.concat([returns_table,vol_table], join='inner', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T_x = 10\n",
    "n_fields = 2\n",
    "T_y = 3\n",
    "T_stride = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_dataset(T_x, T_y, n_fields, T_stride, retvol_table):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    return\n",
    "        x E (m, T_x)\n",
    "        y E (m, T_y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = int(np.floor((returns.shape[0] - T_x) / T_stride))\n",
    "    \n",
    "    x = np.nan * np.ones((m-T_y*T_stride, T_x, n_fields))\n",
    "    y = np.nan * np.ones((m-T_y*T_stride, T_y, n_fields))\n",
    "    \n",
    "    for i in range(m-T_y*T_stride):\n",
    "        x[i,:,0] = retvol_table.Return[i*T_stride:i*T_stride+T_x].transpose()\n",
    "        x[i,:,1] = retvol_table.Vol[i*T_stride:i*T_stride+T_x].transpose()\n",
    "        y[i,:,0] = retvol_table.Return[i*T_stride+T_x:i*T_stride+T_x+T_y].transpose()\n",
    "        y[i,:,1] = retvol_table.Vol[i*T_stride+T_x:i*T_stride+T_x+T_y].transpose()\n",
    "\n",
    "    return x, y, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_data(x, params=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    return \n",
    "        x_norm\n",
    "        x_norm_param = (mean, std)\n",
    "    \"\"\"\n",
    "    if params == None:\n",
    "        mean = np.mean(x, axis=(0,1)) \n",
    "        std = np.std(x, axis=(0,1))\n",
    "    else:\n",
    "        mean = params[0]\n",
    "        std = params[1]\n",
    "    x_norm_param = (mean, std)\n",
    "    x_norm = (x - mean)/std\n",
    "    \n",
    "    return x_norm, x_norm_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denormalize_data(x_norm, x_norm_param):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    mean = x_norm_param[0]\n",
    "    std = x_norm_param[1]\n",
    "    x = x_norm * std + mean\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Example: 6085\n",
      "X Shape: (6082, 10, 2)\n",
      "Y Shape: (6082, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "x, y, m = gen_dataset(T_x,T_y, n_fields, T_stride,retvol_table)\n",
    "x, x_norm_param = normalize_data(x)\n",
    "y, _ = normalize_data(y, x_norm_param)\n",
    "print('Training Example: '+str(m))\n",
    "print('X Shape: '+str(x.shape))\n",
    "print('Y Shape: '+str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Val / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = shuffle(x,y)\n",
    "\n",
    "train_end = int(m * 0.7)\n",
    "\n",
    "val_end = train_end + int(0.15 * m)\n",
    "\n",
    "x_train = x[0:train_end]\n",
    "x_val = x[train_end:val_end]\n",
    "x_test = x[val_end:]\n",
    "\n",
    "y_train = y[0:train_end]\n",
    "y_val = y[train_end:val_end]\n",
    "y_test = y[val_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder- Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "n_a = 100\n",
    "\n",
    "encoder_LSTM = keras.layers.LSTM(units = n_a, return_state=True)\n",
    "decoder_LSTM = keras.layers.LSTM(units = n_a, return_state=True, return_sequences=True)\n",
    "\n",
    "flatter = keras.layers.Flatten()\n",
    "dense = keras.layers.Dense(units = 100, activation='tanh')\n",
    "relu_out = keras.layers.Dense(units = n_fields, activation='tanh')\n",
    "concatenator = keras.layers.Lambda(lambda x: keras.backend.stack(x, axis=1))\n",
    "last_slicor = keras.layers.Lambda(lambda x: x[:,-2:-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_model(T_x, T_y, n_fields, n_a):\n",
    "    \n",
    "    x_input = keras.layers.Input(shape=(T_x, n_fields))\n",
    "    output_seq = list()\n",
    "    \n",
    "    _, encoder_h, encoder_c = encoder_LSTM(x_input)  \n",
    "    \n",
    "    decoder_input = keras.layers.Input(shape=(1,n_a))\n",
    "    deco_input = decoder_input\n",
    "    decoder_h = encoder_h\n",
    "    decoder_c = encoder_c\n",
    "    \n",
    "    for _ in range(T_y):\n",
    "        decoder_outputs, decoder_h, decoder_c = decoder_LSTM(deco_input, initial_state=[decoder_h, decoder_c])\n",
    "        decoder_outputs_flat = flatter(decoder_outputs)\n",
    "        out = dense(decoder_outputs_flat)\n",
    "        out = relu_out(out)\n",
    "        \n",
    "        output_seq.append(out)\n",
    "        deco_input = decoder_outputs\n",
    "        \n",
    "    output_seq = concatenator(output_seq)\n",
    "    model = keras.models.Model(inputs=[x_input, decoder_input], outputs=output_seq)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 10, 2)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 100), (None, 41200       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 1, 100), (No 80400       input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "                                                                 lstm_2[1][0]                     \n",
      "                                                                 lstm_2[1][1]                     \n",
      "                                                                 lstm_2[1][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 100)          0           lstm_2[0][0]                     \n",
      "                                                                 lstm_2[1][0]                     \n",
      "                                                                 lstm_2[2][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          10100       flatten_1[0][0]                  \n",
      "                                                                 flatten_1[1][0]                  \n",
      "                                                                 flatten_1[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            202         dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_1[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 3, 2)         0           dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 131,902\n",
      "Trainable params: 131,902\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model(T_x, T_y, n_fields, n_a)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optim = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=optim, loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4259 samples, validate on 912 samples\n",
      "Epoch 1/10000\n",
      "4259/4259 [==============================] - 6s 1ms/step - loss: 0.6921 - acc: 0.7567 - val_loss: 0.6104 - val_acc: 0.7664\n",
      "Epoch 2/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.6833 - acc: 0.7557 - val_loss: 0.6102 - val_acc: 0.7675\n",
      "Epoch 3/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.6818 - acc: 0.7573 - val_loss: 0.6088 - val_acc: 0.7635\n",
      "Epoch 4/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.6812 - acc: 0.7567 - val_loss: 0.6117 - val_acc: 0.7632\n",
      "Epoch 5/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.6819 - acc: 0.7575 - val_loss: 0.6086 - val_acc: 0.7661\n",
      "Epoch 6/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.6780 - acc: 0.7583 - val_loss: 0.6098 - val_acc: 0.7628\n",
      "Epoch 7/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.6777 - acc: 0.7593 - val_loss: 0.6088 - val_acc: 0.7617\n",
      "Epoch 8/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.6785 - acc: 0.7571 - val_loss: 0.6099 - val_acc: 0.7635\n",
      "Epoch 9/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.6764 - acc: 0.7571 - val_loss: 0.6115 - val_acc: 0.7664\n",
      "Epoch 10/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.6748 - acc: 0.7574 - val_loss: 0.6084 - val_acc: 0.7672\n",
      "Epoch 11/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.6767 - acc: 0.7579 - val_loss: 0.6128 - val_acc: 0.7624\n",
      "Epoch 12/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.6738 - acc: 0.7567 - val_loss: 0.6112 - val_acc: 0.7654\n",
      "Epoch 13/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.6761 - acc: 0.7583 - val_loss: 0.6119 - val_acc: 0.7657\n",
      "Epoch 14/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.6733 - acc: 0.7557 - val_loss: 0.6100 - val_acc: 0.7646\n",
      "Epoch 15/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.6709 - acc: 0.7582 - val_loss: 0.6147 - val_acc: 0.7643\n",
      "Epoch 16/10000\n",
      "4259/4259 [==============================] - 2s 499us/step - loss: 0.6710 - acc: 0.7578 - val_loss: 0.6106 - val_acc: 0.7621\n",
      "Epoch 17/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.6685 - acc: 0.7586 - val_loss: 0.6194 - val_acc: 0.7657\n",
      "Epoch 18/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.6669 - acc: 0.7587 - val_loss: 0.6194 - val_acc: 0.7650\n",
      "Epoch 19/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.6670 - acc: 0.7589 - val_loss: 0.6144 - val_acc: 0.7632\n",
      "Epoch 20/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.6618 - acc: 0.7582 - val_loss: 0.6107 - val_acc: 0.7635\n",
      "Epoch 21/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.6613 - acc: 0.7588 - val_loss: 0.6158 - val_acc: 0.7654\n",
      "Epoch 22/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.6588 - acc: 0.7590 - val_loss: 0.6123 - val_acc: 0.7632\n",
      "Epoch 23/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.6575 - acc: 0.7588 - val_loss: 0.6136 - val_acc: 0.7580\n",
      "Epoch 24/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.6571 - acc: 0.7604 - val_loss: 0.6133 - val_acc: 0.7632\n",
      "Epoch 25/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.6532 - acc: 0.7570 - val_loss: 0.6149 - val_acc: 0.7661\n",
      "Epoch 26/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.6510 - acc: 0.7573 - val_loss: 0.6137 - val_acc: 0.7643\n",
      "Epoch 27/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.6509 - acc: 0.7578 - val_loss: 0.6058 - val_acc: 0.7668\n",
      "Epoch 28/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.6457 - acc: 0.7593 - val_loss: 0.6250 - val_acc: 0.7668\n",
      "Epoch 29/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.6450 - acc: 0.7579 - val_loss: 0.6086 - val_acc: 0.7628\n",
      "Epoch 30/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.6439 - acc: 0.7582 - val_loss: 0.6053 - val_acc: 0.7668\n",
      "Epoch 31/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.6422 - acc: 0.7588 - val_loss: 0.6137 - val_acc: 0.7657\n",
      "Epoch 32/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.6380 - acc: 0.7582 - val_loss: 0.6094 - val_acc: 0.7595\n",
      "Epoch 33/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.6370 - acc: 0.7563 - val_loss: 0.6084 - val_acc: 0.7635\n",
      "Epoch 34/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.6382 - acc: 0.7567 - val_loss: 0.6105 - val_acc: 0.7610\n",
      "Epoch 35/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.6317 - acc: 0.7564 - val_loss: 0.6067 - val_acc: 0.7639\n",
      "Epoch 36/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.6276 - acc: 0.7586 - val_loss: 0.6110 - val_acc: 0.7617\n",
      "Epoch 37/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.6278 - acc: 0.7580 - val_loss: 0.6070 - val_acc: 0.7507\n",
      "Epoch 38/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.6243 - acc: 0.7570 - val_loss: 0.6066 - val_acc: 0.7610\n",
      "Epoch 39/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.6194 - acc: 0.7578 - val_loss: 0.6054 - val_acc: 0.7635\n",
      "Epoch 40/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.6149 - acc: 0.7584 - val_loss: 0.6110 - val_acc: 0.7632\n",
      "Epoch 41/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.6146 - acc: 0.7590 - val_loss: 0.5994 - val_acc: 0.7613\n",
      "Epoch 42/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.6103 - acc: 0.7584 - val_loss: 0.6016 - val_acc: 0.7639\n",
      "Epoch 43/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.6073 - acc: 0.7593 - val_loss: 0.6082 - val_acc: 0.7654\n",
      "Epoch 44/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.6064 - acc: 0.7587 - val_loss: 0.6090 - val_acc: 0.7577\n",
      "Epoch 45/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.6017 - acc: 0.7578 - val_loss: 0.6133 - val_acc: 0.7650\n",
      "Epoch 46/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.5932 - acc: 0.7593 - val_loss: 0.6105 - val_acc: 0.7639\n",
      "Epoch 47/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.5936 - acc: 0.7567 - val_loss: 0.6159 - val_acc: 0.7606\n",
      "Epoch 48/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.5890 - acc: 0.7606 - val_loss: 0.6095 - val_acc: 0.7624\n",
      "Epoch 49/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.5850 - acc: 0.7589 - val_loss: 0.6193 - val_acc: 0.7610\n",
      "Epoch 50/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.5806 - acc: 0.7601 - val_loss: 0.6036 - val_acc: 0.7664\n",
      "Epoch 51/10000\n",
      "4259/4259 [==============================] - 2s 504us/step - loss: 0.5777 - acc: 0.7601 - val_loss: 0.6126 - val_acc: 0.7544\n",
      "Epoch 52/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.5710 - acc: 0.7597 - val_loss: 0.6046 - val_acc: 0.7635\n",
      "Epoch 53/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.5683 - acc: 0.7591 - val_loss: 0.6128 - val_acc: 0.7602\n",
      "Epoch 54/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.5649 - acc: 0.7608 - val_loss: 0.6086 - val_acc: 0.7606\n",
      "Epoch 55/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.5744 - acc: 0.7618 - val_loss: 0.6110 - val_acc: 0.7628\n",
      "Epoch 56/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.5594 - acc: 0.7622 - val_loss: 0.6094 - val_acc: 0.7551\n",
      "Epoch 57/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.5577 - acc: 0.7629 - val_loss: 0.6160 - val_acc: 0.7610\n",
      "Epoch 58/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.5566 - acc: 0.7630 - val_loss: 0.6097 - val_acc: 0.7569\n",
      "Epoch 59/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.5522 - acc: 0.7660 - val_loss: 0.6059 - val_acc: 0.7606\n",
      "Epoch 60/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.5512 - acc: 0.7661 - val_loss: 0.6105 - val_acc: 0.7540\n",
      "Epoch 61/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.5499 - acc: 0.7684 - val_loss: 0.6136 - val_acc: 0.7624\n",
      "Epoch 62/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.5461 - acc: 0.7683 - val_loss: 0.6098 - val_acc: 0.7588\n",
      "Epoch 63/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.5424 - acc: 0.7710 - val_loss: 0.6085 - val_acc: 0.7507\n",
      "Epoch 64/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.5388 - acc: 0.7707 - val_loss: 0.6279 - val_acc: 0.7544\n",
      "Epoch 65/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.5426 - acc: 0.7719 - val_loss: 0.6238 - val_acc: 0.7522\n",
      "Epoch 66/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.5461 - acc: 0.7713 - val_loss: 0.6278 - val_acc: 0.7471\n",
      "Epoch 67/10000\n",
      "4259/4259 [==============================] - 2s 499us/step - loss: 0.5394 - acc: 0.7707 - val_loss: 0.6252 - val_acc: 0.7500\n",
      "Epoch 68/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.5337 - acc: 0.7740 - val_loss: 0.6269 - val_acc: 0.7507\n",
      "Epoch 69/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.5285 - acc: 0.7766 - val_loss: 0.6275 - val_acc: 0.7515\n",
      "Epoch 70/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.5269 - acc: 0.7762 - val_loss: 0.6305 - val_acc: 0.7529\n",
      "Epoch 71/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.5240 - acc: 0.7776 - val_loss: 0.6391 - val_acc: 0.7445\n",
      "Epoch 72/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.5225 - acc: 0.7792 - val_loss: 0.6321 - val_acc: 0.7507\n",
      "Epoch 73/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.5162 - acc: 0.7812 - val_loss: 0.6356 - val_acc: 0.7526\n",
      "Epoch 74/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.5170 - acc: 0.7848 - val_loss: 0.6198 - val_acc: 0.7515\n",
      "Epoch 75/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.5142 - acc: 0.7852 - val_loss: 0.6338 - val_acc: 0.7489\n",
      "Epoch 76/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.5095 - acc: 0.7833 - val_loss: 0.6289 - val_acc: 0.7467\n",
      "Epoch 77/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.5122 - acc: 0.7851 - val_loss: 0.6297 - val_acc: 0.7493\n",
      "Epoch 78/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.5058 - acc: 0.7877 - val_loss: 0.6282 - val_acc: 0.7518\n",
      "Epoch 79/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.5043 - acc: 0.7882 - val_loss: 0.6298 - val_acc: 0.7442\n",
      "Epoch 80/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.4995 - acc: 0.7927 - val_loss: 0.6323 - val_acc: 0.7485\n",
      "Epoch 81/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.4980 - acc: 0.7935 - val_loss: 0.6285 - val_acc: 0.7478\n",
      "Epoch 82/10000\n",
      "4259/4259 [==============================] - 2s 501us/step - loss: 0.5073 - acc: 0.7903 - val_loss: 0.6325 - val_acc: 0.7496\n",
      "Epoch 83/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.5015 - acc: 0.7940 - val_loss: 0.6346 - val_acc: 0.7485\n",
      "Epoch 84/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.4971 - acc: 0.7951 - val_loss: 0.6351 - val_acc: 0.7474\n",
      "Epoch 85/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.4904 - acc: 0.8031 - val_loss: 0.6326 - val_acc: 0.7522\n",
      "Epoch 86/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.4869 - acc: 0.8016 - val_loss: 0.6306 - val_acc: 0.7526\n",
      "Epoch 87/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.4836 - acc: 0.8077 - val_loss: 0.6391 - val_acc: 0.7463\n",
      "Epoch 88/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.4823 - acc: 0.8068 - val_loss: 0.6335 - val_acc: 0.7445\n",
      "Epoch 89/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.4805 - acc: 0.8079 - val_loss: 0.6309 - val_acc: 0.7511\n",
      "Epoch 90/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.4769 - acc: 0.8104 - val_loss: 0.6420 - val_acc: 0.7442\n",
      "Epoch 91/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.4753 - acc: 0.8125 - val_loss: 0.6413 - val_acc: 0.7489\n",
      "Epoch 92/10000\n",
      "4259/4259 [==============================] - 2s 502us/step - loss: 0.4727 - acc: 0.8163 - val_loss: 0.6476 - val_acc: 0.7401\n",
      "Epoch 93/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.4715 - acc: 0.8165 - val_loss: 0.6453 - val_acc: 0.7445\n",
      "Epoch 94/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.4741 - acc: 0.8140 - val_loss: 0.6479 - val_acc: 0.7511\n",
      "Epoch 95/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.4662 - acc: 0.8190 - val_loss: 0.6513 - val_acc: 0.7460\n",
      "Epoch 96/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.4689 - acc: 0.8196 - val_loss: 0.6511 - val_acc: 0.7394\n",
      "Epoch 97/10000\n",
      "4259/4259 [==============================] - 2s 499us/step - loss: 0.4636 - acc: 0.8220 - val_loss: 0.6499 - val_acc: 0.7463\n",
      "Epoch 98/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.4599 - acc: 0.8258 - val_loss: 0.6471 - val_acc: 0.7482\n",
      "Epoch 99/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.4568 - acc: 0.8276 - val_loss: 0.6487 - val_acc: 0.7485\n",
      "Epoch 100/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.4560 - acc: 0.8263 - val_loss: 0.6525 - val_acc: 0.7526\n",
      "Epoch 101/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.4587 - acc: 0.8280 - val_loss: 0.6544 - val_acc: 0.7449\n",
      "Epoch 102/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.4524 - acc: 0.8312 - val_loss: 0.6547 - val_acc: 0.7463\n",
      "Epoch 103/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.4519 - acc: 0.8328 - val_loss: 0.6540 - val_acc: 0.7537\n",
      "Epoch 104/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.4521 - acc: 0.8332 - val_loss: 0.6564 - val_acc: 0.7493\n",
      "Epoch 105/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.4452 - acc: 0.8370 - val_loss: 0.6586 - val_acc: 0.7449\n",
      "Epoch 106/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.4421 - acc: 0.8414 - val_loss: 0.6552 - val_acc: 0.7376\n",
      "Epoch 107/10000\n",
      "4259/4259 [==============================] - 2s 503us/step - loss: 0.4390 - acc: 0.8435 - val_loss: 0.6617 - val_acc: 0.7442\n",
      "Epoch 108/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.4383 - acc: 0.8427 - val_loss: 0.6622 - val_acc: 0.7460\n",
      "Epoch 109/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.4362 - acc: 0.8457 - val_loss: 0.6571 - val_acc: 0.7474\n",
      "Epoch 110/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.4355 - acc: 0.8499 - val_loss: 0.6670 - val_acc: 0.7471\n",
      "Epoch 111/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.4346 - acc: 0.8504 - val_loss: 0.6675 - val_acc: 0.7398\n",
      "Epoch 112/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.4330 - acc: 0.8477 - val_loss: 0.6650 - val_acc: 0.7471\n",
      "Epoch 113/10000\n",
      "4259/4259 [==============================] - 2s 516us/step - loss: 0.4278 - acc: 0.8515 - val_loss: 0.6710 - val_acc: 0.7420\n",
      "Epoch 114/10000\n",
      "4259/4259 [==============================] - 2s 507us/step - loss: 0.4258 - acc: 0.8550 - val_loss: 0.6670 - val_acc: 0.7427\n",
      "Epoch 115/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.4242 - acc: 0.8583 - val_loss: 0.6726 - val_acc: 0.7394\n",
      "Epoch 116/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.4230 - acc: 0.8568 - val_loss: 0.6738 - val_acc: 0.7463\n",
      "Epoch 117/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.4275 - acc: 0.8569 - val_loss: 0.6819 - val_acc: 0.7383\n",
      "Epoch 118/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.4200 - acc: 0.8614 - val_loss: 0.6725 - val_acc: 0.7438\n",
      "Epoch 119/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.4177 - acc: 0.8601 - val_loss: 0.6767 - val_acc: 0.7423\n",
      "Epoch 120/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.4163 - acc: 0.8644 - val_loss: 0.6796 - val_acc: 0.7471\n",
      "Epoch 121/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.4139 - acc: 0.8672 - val_loss: 0.6677 - val_acc: 0.7361\n",
      "Epoch 122/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.4117 - acc: 0.8693 - val_loss: 0.6871 - val_acc: 0.7361\n",
      "Epoch 123/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.4100 - acc: 0.8716 - val_loss: 0.6853 - val_acc: 0.7350\n",
      "Epoch 124/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.4099 - acc: 0.8701 - val_loss: 0.6784 - val_acc: 0.7336\n",
      "Epoch 125/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.4076 - acc: 0.8692 - val_loss: 0.6841 - val_acc: 0.7365\n",
      "Epoch 126/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.4070 - acc: 0.8732 - val_loss: 0.6821 - val_acc: 0.7383\n",
      "Epoch 127/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.4054 - acc: 0.8771 - val_loss: 0.6864 - val_acc: 0.7390\n",
      "Epoch 128/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.4031 - acc: 0.8752 - val_loss: 0.6863 - val_acc: 0.7401\n",
      "Epoch 129/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.4019 - acc: 0.8787 - val_loss: 0.6784 - val_acc: 0.7357\n",
      "Epoch 130/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.4003 - acc: 0.8805 - val_loss: 0.6854 - val_acc: 0.7438\n",
      "Epoch 131/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3988 - acc: 0.8829 - val_loss: 0.6865 - val_acc: 0.7317\n",
      "Epoch 132/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3965 - acc: 0.8831 - val_loss: 0.6908 - val_acc: 0.7303\n",
      "Epoch 133/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3972 - acc: 0.8795 - val_loss: 0.6864 - val_acc: 0.7350\n",
      "Epoch 134/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3954 - acc: 0.8804 - val_loss: 0.6908 - val_acc: 0.7321\n",
      "Epoch 135/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3930 - acc: 0.8835 - val_loss: 0.6900 - val_acc: 0.7317\n",
      "Epoch 136/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3913 - acc: 0.8861 - val_loss: 0.6849 - val_acc: 0.7365\n",
      "Epoch 137/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3926 - acc: 0.8829 - val_loss: 0.6875 - val_acc: 0.7321\n",
      "Epoch 138/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3911 - acc: 0.8862 - val_loss: 0.6906 - val_acc: 0.7354\n",
      "Epoch 139/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3881 - acc: 0.8884 - val_loss: 0.6872 - val_acc: 0.7346\n",
      "Epoch 140/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3869 - acc: 0.8913 - val_loss: 0.6946 - val_acc: 0.7317\n",
      "Epoch 141/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3866 - acc: 0.8914 - val_loss: 0.6989 - val_acc: 0.7251\n",
      "Epoch 142/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3867 - acc: 0.8889 - val_loss: 0.6999 - val_acc: 0.7314\n",
      "Epoch 143/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3832 - acc: 0.8938 - val_loss: 0.6971 - val_acc: 0.7346\n",
      "Epoch 144/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3861 - acc: 0.8900 - val_loss: 0.6879 - val_acc: 0.7317\n",
      "Epoch 145/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3813 - acc: 0.8924 - val_loss: 0.6939 - val_acc: 0.7284\n",
      "Epoch 146/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3811 - acc: 0.8947 - val_loss: 0.6999 - val_acc: 0.7222\n",
      "Epoch 147/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3782 - acc: 0.9007 - val_loss: 0.6954 - val_acc: 0.7200\n",
      "Epoch 148/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3778 - acc: 0.8993 - val_loss: 0.7022 - val_acc: 0.7295\n",
      "Epoch 149/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3758 - acc: 0.8996 - val_loss: 0.7013 - val_acc: 0.7233\n",
      "Epoch 150/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3746 - acc: 0.9008 - val_loss: 0.7045 - val_acc: 0.7222\n",
      "Epoch 151/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3744 - acc: 0.9010 - val_loss: 0.7003 - val_acc: 0.7186\n",
      "Epoch 152/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3727 - acc: 0.9044 - val_loss: 0.6977 - val_acc: 0.7219\n",
      "Epoch 153/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3729 - acc: 0.9008 - val_loss: 0.6999 - val_acc: 0.7332\n",
      "Epoch 154/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3727 - acc: 0.9020 - val_loss: 0.7050 - val_acc: 0.7288\n",
      "Epoch 155/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3708 - acc: 0.9051 - val_loss: 0.7029 - val_acc: 0.7255\n",
      "Epoch 156/10000\n",
      "4259/4259 [==============================] - 2s 501us/step - loss: 0.3696 - acc: 0.9068 - val_loss: 0.7047 - val_acc: 0.7200\n",
      "Epoch 157/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3705 - acc: 0.9013 - val_loss: 0.7056 - val_acc: 0.7255\n",
      "Epoch 158/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3681 - acc: 0.9090 - val_loss: 0.7212 - val_acc: 0.7292\n",
      "Epoch 159/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3662 - acc: 0.9088 - val_loss: 0.7115 - val_acc: 0.7153\n",
      "Epoch 160/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3665 - acc: 0.9098 - val_loss: 0.7180 - val_acc: 0.7233\n",
      "Epoch 161/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3646 - acc: 0.9116 - val_loss: 0.7135 - val_acc: 0.7171\n",
      "Epoch 162/10000\n",
      "4259/4259 [==============================] - 2s 504us/step - loss: 0.3636 - acc: 0.9103 - val_loss: 0.7116 - val_acc: 0.7325\n",
      "Epoch 163/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3631 - acc: 0.9094 - val_loss: 0.7153 - val_acc: 0.7219\n",
      "Epoch 164/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3597 - acc: 0.9160 - val_loss: 0.7177 - val_acc: 0.7295\n",
      "Epoch 165/10000\n",
      "4259/4259 [==============================] - 2s 535us/step - loss: 0.3588 - acc: 0.9135 - val_loss: 0.7205 - val_acc: 0.7273\n",
      "Epoch 166/10000\n",
      "4259/4259 [==============================] - 2s 505us/step - loss: 0.3587 - acc: 0.9128 - val_loss: 0.7124 - val_acc: 0.7240\n",
      "Epoch 167/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3582 - acc: 0.9192 - val_loss: 0.7160 - val_acc: 0.7171\n",
      "Epoch 168/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3568 - acc: 0.9159 - val_loss: 0.7212 - val_acc: 0.7156\n",
      "Epoch 169/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3546 - acc: 0.9191 - val_loss: 0.7202 - val_acc: 0.7153\n",
      "Epoch 170/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3542 - acc: 0.9215 - val_loss: 0.7172 - val_acc: 0.7145\n",
      "Epoch 171/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3545 - acc: 0.9181 - val_loss: 0.7171 - val_acc: 0.7226\n",
      "Epoch 172/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3534 - acc: 0.9196 - val_loss: 0.7218 - val_acc: 0.7145\n",
      "Epoch 173/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3526 - acc: 0.9194 - val_loss: 0.7174 - val_acc: 0.7292\n",
      "Epoch 174/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3519 - acc: 0.9209 - val_loss: 0.7247 - val_acc: 0.7149\n",
      "Epoch 175/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3502 - acc: 0.9213 - val_loss: 0.7188 - val_acc: 0.7193\n",
      "Epoch 176/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.3493 - acc: 0.9249 - val_loss: 0.7240 - val_acc: 0.7186\n",
      "Epoch 177/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3496 - acc: 0.9228 - val_loss: 0.7213 - val_acc: 0.7175\n",
      "Epoch 178/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3478 - acc: 0.9258 - val_loss: 0.7200 - val_acc: 0.7164\n",
      "Epoch 179/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3477 - acc: 0.9231 - val_loss: 0.7279 - val_acc: 0.7080\n",
      "Epoch 180/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3470 - acc: 0.9228 - val_loss: 0.7205 - val_acc: 0.7127\n",
      "Epoch 181/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3453 - acc: 0.9309 - val_loss: 0.7288 - val_acc: 0.7083\n",
      "Epoch 182/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3478 - acc: 0.9210 - val_loss: 0.7243 - val_acc: 0.7189\n",
      "Epoch 183/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3456 - acc: 0.9254 - val_loss: 0.7221 - val_acc: 0.7124\n",
      "Epoch 184/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3463 - acc: 0.9279 - val_loss: 0.7245 - val_acc: 0.7113\n",
      "Epoch 185/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3439 - acc: 0.9308 - val_loss: 0.7283 - val_acc: 0.7175\n",
      "Epoch 186/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3420 - acc: 0.9315 - val_loss: 0.7265 - val_acc: 0.7208\n",
      "Epoch 187/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3415 - acc: 0.9317 - val_loss: 0.7253 - val_acc: 0.7182\n",
      "Epoch 188/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3408 - acc: 0.9289 - val_loss: 0.7280 - val_acc: 0.7149\n",
      "Epoch 189/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3399 - acc: 0.9328 - val_loss: 0.7256 - val_acc: 0.7113\n",
      "Epoch 190/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3391 - acc: 0.9325 - val_loss: 0.7289 - val_acc: 0.7113\n",
      "Epoch 191/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3385 - acc: 0.9322 - val_loss: 0.7307 - val_acc: 0.7131\n",
      "Epoch 192/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3392 - acc: 0.9324 - val_loss: 0.7326 - val_acc: 0.7076\n",
      "Epoch 193/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3381 - acc: 0.9312 - val_loss: 0.7265 - val_acc: 0.7182\n",
      "Epoch 194/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3374 - acc: 0.9357 - val_loss: 0.7291 - val_acc: 0.7124\n",
      "Epoch 195/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3378 - acc: 0.9348 - val_loss: 0.7286 - val_acc: 0.7080\n",
      "Epoch 196/10000\n",
      "4259/4259 [==============================] - 2s 499us/step - loss: 0.3364 - acc: 0.9350 - val_loss: 0.7337 - val_acc: 0.7109\n",
      "Epoch 197/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3359 - acc: 0.9376 - val_loss: 0.7362 - val_acc: 0.7094\n",
      "Epoch 198/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3395 - acc: 0.9312 - val_loss: 0.7298 - val_acc: 0.7145\n",
      "Epoch 199/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3364 - acc: 0.9351 - val_loss: 0.7319 - val_acc: 0.7120\n",
      "Epoch 200/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3341 - acc: 0.9375 - val_loss: 0.7273 - val_acc: 0.7124\n",
      "Epoch 201/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3335 - acc: 0.9375 - val_loss: 0.7364 - val_acc: 0.7113\n",
      "Epoch 202/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.3335 - acc: 0.9382 - val_loss: 0.7360 - val_acc: 0.7120\n",
      "Epoch 203/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3331 - acc: 0.9386 - val_loss: 0.7330 - val_acc: 0.7094\n",
      "Epoch 204/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3325 - acc: 0.9382 - val_loss: 0.7342 - val_acc: 0.7124\n",
      "Epoch 205/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3319 - acc: 0.9395 - val_loss: 0.7336 - val_acc: 0.7021\n",
      "Epoch 206/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3313 - acc: 0.9396 - val_loss: 0.7374 - val_acc: 0.7072\n",
      "Epoch 207/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3307 - acc: 0.9399 - val_loss: 0.7312 - val_acc: 0.7175\n",
      "Epoch 208/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3308 - acc: 0.9393 - val_loss: 0.7340 - val_acc: 0.7142\n",
      "Epoch 209/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3307 - acc: 0.9400 - val_loss: 0.7305 - val_acc: 0.7091\n",
      "Epoch 210/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3301 - acc: 0.9408 - val_loss: 0.7343 - val_acc: 0.7142\n",
      "Epoch 211/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3302 - acc: 0.9413 - val_loss: 0.7367 - val_acc: 0.7127\n",
      "Epoch 212/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3284 - acc: 0.9418 - val_loss: 0.7324 - val_acc: 0.7124\n",
      "Epoch 213/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3285 - acc: 0.9426 - val_loss: 0.7374 - val_acc: 0.7124\n",
      "Epoch 214/10000\n",
      "4259/4259 [==============================] - 2s 499us/step - loss: 0.3287 - acc: 0.9412 - val_loss: 0.7325 - val_acc: 0.7039\n",
      "Epoch 215/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3284 - acc: 0.9447 - val_loss: 0.7362 - val_acc: 0.7036\n",
      "Epoch 216/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3277 - acc: 0.9403 - val_loss: 0.7357 - val_acc: 0.7072\n",
      "Epoch 217/10000\n",
      "4259/4259 [==============================] - 2s 499us/step - loss: 0.3270 - acc: 0.9450 - val_loss: 0.7337 - val_acc: 0.7058\n",
      "Epoch 218/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3264 - acc: 0.9453 - val_loss: 0.7373 - val_acc: 0.7102\n",
      "Epoch 219/10000\n",
      "4259/4259 [==============================] - 2s 506us/step - loss: 0.3266 - acc: 0.9440 - val_loss: 0.7330 - val_acc: 0.7091\n",
      "Epoch 220/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3252 - acc: 0.9458 - val_loss: 0.7330 - val_acc: 0.7127\n",
      "Epoch 221/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3247 - acc: 0.9450 - val_loss: 0.7305 - val_acc: 0.7061\n",
      "Epoch 222/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3249 - acc: 0.9480 - val_loss: 0.7366 - val_acc: 0.7094\n",
      "Epoch 223/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3252 - acc: 0.9476 - val_loss: 0.7329 - val_acc: 0.7047\n",
      "Epoch 224/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3247 - acc: 0.9454 - val_loss: 0.7396 - val_acc: 0.7171\n",
      "Epoch 225/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3247 - acc: 0.9472 - val_loss: 0.7353 - val_acc: 0.7142\n",
      "Epoch 226/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3252 - acc: 0.9471 - val_loss: 0.7353 - val_acc: 0.7094\n",
      "Epoch 227/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3269 - acc: 0.9409 - val_loss: 0.7323 - val_acc: 0.6996\n",
      "Epoch 228/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3257 - acc: 0.9433 - val_loss: 0.7363 - val_acc: 0.7091\n",
      "Epoch 229/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3236 - acc: 0.9503 - val_loss: 0.7346 - val_acc: 0.7014\n",
      "Epoch 230/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3243 - acc: 0.9454 - val_loss: 0.7399 - val_acc: 0.6996\n",
      "Epoch 231/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3239 - acc: 0.9493 - val_loss: 0.7330 - val_acc: 0.7061\n",
      "Epoch 232/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3232 - acc: 0.9482 - val_loss: 0.7356 - val_acc: 0.7010\n",
      "Epoch 233/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3222 - acc: 0.9498 - val_loss: 0.7420 - val_acc: 0.7021\n",
      "Epoch 234/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3224 - acc: 0.9475 - val_loss: 0.7398 - val_acc: 0.7091\n",
      "Epoch 235/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3219 - acc: 0.9485 - val_loss: 0.7403 - val_acc: 0.7010\n",
      "Epoch 236/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3230 - acc: 0.9458 - val_loss: 0.7351 - val_acc: 0.7054\n",
      "Epoch 237/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3225 - acc: 0.9480 - val_loss: 0.7340 - val_acc: 0.7080\n",
      "Epoch 238/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3229 - acc: 0.9476 - val_loss: 0.7389 - val_acc: 0.6988\n",
      "Epoch 239/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3214 - acc: 0.9510 - val_loss: 0.7391 - val_acc: 0.7098\n",
      "Epoch 240/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3206 - acc: 0.9512 - val_loss: 0.7395 - val_acc: 0.7039\n",
      "Epoch 241/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3205 - acc: 0.9513 - val_loss: 0.7373 - val_acc: 0.7058\n",
      "Epoch 242/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3221 - acc: 0.9495 - val_loss: 0.7376 - val_acc: 0.7058\n",
      "Epoch 243/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3211 - acc: 0.9487 - val_loss: 0.7386 - val_acc: 0.7018\n",
      "Epoch 244/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3207 - acc: 0.9507 - val_loss: 0.7371 - val_acc: 0.7036\n",
      "Epoch 245/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3204 - acc: 0.9533 - val_loss: 0.7368 - val_acc: 0.7018\n",
      "Epoch 246/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3206 - acc: 0.9509 - val_loss: 0.7342 - val_acc: 0.7120\n",
      "Epoch 247/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3212 - acc: 0.9498 - val_loss: 0.7349 - val_acc: 0.7116\n",
      "Epoch 248/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3204 - acc: 0.9508 - val_loss: 0.7334 - val_acc: 0.6999\n",
      "Epoch 249/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3201 - acc: 0.9537 - val_loss: 0.7347 - val_acc: 0.7039\n",
      "Epoch 250/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3198 - acc: 0.9527 - val_loss: 0.7371 - val_acc: 0.7047\n",
      "Epoch 251/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3197 - acc: 0.9511 - val_loss: 0.7367 - val_acc: 0.7050\n",
      "Epoch 252/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3192 - acc: 0.9515 - val_loss: 0.7317 - val_acc: 0.7054\n",
      "Epoch 253/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3196 - acc: 0.9540 - val_loss: 0.7347 - val_acc: 0.7043\n",
      "Epoch 254/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3196 - acc: 0.9519 - val_loss: 0.7352 - val_acc: 0.7076\n",
      "Epoch 255/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3197 - acc: 0.9519 - val_loss: 0.7346 - val_acc: 0.7127\n",
      "Epoch 256/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3199 - acc: 0.9516 - val_loss: 0.7367 - val_acc: 0.7025\n",
      "Epoch 257/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3194 - acc: 0.9520 - val_loss: 0.7302 - val_acc: 0.7072\n",
      "Epoch 258/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3210 - acc: 0.9535 - val_loss: 0.7338 - val_acc: 0.7025\n",
      "Epoch 259/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3190 - acc: 0.9519 - val_loss: 0.7281 - val_acc: 0.7083\n",
      "Epoch 260/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3181 - acc: 0.9524 - val_loss: 0.7309 - val_acc: 0.7032\n",
      "Epoch 261/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3185 - acc: 0.9551 - val_loss: 0.7353 - val_acc: 0.7072\n",
      "Epoch 262/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3183 - acc: 0.9540 - val_loss: 0.7338 - val_acc: 0.7043\n",
      "Epoch 263/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3191 - acc: 0.9520 - val_loss: 0.7341 - val_acc: 0.7105\n",
      "Epoch 264/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3186 - acc: 0.9540 - val_loss: 0.7308 - val_acc: 0.7065\n",
      "Epoch 265/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3196 - acc: 0.9503 - val_loss: 0.7298 - val_acc: 0.7076\n",
      "Epoch 266/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3191 - acc: 0.9512 - val_loss: 0.7365 - val_acc: 0.7050\n",
      "Epoch 267/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3187 - acc: 0.9530 - val_loss: 0.7333 - val_acc: 0.7065\n",
      "Epoch 268/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3173 - acc: 0.9565 - val_loss: 0.7314 - val_acc: 0.7043\n",
      "Epoch 269/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3176 - acc: 0.9541 - val_loss: 0.7328 - val_acc: 0.7087\n",
      "Epoch 270/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3176 - acc: 0.9561 - val_loss: 0.7347 - val_acc: 0.7058\n",
      "Epoch 271/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3184 - acc: 0.9518 - val_loss: 0.7337 - val_acc: 0.7054\n",
      "Epoch 272/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3182 - acc: 0.9526 - val_loss: 0.7285 - val_acc: 0.7036\n",
      "Epoch 273/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3186 - acc: 0.9508 - val_loss: 0.7328 - val_acc: 0.7076\n",
      "Epoch 274/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3191 - acc: 0.9534 - val_loss: 0.7295 - val_acc: 0.7054\n",
      "Epoch 275/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3177 - acc: 0.9525 - val_loss: 0.7328 - val_acc: 0.7131\n",
      "Epoch 276/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3165 - acc: 0.9567 - val_loss: 0.7324 - val_acc: 0.7054\n",
      "Epoch 277/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3174 - acc: 0.9558 - val_loss: 0.7302 - val_acc: 0.7054\n",
      "Epoch 278/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3173 - acc: 0.9553 - val_loss: 0.7347 - val_acc: 0.7113\n",
      "Epoch 279/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3169 - acc: 0.9546 - val_loss: 0.7344 - val_acc: 0.7113\n",
      "Epoch 280/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3171 - acc: 0.9544 - val_loss: 0.7323 - val_acc: 0.7061\n",
      "Epoch 281/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3170 - acc: 0.9573 - val_loss: 0.7359 - val_acc: 0.7109\n",
      "Epoch 282/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3167 - acc: 0.9559 - val_loss: 0.7310 - val_acc: 0.7102\n",
      "Epoch 283/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3175 - acc: 0.9559 - val_loss: 0.7342 - val_acc: 0.7043\n",
      "Epoch 284/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3166 - acc: 0.9541 - val_loss: 0.7321 - val_acc: 0.7061\n",
      "Epoch 285/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3164 - acc: 0.9570 - val_loss: 0.7315 - val_acc: 0.7014\n",
      "Epoch 286/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3168 - acc: 0.9535 - val_loss: 0.7306 - val_acc: 0.7069\n",
      "Epoch 287/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3170 - acc: 0.9544 - val_loss: 0.7328 - val_acc: 0.7054\n",
      "Epoch 288/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3165 - acc: 0.9570 - val_loss: 0.7313 - val_acc: 0.6999\n",
      "Epoch 289/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3165 - acc: 0.9564 - val_loss: 0.7292 - val_acc: 0.7058\n",
      "Epoch 290/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3163 - acc: 0.9571 - val_loss: 0.7361 - val_acc: 0.7039\n",
      "Epoch 291/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3170 - acc: 0.9540 - val_loss: 0.7287 - val_acc: 0.7047\n",
      "Epoch 292/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3219 - acc: 0.9473 - val_loss: 0.7237 - val_acc: 0.7061\n",
      "Epoch 293/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3176 - acc: 0.9513 - val_loss: 0.7219 - val_acc: 0.7061\n",
      "Epoch 294/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3158 - acc: 0.9577 - val_loss: 0.7274 - val_acc: 0.7113\n",
      "Epoch 295/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3154 - acc: 0.9584 - val_loss: 0.7309 - val_acc: 0.7036\n",
      "Epoch 296/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3156 - acc: 0.9573 - val_loss: 0.7307 - val_acc: 0.7061\n",
      "Epoch 297/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3155 - acc: 0.9583 - val_loss: 0.7278 - val_acc: 0.7142\n",
      "Epoch 298/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3161 - acc: 0.9574 - val_loss: 0.7311 - val_acc: 0.7080\n",
      "Epoch 299/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3164 - acc: 0.9551 - val_loss: 0.7298 - val_acc: 0.7036\n",
      "Epoch 300/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3159 - acc: 0.9588 - val_loss: 0.7333 - val_acc: 0.7135\n",
      "Epoch 301/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3156 - acc: 0.9585 - val_loss: 0.7275 - val_acc: 0.7116\n",
      "Epoch 302/10000\n",
      "4259/4259 [==============================] - 2s 513us/step - loss: 0.3158 - acc: 0.9578 - val_loss: 0.7246 - val_acc: 0.7105\n",
      "Epoch 303/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3163 - acc: 0.9555 - val_loss: 0.7272 - val_acc: 0.7094\n",
      "Epoch 304/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3158 - acc: 0.9565 - val_loss: 0.7263 - val_acc: 0.7061\n",
      "Epoch 305/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3159 - acc: 0.9567 - val_loss: 0.7282 - val_acc: 0.7091\n",
      "Epoch 306/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3157 - acc: 0.9576 - val_loss: 0.7275 - val_acc: 0.7018\n",
      "Epoch 307/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3157 - acc: 0.9573 - val_loss: 0.7260 - val_acc: 0.7058\n",
      "Epoch 308/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3152 - acc: 0.9613 - val_loss: 0.7225 - val_acc: 0.7054\n",
      "Epoch 309/10000\n",
      "4259/4259 [==============================] - 2s 503us/step - loss: 0.3152 - acc: 0.9573 - val_loss: 0.7261 - val_acc: 0.7039\n",
      "Epoch 310/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3153 - acc: 0.9592 - val_loss: 0.7255 - val_acc: 0.7072\n",
      "Epoch 311/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3152 - acc: 0.9580 - val_loss: 0.7287 - val_acc: 0.7043\n",
      "Epoch 312/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3150 - acc: 0.9591 - val_loss: 0.7249 - val_acc: 0.7102\n",
      "Epoch 313/10000\n",
      "4259/4259 [==============================] - 2s 502us/step - loss: 0.3159 - acc: 0.9582 - val_loss: 0.7277 - val_acc: 0.7032\n",
      "Epoch 314/10000\n",
      "4259/4259 [==============================] - 2s 504us/step - loss: 0.3157 - acc: 0.9562 - val_loss: 0.7207 - val_acc: 0.7116\n",
      "Epoch 315/10000\n",
      "4259/4259 [==============================] - 2s 501us/step - loss: 0.3154 - acc: 0.9588 - val_loss: 0.7231 - val_acc: 0.7080\n",
      "Epoch 316/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3158 - acc: 0.9582 - val_loss: 0.7238 - val_acc: 0.7021\n",
      "Epoch 317/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3157 - acc: 0.9578 - val_loss: 0.7233 - val_acc: 0.7105\n",
      "Epoch 318/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3154 - acc: 0.9566 - val_loss: 0.7223 - val_acc: 0.7076\n",
      "Epoch 319/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3154 - acc: 0.9588 - val_loss: 0.7247 - val_acc: 0.7105\n",
      "Epoch 320/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3150 - acc: 0.9587 - val_loss: 0.7198 - val_acc: 0.7116\n",
      "Epoch 321/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3162 - acc: 0.9570 - val_loss: 0.7218 - val_acc: 0.7116\n",
      "Epoch 322/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3158 - acc: 0.9589 - val_loss: 0.7236 - val_acc: 0.7065\n",
      "Epoch 323/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3147 - acc: 0.9575 - val_loss: 0.7187 - val_acc: 0.7120\n",
      "Epoch 324/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3145 - acc: 0.9627 - val_loss: 0.7241 - val_acc: 0.7094\n",
      "Epoch 325/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3160 - acc: 0.9570 - val_loss: 0.7194 - val_acc: 0.7127\n",
      "Epoch 326/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3167 - acc: 0.9546 - val_loss: 0.7216 - val_acc: 0.7050\n",
      "Epoch 327/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3150 - acc: 0.9588 - val_loss: 0.7228 - val_acc: 0.7145\n",
      "Epoch 328/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3143 - acc: 0.9614 - val_loss: 0.7234 - val_acc: 0.7091\n",
      "Epoch 329/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3145 - acc: 0.9595 - val_loss: 0.7236 - val_acc: 0.7069\n",
      "Epoch 330/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3143 - acc: 0.9617 - val_loss: 0.7249 - val_acc: 0.7094\n",
      "Epoch 331/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3146 - acc: 0.9602 - val_loss: 0.7212 - val_acc: 0.7109\n",
      "Epoch 332/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3144 - acc: 0.9596 - val_loss: 0.7212 - val_acc: 0.7069\n",
      "Epoch 333/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3147 - acc: 0.9594 - val_loss: 0.7229 - val_acc: 0.7113\n",
      "Epoch 334/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3141 - acc: 0.9635 - val_loss: 0.7221 - val_acc: 0.7094\n",
      "Epoch 335/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3147 - acc: 0.9580 - val_loss: 0.7233 - val_acc: 0.7043\n",
      "Epoch 336/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3155 - acc: 0.9573 - val_loss: 0.7156 - val_acc: 0.7160\n",
      "Epoch 337/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3150 - acc: 0.9588 - val_loss: 0.7201 - val_acc: 0.7102\n",
      "Epoch 338/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3139 - acc: 0.9613 - val_loss: 0.7211 - val_acc: 0.7058\n",
      "Epoch 339/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3140 - acc: 0.9635 - val_loss: 0.7228 - val_acc: 0.7091\n",
      "Epoch 340/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3143 - acc: 0.9620 - val_loss: 0.7248 - val_acc: 0.7109\n",
      "Epoch 341/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3234 - acc: 0.9510 - val_loss: 0.7326 - val_acc: 0.7116\n",
      "Epoch 342/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3321 - acc: 0.9412 - val_loss: 0.7320 - val_acc: 0.7094\n",
      "Epoch 343/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3228 - acc: 0.9485 - val_loss: 0.7193 - val_acc: 0.7098\n",
      "Epoch 344/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3154 - acc: 0.9602 - val_loss: 0.7243 - val_acc: 0.7094\n",
      "Epoch 345/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3130 - acc: 0.9676 - val_loss: 0.7234 - val_acc: 0.7091\n",
      "Epoch 346/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3119 - acc: 0.9701 - val_loss: 0.7270 - val_acc: 0.7039\n",
      "Epoch 347/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3118 - acc: 0.9697 - val_loss: 0.7268 - val_acc: 0.7083\n",
      "Epoch 348/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3117 - acc: 0.9700 - val_loss: 0.7291 - val_acc: 0.7072\n",
      "Epoch 349/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3115 - acc: 0.9697 - val_loss: 0.7282 - val_acc: 0.7127\n",
      "Epoch 350/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3112 - acc: 0.9729 - val_loss: 0.7305 - val_acc: 0.7036\n",
      "Epoch 351/10000\n",
      "4259/4259 [==============================] - 2s 555us/step - loss: 0.3113 - acc: 0.9695 - val_loss: 0.7298 - val_acc: 0.7069\n",
      "Epoch 352/10000\n",
      "4259/4259 [==============================] - 2s 536us/step - loss: 0.3120 - acc: 0.9663 - val_loss: 0.7306 - val_acc: 0.7076\n",
      "Epoch 353/10000\n",
      "4259/4259 [==============================] - ETA: 0s - loss: 0.3152 - acc: 0.966 - 2s 492us/step - loss: 0.3124 - acc: 0.9663 - val_loss: 0.7312 - val_acc: 0.7098\n",
      "Epoch 354/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3129 - acc: 0.9644 - val_loss: 0.7302 - val_acc: 0.7021\n",
      "Epoch 355/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3136 - acc: 0.9645 - val_loss: 0.7295 - val_acc: 0.7032\n",
      "Epoch 356/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3142 - acc: 0.9626 - val_loss: 0.7264 - val_acc: 0.7105\n",
      "Epoch 357/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3141 - acc: 0.9595 - val_loss: 0.7256 - val_acc: 0.7036\n",
      "Epoch 358/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3138 - acc: 0.9634 - val_loss: 0.7282 - val_acc: 0.7050\n",
      "Epoch 359/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3136 - acc: 0.9602 - val_loss: 0.7298 - val_acc: 0.7036\n",
      "Epoch 360/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3140 - acc: 0.9612 - val_loss: 0.7263 - val_acc: 0.7102\n",
      "Epoch 361/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3136 - acc: 0.9624 - val_loss: 0.7284 - val_acc: 0.7087\n",
      "Epoch 362/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3134 - acc: 0.9639 - val_loss: 0.7257 - val_acc: 0.7142\n",
      "Epoch 363/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3136 - acc: 0.9607 - val_loss: 0.7255 - val_acc: 0.7105\n",
      "Epoch 364/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3134 - acc: 0.9621 - val_loss: 0.7255 - val_acc: 0.7094\n",
      "Epoch 365/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3136 - acc: 0.9633 - val_loss: 0.7244 - val_acc: 0.7061\n",
      "Epoch 366/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3132 - acc: 0.9620 - val_loss: 0.7185 - val_acc: 0.7072\n",
      "Epoch 367/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3138 - acc: 0.9600 - val_loss: 0.7191 - val_acc: 0.7120\n",
      "Epoch 368/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3132 - acc: 0.9613 - val_loss: 0.7227 - val_acc: 0.7102\n",
      "Epoch 369/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3131 - acc: 0.9636 - val_loss: 0.7199 - val_acc: 0.7142\n",
      "Epoch 370/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3130 - acc: 0.9631 - val_loss: 0.7200 - val_acc: 0.7087\n",
      "Epoch 371/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3132 - acc: 0.9585 - val_loss: 0.7197 - val_acc: 0.7036\n",
      "Epoch 372/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3131 - acc: 0.9656 - val_loss: 0.7191 - val_acc: 0.7083\n",
      "Epoch 373/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3137 - acc: 0.9631 - val_loss: 0.7199 - val_acc: 0.7145\n",
      "Epoch 374/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3131 - acc: 0.9634 - val_loss: 0.7212 - val_acc: 0.7025\n",
      "Epoch 375/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3131 - acc: 0.9628 - val_loss: 0.7194 - val_acc: 0.7098\n",
      "Epoch 376/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3131 - acc: 0.9610 - val_loss: 0.7191 - val_acc: 0.7087\n",
      "Epoch 377/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3128 - acc: 0.9639 - val_loss: 0.7206 - val_acc: 0.7120\n",
      "Epoch 378/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3128 - acc: 0.9649 - val_loss: 0.7190 - val_acc: 0.7069\n",
      "Epoch 379/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3129 - acc: 0.9622 - val_loss: 0.7221 - val_acc: 0.7029\n",
      "Epoch 380/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3132 - acc: 0.9610 - val_loss: 0.7171 - val_acc: 0.7127\n",
      "Epoch 381/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3132 - acc: 0.9626 - val_loss: 0.7266 - val_acc: 0.7039\n",
      "Epoch 382/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3142 - acc: 0.9593 - val_loss: 0.7195 - val_acc: 0.7116\n",
      "Epoch 383/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3133 - acc: 0.9621 - val_loss: 0.7201 - val_acc: 0.7087\n",
      "Epoch 384/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3128 - acc: 0.9634 - val_loss: 0.7199 - val_acc: 0.7076\n",
      "Epoch 385/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3127 - acc: 0.9624 - val_loss: 0.7202 - val_acc: 0.7091\n",
      "Epoch 386/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3135 - acc: 0.9616 - val_loss: 0.7174 - val_acc: 0.7098\n",
      "Epoch 387/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3124 - acc: 0.9652 - val_loss: 0.7202 - val_acc: 0.7091\n",
      "Epoch 388/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3121 - acc: 0.9664 - val_loss: 0.7188 - val_acc: 0.7091\n",
      "Epoch 389/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3120 - acc: 0.9662 - val_loss: 0.7190 - val_acc: 0.7105\n",
      "Epoch 390/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3123 - acc: 0.9655 - val_loss: 0.7190 - val_acc: 0.7113\n",
      "Epoch 391/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3128 - acc: 0.9623 - val_loss: 0.7205 - val_acc: 0.7098\n",
      "Epoch 392/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3132 - acc: 0.9633 - val_loss: 0.7222 - val_acc: 0.7076\n",
      "Epoch 393/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3131 - acc: 0.9603 - val_loss: 0.7186 - val_acc: 0.7153\n",
      "Epoch 394/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3127 - acc: 0.9609 - val_loss: 0.7214 - val_acc: 0.7083\n",
      "Epoch 395/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3125 - acc: 0.9636 - val_loss: 0.7172 - val_acc: 0.7069\n",
      "Epoch 396/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3121 - acc: 0.9659 - val_loss: 0.7172 - val_acc: 0.7145\n",
      "Epoch 397/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3123 - acc: 0.9643 - val_loss: 0.7177 - val_acc: 0.7054\n",
      "Epoch 398/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3126 - acc: 0.9634 - val_loss: 0.7191 - val_acc: 0.7105\n",
      "Epoch 399/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3125 - acc: 0.9651 - val_loss: 0.7174 - val_acc: 0.7054\n",
      "Epoch 400/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3126 - acc: 0.9619 - val_loss: 0.7194 - val_acc: 0.7149\n",
      "Epoch 401/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3126 - acc: 0.9634 - val_loss: 0.7178 - val_acc: 0.7175\n",
      "Epoch 402/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.3126 - acc: 0.9647 - val_loss: 0.7184 - val_acc: 0.7149\n",
      "Epoch 403/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3123 - acc: 0.9642 - val_loss: 0.7179 - val_acc: 0.7087\n",
      "Epoch 404/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3121 - acc: 0.9647 - val_loss: 0.7158 - val_acc: 0.7105\n",
      "Epoch 405/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3121 - acc: 0.9651 - val_loss: 0.7174 - val_acc: 0.7105\n",
      "Epoch 406/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3127 - acc: 0.9638 - val_loss: 0.7177 - val_acc: 0.7153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3128 - acc: 0.9620 - val_loss: 0.7180 - val_acc: 0.7061\n",
      "Epoch 408/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3123 - acc: 0.9643 - val_loss: 0.7196 - val_acc: 0.7102\n",
      "Epoch 409/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3117 - acc: 0.9651 - val_loss: 0.7158 - val_acc: 0.7069\n",
      "Epoch 410/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3120 - acc: 0.9659 - val_loss: 0.7129 - val_acc: 0.7113\n",
      "Epoch 411/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3124 - acc: 0.9614 - val_loss: 0.7151 - val_acc: 0.7120\n",
      "Epoch 412/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3119 - acc: 0.9653 - val_loss: 0.7161 - val_acc: 0.7102\n",
      "Epoch 413/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3116 - acc: 0.9663 - val_loss: 0.7162 - val_acc: 0.7142\n",
      "Epoch 414/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3120 - acc: 0.9658 - val_loss: 0.7158 - val_acc: 0.7072\n",
      "Epoch 415/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3131 - acc: 0.9632 - val_loss: 0.7170 - val_acc: 0.7160\n",
      "Epoch 416/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3126 - acc: 0.9625 - val_loss: 0.7159 - val_acc: 0.7120\n",
      "Epoch 417/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3121 - acc: 0.9662 - val_loss: 0.7138 - val_acc: 0.7113\n",
      "Epoch 418/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3128 - acc: 0.9613 - val_loss: 0.7085 - val_acc: 0.7127\n",
      "Epoch 419/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3123 - acc: 0.9624 - val_loss: 0.7139 - val_acc: 0.7102\n",
      "Epoch 420/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3120 - acc: 0.9646 - val_loss: 0.7145 - val_acc: 0.7138\n",
      "Epoch 421/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3119 - acc: 0.9662 - val_loss: 0.7159 - val_acc: 0.7072\n",
      "Epoch 422/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3125 - acc: 0.9669 - val_loss: 0.7166 - val_acc: 0.7138\n",
      "Epoch 423/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3120 - acc: 0.9652 - val_loss: 0.7146 - val_acc: 0.7072\n",
      "Epoch 424/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3114 - acc: 0.9673 - val_loss: 0.7177 - val_acc: 0.7083\n",
      "Epoch 425/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3112 - acc: 0.9676 - val_loss: 0.7151 - val_acc: 0.7135\n",
      "Epoch 426/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3113 - acc: 0.9689 - val_loss: 0.7150 - val_acc: 0.7116\n",
      "Epoch 427/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3114 - acc: 0.9649 - val_loss: 0.7141 - val_acc: 0.7080\n",
      "Epoch 428/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3113 - acc: 0.9668 - val_loss: 0.7134 - val_acc: 0.7102\n",
      "Epoch 429/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3122 - acc: 0.9638 - val_loss: 0.7167 - val_acc: 0.7186\n",
      "Epoch 430/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3121 - acc: 0.9647 - val_loss: 0.7131 - val_acc: 0.7131\n",
      "Epoch 431/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3124 - acc: 0.9651 - val_loss: 0.7153 - val_acc: 0.7098\n",
      "Epoch 432/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3122 - acc: 0.9638 - val_loss: 0.7119 - val_acc: 0.7142\n",
      "Epoch 433/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3116 - acc: 0.9636 - val_loss: 0.7119 - val_acc: 0.7131\n",
      "Epoch 434/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3109 - acc: 0.9687 - val_loss: 0.7148 - val_acc: 0.7142\n",
      "Epoch 435/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3112 - acc: 0.9666 - val_loss: 0.7134 - val_acc: 0.7138\n",
      "Epoch 436/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3246 - acc: 0.9458 - val_loss: 0.7296 - val_acc: 0.7058\n",
      "Epoch 437/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3259 - acc: 0.9462 - val_loss: 0.7155 - val_acc: 0.7072\n",
      "Epoch 438/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3170 - acc: 0.9597 - val_loss: 0.7159 - val_acc: 0.7160\n",
      "Epoch 439/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3124 - acc: 0.9664 - val_loss: 0.7133 - val_acc: 0.7135\n",
      "Epoch 440/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3101 - acc: 0.9732 - val_loss: 0.7178 - val_acc: 0.7127\n",
      "Epoch 441/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3092 - acc: 0.9753 - val_loss: 0.7181 - val_acc: 0.7120\n",
      "Epoch 442/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3088 - acc: 0.9754 - val_loss: 0.7181 - val_acc: 0.7138\n",
      "Epoch 443/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3086 - acc: 0.9772 - val_loss: 0.7201 - val_acc: 0.7109\n",
      "Epoch 444/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3085 - acc: 0.9774 - val_loss: 0.7202 - val_acc: 0.7109\n",
      "Epoch 445/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3085 - acc: 0.9759 - val_loss: 0.7218 - val_acc: 0.7142\n",
      "Epoch 446/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3091 - acc: 0.9752 - val_loss: 0.7200 - val_acc: 0.7124\n",
      "Epoch 447/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3091 - acc: 0.9745 - val_loss: 0.7225 - val_acc: 0.7127\n",
      "Epoch 448/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3092 - acc: 0.9722 - val_loss: 0.7202 - val_acc: 0.7164\n",
      "Epoch 449/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3095 - acc: 0.9710 - val_loss: 0.7205 - val_acc: 0.7171\n",
      "Epoch 450/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3099 - acc: 0.9699 - val_loss: 0.7203 - val_acc: 0.7138\n",
      "Epoch 451/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3104 - acc: 0.9691 - val_loss: 0.7181 - val_acc: 0.7087\n",
      "Epoch 452/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3107 - acc: 0.9664 - val_loss: 0.7163 - val_acc: 0.7142\n",
      "Epoch 453/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3119 - acc: 0.9638 - val_loss: 0.7199 - val_acc: 0.7124\n",
      "Epoch 454/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3110 - acc: 0.9653 - val_loss: 0.7119 - val_acc: 0.7186\n",
      "Epoch 455/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3112 - acc: 0.9687 - val_loss: 0.7180 - val_acc: 0.7127\n",
      "Epoch 456/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3106 - acc: 0.9707 - val_loss: 0.7139 - val_acc: 0.7105\n",
      "Epoch 457/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3102 - acc: 0.9708 - val_loss: 0.7142 - val_acc: 0.7153\n",
      "Epoch 458/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3103 - acc: 0.9693 - val_loss: 0.7135 - val_acc: 0.7156\n",
      "Epoch 459/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3104 - acc: 0.9696 - val_loss: 0.7128 - val_acc: 0.7145\n",
      "Epoch 460/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3104 - acc: 0.9695 - val_loss: 0.7133 - val_acc: 0.7145\n",
      "Epoch 461/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3102 - acc: 0.9707 - val_loss: 0.7133 - val_acc: 0.7153\n",
      "Epoch 462/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3103 - acc: 0.9681 - val_loss: 0.7136 - val_acc: 0.7160\n",
      "Epoch 463/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3103 - acc: 0.9689 - val_loss: 0.7150 - val_acc: 0.7094\n",
      "Epoch 464/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3105 - acc: 0.9684 - val_loss: 0.7168 - val_acc: 0.7120\n",
      "Epoch 465/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3104 - acc: 0.9695 - val_loss: 0.7108 - val_acc: 0.7145\n",
      "Epoch 466/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3107 - acc: 0.9679 - val_loss: 0.7156 - val_acc: 0.7171\n",
      "Epoch 467/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3108 - acc: 0.9677 - val_loss: 0.7126 - val_acc: 0.7189\n",
      "Epoch 468/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3108 - acc: 0.9674 - val_loss: 0.7109 - val_acc: 0.7156\n",
      "Epoch 469/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3108 - acc: 0.9668 - val_loss: 0.7135 - val_acc: 0.7145\n",
      "Epoch 470/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3109 - acc: 0.9646 - val_loss: 0.7156 - val_acc: 0.7153\n",
      "Epoch 471/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3104 - acc: 0.9693 - val_loss: 0.7099 - val_acc: 0.7135\n",
      "Epoch 472/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3101 - acc: 0.9669 - val_loss: 0.7129 - val_acc: 0.7167\n",
      "Epoch 473/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3103 - acc: 0.9703 - val_loss: 0.7105 - val_acc: 0.7167\n",
      "Epoch 474/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3102 - acc: 0.9699 - val_loss: 0.7098 - val_acc: 0.7164\n",
      "Epoch 475/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3101 - acc: 0.9681 - val_loss: 0.7107 - val_acc: 0.7222\n",
      "Epoch 476/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3102 - acc: 0.9702 - val_loss: 0.7096 - val_acc: 0.7175\n",
      "Epoch 477/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3101 - acc: 0.9678 - val_loss: 0.7113 - val_acc: 0.7167\n",
      "Epoch 478/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3104 - acc: 0.9685 - val_loss: 0.7114 - val_acc: 0.7131\n",
      "Epoch 479/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3108 - acc: 0.9674 - val_loss: 0.7097 - val_acc: 0.7197\n",
      "Epoch 480/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3107 - acc: 0.9665 - val_loss: 0.7084 - val_acc: 0.7164\n",
      "Epoch 481/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3102 - acc: 0.9692 - val_loss: 0.7115 - val_acc: 0.7175\n",
      "Epoch 482/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3099 - acc: 0.9705 - val_loss: 0.7094 - val_acc: 0.7135\n",
      "Epoch 483/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3101 - acc: 0.9697 - val_loss: 0.7101 - val_acc: 0.7167\n",
      "Epoch 484/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3101 - acc: 0.9706 - val_loss: 0.7086 - val_acc: 0.7138\n",
      "Epoch 485/10000\n",
      "4259/4259 [==============================] - 2s 499us/step - loss: 0.3100 - acc: 0.9697 - val_loss: 0.7141 - val_acc: 0.7142\n",
      "Epoch 486/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3105 - acc: 0.9671 - val_loss: 0.7080 - val_acc: 0.7186\n",
      "Epoch 487/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3104 - acc: 0.9683 - val_loss: 0.7067 - val_acc: 0.7171\n",
      "Epoch 488/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3101 - acc: 0.9699 - val_loss: 0.7085 - val_acc: 0.7149\n",
      "Epoch 489/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3098 - acc: 0.9724 - val_loss: 0.7113 - val_acc: 0.7178\n",
      "Epoch 490/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3098 - acc: 0.9702 - val_loss: 0.7069 - val_acc: 0.7230\n",
      "Epoch 491/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3101 - acc: 0.9681 - val_loss: 0.7103 - val_acc: 0.7178\n",
      "Epoch 492/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3107 - acc: 0.9680 - val_loss: 0.7137 - val_acc: 0.7135\n",
      "Epoch 493/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3115 - acc: 0.9638 - val_loss: 0.7114 - val_acc: 0.7186\n",
      "Epoch 494/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3110 - acc: 0.9667 - val_loss: 0.7079 - val_acc: 0.7164\n",
      "Epoch 495/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3102 - acc: 0.9681 - val_loss: 0.7093 - val_acc: 0.7153\n",
      "Epoch 496/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3095 - acc: 0.9713 - val_loss: 0.7080 - val_acc: 0.7156\n",
      "Epoch 497/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3091 - acc: 0.9739 - val_loss: 0.7090 - val_acc: 0.7164\n",
      "Epoch 498/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3090 - acc: 0.9746 - val_loss: 0.7108 - val_acc: 0.7186\n",
      "Epoch 499/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3099 - acc: 0.9705 - val_loss: 0.7108 - val_acc: 0.7204\n",
      "Epoch 500/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3102 - acc: 0.9704 - val_loss: 0.7063 - val_acc: 0.7182\n",
      "Epoch 501/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3105 - acc: 0.9652 - val_loss: 0.7066 - val_acc: 0.7171\n",
      "Epoch 502/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3104 - acc: 0.9683 - val_loss: 0.7089 - val_acc: 0.7178\n",
      "Epoch 503/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3101 - acc: 0.9706 - val_loss: 0.7053 - val_acc: 0.7197\n",
      "Epoch 504/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3096 - acc: 0.9703 - val_loss: 0.7044 - val_acc: 0.7160\n",
      "Epoch 505/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3095 - acc: 0.9732 - val_loss: 0.7088 - val_acc: 0.7182\n",
      "Epoch 506/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3098 - acc: 0.9722 - val_loss: 0.7038 - val_acc: 0.7211\n",
      "Epoch 507/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3099 - acc: 0.9698 - val_loss: 0.7083 - val_acc: 0.7186\n",
      "Epoch 508/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3103 - acc: 0.9703 - val_loss: 0.7074 - val_acc: 0.7208\n",
      "Epoch 509/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3103 - acc: 0.9696 - val_loss: 0.7067 - val_acc: 0.7197\n",
      "Epoch 510/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3101 - acc: 0.9685 - val_loss: 0.7055 - val_acc: 0.7193\n",
      "Epoch 511/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3097 - acc: 0.9696 - val_loss: 0.7070 - val_acc: 0.7222\n",
      "Epoch 512/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3095 - acc: 0.9696 - val_loss: 0.7065 - val_acc: 0.7189\n",
      "Epoch 513/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3099 - acc: 0.9692 - val_loss: 0.7076 - val_acc: 0.7186\n",
      "Epoch 514/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3096 - acc: 0.9721 - val_loss: 0.7076 - val_acc: 0.7211\n",
      "Epoch 515/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3097 - acc: 0.9701 - val_loss: 0.7088 - val_acc: 0.7211\n",
      "Epoch 516/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3095 - acc: 0.9717 - val_loss: 0.7087 - val_acc: 0.7230\n",
      "Epoch 517/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3100 - acc: 0.9693 - val_loss: 0.7090 - val_acc: 0.7226\n",
      "Epoch 518/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3102 - acc: 0.9707 - val_loss: 0.7066 - val_acc: 0.7167\n",
      "Epoch 519/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3102 - acc: 0.9684 - val_loss: 0.7050 - val_acc: 0.7149\n",
      "Epoch 520/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3099 - acc: 0.9706 - val_loss: 0.7070 - val_acc: 0.7175\n",
      "Epoch 521/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3095 - acc: 0.9708 - val_loss: 0.7075 - val_acc: 0.7204\n",
      "Epoch 522/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3092 - acc: 0.9744 - val_loss: 0.7065 - val_acc: 0.7219\n",
      "Epoch 523/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3091 - acc: 0.9710 - val_loss: 0.7054 - val_acc: 0.7175\n",
      "Epoch 524/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3090 - acc: 0.9735 - val_loss: 0.7072 - val_acc: 0.7215\n",
      "Epoch 525/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3155 - acc: 0.9584 - val_loss: 0.7178 - val_acc: 0.7189\n",
      "Epoch 526/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3308 - acc: 0.9393 - val_loss: 0.7184 - val_acc: 0.7182\n",
      "Epoch 527/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3299 - acc: 0.9429 - val_loss: 0.7170 - val_acc: 0.7175\n",
      "Epoch 528/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3171 - acc: 0.9561 - val_loss: 0.7043 - val_acc: 0.7164\n",
      "Epoch 529/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3113 - acc: 0.9690 - val_loss: 0.7047 - val_acc: 0.7164\n",
      "Epoch 530/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3097 - acc: 0.9724 - val_loss: 0.7051 - val_acc: 0.7189\n",
      "Epoch 531/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3088 - acc: 0.9749 - val_loss: 0.7064 - val_acc: 0.7193\n",
      "Epoch 532/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3084 - acc: 0.9768 - val_loss: 0.7083 - val_acc: 0.7182\n",
      "Epoch 533/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3080 - acc: 0.9784 - val_loss: 0.7083 - val_acc: 0.7189\n",
      "Epoch 534/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3079 - acc: 0.9784 - val_loss: 0.7092 - val_acc: 0.7211\n",
      "Epoch 535/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3077 - acc: 0.9791 - val_loss: 0.7095 - val_acc: 0.7193\n",
      "Epoch 536/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3076 - acc: 0.9804 - val_loss: 0.7099 - val_acc: 0.7215\n",
      "Epoch 537/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3075 - acc: 0.9807 - val_loss: 0.7107 - val_acc: 0.7197\n",
      "Epoch 538/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3075 - acc: 0.9808 - val_loss: 0.7111 - val_acc: 0.7197\n",
      "Epoch 539/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3074 - acc: 0.9802 - val_loss: 0.7126 - val_acc: 0.7164\n",
      "Epoch 540/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3074 - acc: 0.9813 - val_loss: 0.7115 - val_acc: 0.7167\n",
      "Epoch 541/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3074 - acc: 0.9799 - val_loss: 0.7129 - val_acc: 0.7182\n",
      "Epoch 542/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3079 - acc: 0.9773 - val_loss: 0.7133 - val_acc: 0.7182\n",
      "Epoch 543/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3081 - acc: 0.9780 - val_loss: 0.7139 - val_acc: 0.7120\n",
      "Epoch 544/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3089 - acc: 0.9749 - val_loss: 0.7123 - val_acc: 0.7156\n",
      "Epoch 545/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3090 - acc: 0.9744 - val_loss: 0.7116 - val_acc: 0.7204\n",
      "Epoch 546/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3091 - acc: 0.9720 - val_loss: 0.7133 - val_acc: 0.7219\n",
      "Epoch 547/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3093 - acc: 0.9709 - val_loss: 0.7113 - val_acc: 0.7200\n",
      "Epoch 548/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3096 - acc: 0.9678 - val_loss: 0.7114 - val_acc: 0.7142\n",
      "Epoch 549/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3111 - acc: 0.9675 - val_loss: 0.7089 - val_acc: 0.7178\n",
      "Epoch 550/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3096 - acc: 0.9694 - val_loss: 0.7083 - val_acc: 0.7156\n",
      "Epoch 551/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3088 - acc: 0.9750 - val_loss: 0.7072 - val_acc: 0.7113\n",
      "Epoch 552/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3083 - acc: 0.9757 - val_loss: 0.7089 - val_acc: 0.7160\n",
      "Epoch 553/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3082 - acc: 0.9762 - val_loss: 0.7064 - val_acc: 0.7167\n",
      "Epoch 554/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3084 - acc: 0.9743 - val_loss: 0.7082 - val_acc: 0.7135\n",
      "Epoch 555/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3085 - acc: 0.9745 - val_loss: 0.7057 - val_acc: 0.7182\n",
      "Epoch 556/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3088 - acc: 0.9725 - val_loss: 0.7042 - val_acc: 0.7160\n",
      "Epoch 557/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3090 - acc: 0.9734 - val_loss: 0.7061 - val_acc: 0.7178\n",
      "Epoch 558/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3094 - acc: 0.9703 - val_loss: 0.7033 - val_acc: 0.7193\n",
      "Epoch 559/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3097 - acc: 0.9712 - val_loss: 0.7085 - val_acc: 0.7197\n",
      "Epoch 560/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3097 - acc: 0.9681 - val_loss: 0.7077 - val_acc: 0.7138\n",
      "Epoch 561/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3096 - acc: 0.9694 - val_loss: 0.7052 - val_acc: 0.7160\n",
      "Epoch 562/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3092 - acc: 0.9704 - val_loss: 0.7020 - val_acc: 0.7178\n",
      "Epoch 563/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3090 - acc: 0.9729 - val_loss: 0.7028 - val_acc: 0.7193\n",
      "Epoch 564/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3087 - acc: 0.9722 - val_loss: 0.7043 - val_acc: 0.7167\n",
      "Epoch 565/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3089 - acc: 0.9729 - val_loss: 0.7029 - val_acc: 0.7178\n",
      "Epoch 566/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3091 - acc: 0.9725 - val_loss: 0.7042 - val_acc: 0.7186\n",
      "Epoch 567/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3095 - acc: 0.9700 - val_loss: 0.7021 - val_acc: 0.7164\n",
      "Epoch 568/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3099 - acc: 0.9710 - val_loss: 0.7016 - val_acc: 0.7208\n",
      "Epoch 569/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3098 - acc: 0.9699 - val_loss: 0.7023 - val_acc: 0.7200\n",
      "Epoch 570/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3092 - acc: 0.9710 - val_loss: 0.7017 - val_acc: 0.7219\n",
      "Epoch 571/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3088 - acc: 0.9720 - val_loss: 0.7024 - val_acc: 0.7215\n",
      "Epoch 572/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3088 - acc: 0.9752 - val_loss: 0.7035 - val_acc: 0.7171\n",
      "Epoch 573/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3086 - acc: 0.9756 - val_loss: 0.7017 - val_acc: 0.7149\n",
      "Epoch 574/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3085 - acc: 0.9731 - val_loss: 0.7035 - val_acc: 0.7182\n",
      "Epoch 575/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3086 - acc: 0.9735 - val_loss: 0.6997 - val_acc: 0.7222\n",
      "Epoch 576/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3090 - acc: 0.9721 - val_loss: 0.7002 - val_acc: 0.7171\n",
      "Epoch 577/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3091 - acc: 0.9713 - val_loss: 0.7046 - val_acc: 0.7200\n",
      "Epoch 578/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3089 - acc: 0.9722 - val_loss: 0.7019 - val_acc: 0.7193\n",
      "Epoch 579/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3089 - acc: 0.9717 - val_loss: 0.7044 - val_acc: 0.7186\n",
      "Epoch 580/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3089 - acc: 0.9744 - val_loss: 0.7033 - val_acc: 0.7248\n",
      "Epoch 581/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3096 - acc: 0.9685 - val_loss: 0.7039 - val_acc: 0.7200\n",
      "Epoch 582/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3092 - acc: 0.9715 - val_loss: 0.7017 - val_acc: 0.7193\n",
      "Epoch 583/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3089 - acc: 0.9720 - val_loss: 0.7054 - val_acc: 0.7222\n",
      "Epoch 584/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3088 - acc: 0.9746 - val_loss: 0.7014 - val_acc: 0.7193\n",
      "Epoch 585/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3086 - acc: 0.9727 - val_loss: 0.7005 - val_acc: 0.7230\n",
      "Epoch 586/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3087 - acc: 0.9740 - val_loss: 0.7029 - val_acc: 0.7204\n",
      "Epoch 587/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3100 - acc: 0.9688 - val_loss: 0.7055 - val_acc: 0.7211\n",
      "Epoch 588/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3096 - acc: 0.9717 - val_loss: 0.7036 - val_acc: 0.7240\n",
      "Epoch 589/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3091 - acc: 0.9741 - val_loss: 0.6979 - val_acc: 0.7259\n",
      "Epoch 590/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3087 - acc: 0.9731 - val_loss: 0.7023 - val_acc: 0.7219\n",
      "Epoch 591/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3084 - acc: 0.9757 - val_loss: 0.7010 - val_acc: 0.7240\n",
      "Epoch 592/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3083 - acc: 0.9754 - val_loss: 0.7019 - val_acc: 0.7208\n",
      "Epoch 593/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3086 - acc: 0.9740 - val_loss: 0.7002 - val_acc: 0.7204\n",
      "Epoch 594/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3086 - acc: 0.9735 - val_loss: 0.7003 - val_acc: 0.7226\n",
      "Epoch 595/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3085 - acc: 0.9757 - val_loss: 0.7028 - val_acc: 0.7204\n",
      "Epoch 596/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3086 - acc: 0.9750 - val_loss: 0.7020 - val_acc: 0.7175\n",
      "Epoch 597/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3092 - acc: 0.9719 - val_loss: 0.7001 - val_acc: 0.7251\n",
      "Epoch 598/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3091 - acc: 0.9717 - val_loss: 0.7014 - val_acc: 0.7204\n",
      "Epoch 599/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3087 - acc: 0.9715 - val_loss: 0.7012 - val_acc: 0.7200\n",
      "Epoch 600/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3086 - acc: 0.9737 - val_loss: 0.6997 - val_acc: 0.7208\n",
      "Epoch 601/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3087 - acc: 0.9739 - val_loss: 0.6998 - val_acc: 0.7215\n",
      "Epoch 602/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3087 - acc: 0.9724 - val_loss: 0.6990 - val_acc: 0.7204\n",
      "Epoch 603/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3086 - acc: 0.9736 - val_loss: 0.7002 - val_acc: 0.7240\n",
      "Epoch 604/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3087 - acc: 0.9725 - val_loss: 0.6996 - val_acc: 0.7233\n",
      "Epoch 605/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3086 - acc: 0.9728 - val_loss: 0.6984 - val_acc: 0.7189\n",
      "Epoch 606/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3086 - acc: 0.9753 - val_loss: 0.7016 - val_acc: 0.7204\n",
      "Epoch 607/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3084 - acc: 0.9760 - val_loss: 0.6988 - val_acc: 0.7233\n",
      "Epoch 608/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3083 - acc: 0.9741 - val_loss: 0.6991 - val_acc: 0.7248\n",
      "Epoch 609/10000\n",
      "4259/4259 [==============================] - 2s 501us/step - loss: 0.3085 - acc: 0.9752 - val_loss: 0.7010 - val_acc: 0.7208\n",
      "Epoch 610/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3108 - acc: 0.9715 - val_loss: 0.7107 - val_acc: 0.7237\n",
      "Epoch 611/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3303 - acc: 0.9429 - val_loss: 0.7134 - val_acc: 0.7135\n",
      "Epoch 612/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3282 - acc: 0.9472 - val_loss: 0.7069 - val_acc: 0.7211\n",
      "Epoch 613/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3172 - acc: 0.9562 - val_loss: 0.6999 - val_acc: 0.7219\n",
      "Epoch 614/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3134 - acc: 0.9667 - val_loss: 0.7044 - val_acc: 0.7222\n",
      "Epoch 615/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3132 - acc: 0.9674 - val_loss: 0.6990 - val_acc: 0.7237\n",
      "Epoch 616/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3113 - acc: 0.9707 - val_loss: 0.6989 - val_acc: 0.7215\n",
      "Epoch 617/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3093 - acc: 0.9721 - val_loss: 0.6977 - val_acc: 0.7204\n",
      "Epoch 618/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3087 - acc: 0.9756 - val_loss: 0.6989 - val_acc: 0.7226\n",
      "Epoch 619/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3084 - acc: 0.9771 - val_loss: 0.6988 - val_acc: 0.7197\n",
      "Epoch 620/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3082 - acc: 0.9789 - val_loss: 0.6999 - val_acc: 0.7211\n",
      "Epoch 621/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3080 - acc: 0.9788 - val_loss: 0.6998 - val_acc: 0.7197\n",
      "Epoch 622/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3078 - acc: 0.9811 - val_loss: 0.7009 - val_acc: 0.7197\n",
      "Epoch 623/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3078 - acc: 0.9799 - val_loss: 0.7010 - val_acc: 0.7193\n",
      "Epoch 624/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3077 - acc: 0.9808 - val_loss: 0.7004 - val_acc: 0.7208\n",
      "Epoch 625/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3076 - acc: 0.9813 - val_loss: 0.7013 - val_acc: 0.7215\n",
      "Epoch 626/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3076 - acc: 0.9817 - val_loss: 0.7013 - val_acc: 0.7193\n",
      "Epoch 627/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3076 - acc: 0.9825 - val_loss: 0.7024 - val_acc: 0.7193\n",
      "Epoch 628/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3076 - acc: 0.9807 - val_loss: 0.7020 - val_acc: 0.7186\n",
      "Epoch 629/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3077 - acc: 0.9819 - val_loss: 0.7033 - val_acc: 0.7186\n",
      "Epoch 630/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3078 - acc: 0.9805 - val_loss: 0.7035 - val_acc: 0.7208\n",
      "Epoch 631/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3079 - acc: 0.9797 - val_loss: 0.7032 - val_acc: 0.7211\n",
      "Epoch 632/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3080 - acc: 0.9783 - val_loss: 0.7040 - val_acc: 0.7204\n",
      "Epoch 633/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3083 - acc: 0.9765 - val_loss: 0.7018 - val_acc: 0.7208\n",
      "Epoch 634/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3086 - acc: 0.9750 - val_loss: 0.7032 - val_acc: 0.7226\n",
      "Epoch 635/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3092 - acc: 0.9721 - val_loss: 0.7010 - val_acc: 0.7116\n",
      "Epoch 636/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3105 - acc: 0.9717 - val_loss: 0.7066 - val_acc: 0.7244\n",
      "Epoch 637/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3148 - acc: 0.9600 - val_loss: 0.6969 - val_acc: 0.7284\n",
      "Epoch 638/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3142 - acc: 0.9617 - val_loss: 0.6997 - val_acc: 0.7259\n",
      "Epoch 639/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3102 - acc: 0.9701 - val_loss: 0.6992 - val_acc: 0.7189\n",
      "Epoch 640/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3084 - acc: 0.9756 - val_loss: 0.6985 - val_acc: 0.7255\n",
      "Epoch 641/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3076 - acc: 0.9793 - val_loss: 0.6997 - val_acc: 0.7197\n",
      "Epoch 642/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3073 - acc: 0.9816 - val_loss: 0.7004 - val_acc: 0.7215\n",
      "Epoch 643/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3073 - acc: 0.9823 - val_loss: 0.6996 - val_acc: 0.7200\n",
      "Epoch 644/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3073 - acc: 0.9820 - val_loss: 0.7002 - val_acc: 0.7215\n",
      "Epoch 645/10000\n",
      "4259/4259 [==============================] - 2s 505us/step - loss: 0.3072 - acc: 0.9823 - val_loss: 0.7011 - val_acc: 0.7219\n",
      "Epoch 646/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3073 - acc: 0.9804 - val_loss: 0.7010 - val_acc: 0.7182\n",
      "Epoch 647/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3073 - acc: 0.9795 - val_loss: 0.7018 - val_acc: 0.7233\n",
      "Epoch 648/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3075 - acc: 0.9798 - val_loss: 0.7004 - val_acc: 0.7226\n",
      "Epoch 649/10000\n",
      "4259/4259 [==============================] - ETA: 0s - loss: 0.3086 - acc: 0.977 - 2s 492us/step - loss: 0.3078 - acc: 0.9775 - val_loss: 0.7044 - val_acc: 0.7156\n",
      "Epoch 650/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3083 - acc: 0.9750 - val_loss: 0.7017 - val_acc: 0.7204\n",
      "Epoch 651/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3090 - acc: 0.9718 - val_loss: 0.7009 - val_acc: 0.7208\n",
      "Epoch 652/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3091 - acc: 0.9717 - val_loss: 0.6993 - val_acc: 0.7230\n",
      "Epoch 653/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3090 - acc: 0.9720 - val_loss: 0.6984 - val_acc: 0.7233\n",
      "Epoch 654/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3087 - acc: 0.9730 - val_loss: 0.6977 - val_acc: 0.7171\n",
      "Epoch 655/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3086 - acc: 0.9761 - val_loss: 0.6977 - val_acc: 0.7189\n",
      "Epoch 656/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3082 - acc: 0.9755 - val_loss: 0.6955 - val_acc: 0.7281\n",
      "Epoch 657/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3081 - acc: 0.9765 - val_loss: 0.6969 - val_acc: 0.7230\n",
      "Epoch 658/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3079 - acc: 0.9771 - val_loss: 0.6979 - val_acc: 0.7189\n",
      "Epoch 659/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3081 - acc: 0.9753 - val_loss: 0.6957 - val_acc: 0.7273\n",
      "Epoch 660/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3083 - acc: 0.9746 - val_loss: 0.6959 - val_acc: 0.7208\n",
      "Epoch 661/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3086 - acc: 0.9736 - val_loss: 0.6967 - val_acc: 0.7186\n",
      "Epoch 662/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3089 - acc: 0.9728 - val_loss: 0.6963 - val_acc: 0.7193\n",
      "Epoch 663/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3086 - acc: 0.9749 - val_loss: 0.6949 - val_acc: 0.7219\n",
      "Epoch 664/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3088 - acc: 0.9725 - val_loss: 0.6953 - val_acc: 0.7211\n",
      "Epoch 665/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3087 - acc: 0.9752 - val_loss: 0.6952 - val_acc: 0.7208\n",
      "Epoch 666/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3084 - acc: 0.9743 - val_loss: 0.6952 - val_acc: 0.7219\n",
      "Epoch 667/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3082 - acc: 0.9775 - val_loss: 0.6927 - val_acc: 0.7226\n",
      "Epoch 668/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3079 - acc: 0.9771 - val_loss: 0.6937 - val_acc: 0.7266\n",
      "Epoch 669/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3078 - acc: 0.9786 - val_loss: 0.6928 - val_acc: 0.7244\n",
      "Epoch 670/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3080 - acc: 0.9773 - val_loss: 0.6961 - val_acc: 0.7186\n",
      "Epoch 671/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3092 - acc: 0.9718 - val_loss: 0.6954 - val_acc: 0.7248\n",
      "Epoch 672/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3089 - acc: 0.9731 - val_loss: 0.6948 - val_acc: 0.7244\n",
      "Epoch 673/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3086 - acc: 0.9738 - val_loss: 0.6961 - val_acc: 0.7197\n",
      "Epoch 674/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3083 - acc: 0.9743 - val_loss: 0.6915 - val_acc: 0.7230\n",
      "Epoch 675/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3083 - acc: 0.9746 - val_loss: 0.6930 - val_acc: 0.7149\n",
      "Epoch 676/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3082 - acc: 0.9764 - val_loss: 0.6921 - val_acc: 0.7240\n",
      "Epoch 677/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3089 - acc: 0.9729 - val_loss: 0.6954 - val_acc: 0.7266\n",
      "Epoch 678/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3149 - acc: 0.9574 - val_loss: 0.7078 - val_acc: 0.7171\n",
      "Epoch 679/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3128 - acc: 0.9631 - val_loss: 0.7005 - val_acc: 0.7259\n",
      "Epoch 680/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3107 - acc: 0.9700 - val_loss: 0.7053 - val_acc: 0.7281\n",
      "Epoch 681/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3107 - acc: 0.9710 - val_loss: 0.6972 - val_acc: 0.7288\n",
      "Epoch 682/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3085 - acc: 0.9748 - val_loss: 0.6989 - val_acc: 0.7259\n",
      "Epoch 683/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3074 - acc: 0.9802 - val_loss: 0.6989 - val_acc: 0.7259\n",
      "Epoch 684/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3069 - acc: 0.9800 - val_loss: 0.6991 - val_acc: 0.7226\n",
      "Epoch 685/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9809 - val_loss: 0.7001 - val_acc: 0.7237\n",
      "Epoch 686/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3067 - acc: 0.9822 - val_loss: 0.7002 - val_acc: 0.7251\n",
      "Epoch 687/10000\n",
      "4259/4259 [==============================] - 2s 501us/step - loss: 0.3066 - acc: 0.9840 - val_loss: 0.7002 - val_acc: 0.7259\n",
      "Epoch 688/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3066 - acc: 0.9822 - val_loss: 0.7007 - val_acc: 0.7240\n",
      "Epoch 689/10000\n",
      "4259/4259 [==============================] - 2s 510us/step - loss: 0.3066 - acc: 0.9829 - val_loss: 0.7003 - val_acc: 0.7259\n",
      "Epoch 690/10000\n",
      "4259/4259 [==============================] - 2s 501us/step - loss: 0.3066 - acc: 0.9823 - val_loss: 0.7006 - val_acc: 0.7244\n",
      "Epoch 691/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3067 - acc: 0.9816 - val_loss: 0.7014 - val_acc: 0.7226\n",
      "Epoch 692/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3068 - acc: 0.9807 - val_loss: 0.7025 - val_acc: 0.7222\n",
      "Epoch 693/10000\n",
      "4259/4259 [==============================] - 2s 499us/step - loss: 0.3071 - acc: 0.9788 - val_loss: 0.7029 - val_acc: 0.7240\n",
      "Epoch 694/10000\n",
      "4259/4259 [==============================] - 2s 506us/step - loss: 0.3077 - acc: 0.9753 - val_loss: 0.6991 - val_acc: 0.7208\n",
      "Epoch 695/10000\n",
      "4259/4259 [==============================] - 2s 512us/step - loss: 0.3084 - acc: 0.9726 - val_loss: 0.6973 - val_acc: 0.7259\n",
      "Epoch 696/10000\n",
      "4259/4259 [==============================] - 2s 510us/step - loss: 0.3086 - acc: 0.9732 - val_loss: 0.6988 - val_acc: 0.7204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 697/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3092 - acc: 0.9705 - val_loss: 0.6959 - val_acc: 0.7219\n",
      "Epoch 698/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3085 - acc: 0.9726 - val_loss: 0.6963 - val_acc: 0.7251\n",
      "Epoch 699/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3079 - acc: 0.9752 - val_loss: 0.6916 - val_acc: 0.7211\n",
      "Epoch 700/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3074 - acc: 0.9775 - val_loss: 0.6939 - val_acc: 0.7208\n",
      "Epoch 701/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3072 - acc: 0.9771 - val_loss: 0.6921 - val_acc: 0.7186\n",
      "Epoch 702/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3072 - acc: 0.9776 - val_loss: 0.6947 - val_acc: 0.7215\n",
      "Epoch 703/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3072 - acc: 0.9791 - val_loss: 0.6937 - val_acc: 0.7244\n",
      "Epoch 704/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3074 - acc: 0.9767 - val_loss: 0.6936 - val_acc: 0.7222\n",
      "Epoch 705/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3074 - acc: 0.9775 - val_loss: 0.6920 - val_acc: 0.7230\n",
      "Epoch 706/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3076 - acc: 0.9735 - val_loss: 0.6918 - val_acc: 0.7215\n",
      "Epoch 707/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3077 - acc: 0.9753 - val_loss: 0.6932 - val_acc: 0.7277\n",
      "Epoch 708/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3080 - acc: 0.9753 - val_loss: 0.6916 - val_acc: 0.7248\n",
      "Epoch 709/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3080 - acc: 0.9739 - val_loss: 0.6923 - val_acc: 0.7284\n",
      "Epoch 710/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3084 - acc: 0.9707 - val_loss: 0.6943 - val_acc: 0.7208\n",
      "Epoch 711/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3083 - acc: 0.9721 - val_loss: 0.6947 - val_acc: 0.7211\n",
      "Epoch 712/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3081 - acc: 0.9750 - val_loss: 0.6884 - val_acc: 0.7197\n",
      "Epoch 713/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3076 - acc: 0.9758 - val_loss: 0.6903 - val_acc: 0.7233\n",
      "Epoch 714/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3073 - acc: 0.9774 - val_loss: 0.6911 - val_acc: 0.7208\n",
      "Epoch 715/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3070 - acc: 0.9771 - val_loss: 0.6900 - val_acc: 0.7240\n",
      "Epoch 716/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3071 - acc: 0.9788 - val_loss: 0.6889 - val_acc: 0.7222\n",
      "Epoch 717/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3073 - acc: 0.9776 - val_loss: 0.6910 - val_acc: 0.7233\n",
      "Epoch 718/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3072 - acc: 0.9772 - val_loss: 0.6900 - val_acc: 0.7255\n",
      "Epoch 719/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3075 - acc: 0.9751 - val_loss: 0.6927 - val_acc: 0.7211\n",
      "Epoch 720/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3075 - acc: 0.9759 - val_loss: 0.6894 - val_acc: 0.7251\n",
      "Epoch 721/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3074 - acc: 0.9768 - val_loss: 0.6923 - val_acc: 0.7248\n",
      "Epoch 722/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3075 - acc: 0.9764 - val_loss: 0.6921 - val_acc: 0.7219\n",
      "Epoch 723/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3077 - acc: 0.9751 - val_loss: 0.6887 - val_acc: 0.7219\n",
      "Epoch 724/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3078 - acc: 0.9759 - val_loss: 0.6889 - val_acc: 0.7186\n",
      "Epoch 725/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3077 - acc: 0.9753 - val_loss: 0.6884 - val_acc: 0.7240\n",
      "Epoch 726/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3079 - acc: 0.9732 - val_loss: 0.6879 - val_acc: 0.7211\n",
      "Epoch 727/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3076 - acc: 0.9758 - val_loss: 0.6874 - val_acc: 0.7222\n",
      "Epoch 728/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3073 - acc: 0.9768 - val_loss: 0.6874 - val_acc: 0.7244\n",
      "Epoch 729/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3078 - acc: 0.9749 - val_loss: 0.6875 - val_acc: 0.7237\n",
      "Epoch 730/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3079 - acc: 0.9745 - val_loss: 0.6893 - val_acc: 0.7240\n",
      "Epoch 731/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3076 - acc: 0.9768 - val_loss: 0.6847 - val_acc: 0.7244\n",
      "Epoch 732/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3072 - acc: 0.9776 - val_loss: 0.6855 - val_acc: 0.7262\n",
      "Epoch 733/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3072 - acc: 0.9771 - val_loss: 0.6866 - val_acc: 0.7248\n",
      "Epoch 734/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3072 - acc: 0.9786 - val_loss: 0.6858 - val_acc: 0.7292\n",
      "Epoch 735/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3071 - acc: 0.9768 - val_loss: 0.6838 - val_acc: 0.7211\n",
      "Epoch 736/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3073 - acc: 0.9776 - val_loss: 0.6857 - val_acc: 0.7284\n",
      "Epoch 737/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3078 - acc: 0.9748 - val_loss: 0.6863 - val_acc: 0.7255\n",
      "Epoch 738/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3076 - acc: 0.9763 - val_loss: 0.6858 - val_acc: 0.7240\n",
      "Epoch 739/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3073 - acc: 0.9756 - val_loss: 0.6852 - val_acc: 0.7270\n",
      "Epoch 740/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3073 - acc: 0.9786 - val_loss: 0.6855 - val_acc: 0.7222\n",
      "Epoch 741/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3072 - acc: 0.9761 - val_loss: 0.6840 - val_acc: 0.7219\n",
      "Epoch 742/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3072 - acc: 0.9779 - val_loss: 0.6833 - val_acc: 0.7204\n",
      "Epoch 743/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3072 - acc: 0.9761 - val_loss: 0.6835 - val_acc: 0.7248\n",
      "Epoch 744/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3074 - acc: 0.9777 - val_loss: 0.6839 - val_acc: 0.7230\n",
      "Epoch 745/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3072 - acc: 0.9771 - val_loss: 0.6850 - val_acc: 0.7277\n",
      "Epoch 746/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3073 - acc: 0.9764 - val_loss: 0.6849 - val_acc: 0.7255\n",
      "Epoch 747/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3076 - acc: 0.9769 - val_loss: 0.6852 - val_acc: 0.7251\n",
      "Epoch 748/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3075 - acc: 0.9771 - val_loss: 0.6833 - val_acc: 0.7219\n",
      "Epoch 749/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3076 - acc: 0.9739 - val_loss: 0.6854 - val_acc: 0.7251\n",
      "Epoch 750/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3074 - acc: 0.9755 - val_loss: 0.6829 - val_acc: 0.7211\n",
      "Epoch 751/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.3077 - acc: 0.9765 - val_loss: 0.6834 - val_acc: 0.7248\n",
      "Epoch 752/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3076 - acc: 0.9745 - val_loss: 0.6849 - val_acc: 0.7219\n",
      "Epoch 753/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3094 - acc: 0.9717 - val_loss: 0.6874 - val_acc: 0.7200\n",
      "Epoch 754/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3094 - acc: 0.9699 - val_loss: 0.6838 - val_acc: 0.7219\n",
      "Epoch 755/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3153 - acc: 0.9609 - val_loss: 0.6889 - val_acc: 0.7215\n",
      "Epoch 756/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3197 - acc: 0.9537 - val_loss: 0.6878 - val_acc: 0.7230\n",
      "Epoch 757/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3128 - acc: 0.9644 - val_loss: 0.6895 - val_acc: 0.7281\n",
      "Epoch 758/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3111 - acc: 0.9684 - val_loss: 0.6925 - val_acc: 0.7230\n",
      "Epoch 759/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3114 - acc: 0.9672 - val_loss: 0.6938 - val_acc: 0.7200\n",
      "Epoch 760/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3085 - acc: 0.9726 - val_loss: 0.6854 - val_acc: 0.7211\n",
      "Epoch 761/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3073 - acc: 0.9766 - val_loss: 0.6873 - val_acc: 0.7233\n",
      "Epoch 762/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3069 - acc: 0.9801 - val_loss: 0.6860 - val_acc: 0.7230\n",
      "Epoch 763/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3067 - acc: 0.9812 - val_loss: 0.6870 - val_acc: 0.7230\n",
      "Epoch 764/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3066 - acc: 0.9817 - val_loss: 0.6871 - val_acc: 0.7255\n",
      "Epoch 765/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3065 - acc: 0.9824 - val_loss: 0.6883 - val_acc: 0.7226\n",
      "Epoch 766/10000\n",
      "4259/4259 [==============================] - 2s 499us/step - loss: 0.3064 - acc: 0.9826 - val_loss: 0.6874 - val_acc: 0.7237\n",
      "Epoch 767/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3064 - acc: 0.9832 - val_loss: 0.6881 - val_acc: 0.7262\n",
      "Epoch 768/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3063 - acc: 0.9830 - val_loss: 0.6882 - val_acc: 0.7255\n",
      "Epoch 769/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3063 - acc: 0.9843 - val_loss: 0.6891 - val_acc: 0.7259\n",
      "Epoch 770/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3063 - acc: 0.9837 - val_loss: 0.6884 - val_acc: 0.7259\n",
      "Epoch 771/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3063 - acc: 0.9840 - val_loss: 0.6888 - val_acc: 0.7237\n",
      "Epoch 772/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3063 - acc: 0.9835 - val_loss: 0.6883 - val_acc: 0.7244\n",
      "Epoch 773/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3063 - acc: 0.9840 - val_loss: 0.6888 - val_acc: 0.7266\n",
      "Epoch 774/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3063 - acc: 0.9838 - val_loss: 0.6882 - val_acc: 0.7255\n",
      "Epoch 775/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3063 - acc: 0.9837 - val_loss: 0.6890 - val_acc: 0.7240\n",
      "Epoch 776/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3064 - acc: 0.9823 - val_loss: 0.6881 - val_acc: 0.7248\n",
      "Epoch 777/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3066 - acc: 0.9807 - val_loss: 0.6877 - val_acc: 0.7273\n",
      "Epoch 778/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3067 - acc: 0.9811 - val_loss: 0.6881 - val_acc: 0.7226\n",
      "Epoch 779/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3069 - acc: 0.9775 - val_loss: 0.6873 - val_acc: 0.7251\n",
      "Epoch 780/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3073 - acc: 0.9753 - val_loss: 0.6881 - val_acc: 0.7277\n",
      "Epoch 781/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3076 - acc: 0.9753 - val_loss: 0.6870 - val_acc: 0.7215\n",
      "Epoch 782/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3075 - acc: 0.9764 - val_loss: 0.6862 - val_acc: 0.7248\n",
      "Epoch 783/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3074 - acc: 0.9765 - val_loss: 0.6854 - val_acc: 0.7215\n",
      "Epoch 784/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3072 - acc: 0.9769 - val_loss: 0.6840 - val_acc: 0.7262\n",
      "Epoch 785/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3070 - acc: 0.9778 - val_loss: 0.6825 - val_acc: 0.7255\n",
      "Epoch 786/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3073 - acc: 0.9777 - val_loss: 0.6836 - val_acc: 0.7248\n",
      "Epoch 787/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3075 - acc: 0.9757 - val_loss: 0.6830 - val_acc: 0.7277\n",
      "Epoch 788/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3073 - acc: 0.9777 - val_loss: 0.6845 - val_acc: 0.7197\n",
      "Epoch 789/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3072 - acc: 0.9772 - val_loss: 0.6845 - val_acc: 0.7230\n",
      "Epoch 790/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3075 - acc: 0.9766 - val_loss: 0.6826 - val_acc: 0.7251\n",
      "Epoch 791/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3073 - acc: 0.9761 - val_loss: 0.6827 - val_acc: 0.7230\n",
      "Epoch 792/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3072 - acc: 0.9784 - val_loss: 0.6829 - val_acc: 0.7244\n",
      "Epoch 793/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3072 - acc: 0.9774 - val_loss: 0.6820 - val_acc: 0.7259\n",
      "Epoch 794/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3072 - acc: 0.9769 - val_loss: 0.6823 - val_acc: 0.7259\n",
      "Epoch 795/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3071 - acc: 0.9776 - val_loss: 0.6832 - val_acc: 0.7251\n",
      "Epoch 796/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3070 - acc: 0.9769 - val_loss: 0.6835 - val_acc: 0.7262\n",
      "Epoch 797/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3069 - acc: 0.9772 - val_loss: 0.6828 - val_acc: 0.7244\n",
      "Epoch 798/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3071 - acc: 0.9786 - val_loss: 0.6832 - val_acc: 0.7244\n",
      "Epoch 799/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3102 - acc: 0.9676 - val_loss: 0.6851 - val_acc: 0.7244\n",
      "Epoch 800/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3086 - acc: 0.9715 - val_loss: 0.6843 - val_acc: 0.7259\n",
      "Epoch 801/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3075 - acc: 0.9754 - val_loss: 0.6825 - val_acc: 0.7273\n",
      "Epoch 802/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3070 - acc: 0.9775 - val_loss: 0.6793 - val_acc: 0.7277\n",
      "Epoch 803/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3067 - acc: 0.9806 - val_loss: 0.6810 - val_acc: 0.7222\n",
      "Epoch 804/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3065 - acc: 0.9819 - val_loss: 0.6791 - val_acc: 0.7248\n",
      "Epoch 805/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3064 - acc: 0.9815 - val_loss: 0.6815 - val_acc: 0.7237\n",
      "Epoch 806/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3064 - acc: 0.9819 - val_loss: 0.6805 - val_acc: 0.7259\n",
      "Epoch 807/10000\n",
      "4259/4259 [==============================] - 2s 505us/step - loss: 0.3065 - acc: 0.9801 - val_loss: 0.6831 - val_acc: 0.7259\n",
      "Epoch 808/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3065 - acc: 0.9824 - val_loss: 0.6800 - val_acc: 0.7237\n",
      "Epoch 809/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3067 - acc: 0.9802 - val_loss: 0.6821 - val_acc: 0.7244\n",
      "Epoch 810/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3070 - acc: 0.9798 - val_loss: 0.6796 - val_acc: 0.7277\n",
      "Epoch 811/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3072 - acc: 0.9767 - val_loss: 0.6837 - val_acc: 0.7281\n",
      "Epoch 812/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.3075 - acc: 0.9746 - val_loss: 0.6785 - val_acc: 0.7295\n",
      "Epoch 813/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3078 - acc: 0.9735 - val_loss: 0.6822 - val_acc: 0.7262\n",
      "Epoch 814/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3080 - acc: 0.9744 - val_loss: 0.6815 - val_acc: 0.7255\n",
      "Epoch 815/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3077 - acc: 0.9723 - val_loss: 0.6804 - val_acc: 0.7277\n",
      "Epoch 816/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3073 - acc: 0.9773 - val_loss: 0.6813 - val_acc: 0.7303\n",
      "Epoch 817/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3070 - acc: 0.9799 - val_loss: 0.6799 - val_acc: 0.7284\n",
      "Epoch 818/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3068 - acc: 0.9798 - val_loss: 0.6788 - val_acc: 0.7219\n",
      "Epoch 819/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3069 - acc: 0.9797 - val_loss: 0.6787 - val_acc: 0.7233\n",
      "Epoch 820/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3069 - acc: 0.9791 - val_loss: 0.6787 - val_acc: 0.7255\n",
      "Epoch 821/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3069 - acc: 0.9794 - val_loss: 0.6792 - val_acc: 0.7259\n",
      "Epoch 822/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3072 - acc: 0.9776 - val_loss: 0.6788 - val_acc: 0.7288\n",
      "Epoch 823/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3072 - acc: 0.9753 - val_loss: 0.6818 - val_acc: 0.7314\n",
      "Epoch 824/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3074 - acc: 0.9776 - val_loss: 0.6817 - val_acc: 0.7240\n",
      "Epoch 825/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3085 - acc: 0.9736 - val_loss: 0.6856 - val_acc: 0.7281\n",
      "Epoch 826/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3114 - acc: 0.9696 - val_loss: 0.6888 - val_acc: 0.7215\n",
      "Epoch 827/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3357 - acc: 0.9454 - val_loss: 0.6972 - val_acc: 0.7230\n",
      "Epoch 828/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3244 - acc: 0.9518 - val_loss: 0.6821 - val_acc: 0.7314\n",
      "Epoch 829/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3155 - acc: 0.9619 - val_loss: 0.6804 - val_acc: 0.7222\n",
      "Epoch 830/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3123 - acc: 0.9668 - val_loss: 0.6863 - val_acc: 0.7230\n",
      "Epoch 831/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3093 - acc: 0.9725 - val_loss: 0.6846 - val_acc: 0.7255\n",
      "Epoch 832/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3083 - acc: 0.9763 - val_loss: 0.6820 - val_acc: 0.7259\n",
      "Epoch 833/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3077 - acc: 0.9789 - val_loss: 0.6818 - val_acc: 0.7266\n",
      "Epoch 834/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3074 - acc: 0.9785 - val_loss: 0.6816 - val_acc: 0.7251\n",
      "Epoch 835/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3070 - acc: 0.9799 - val_loss: 0.6812 - val_acc: 0.7284\n",
      "Epoch 836/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3069 - acc: 0.9804 - val_loss: 0.6808 - val_acc: 0.7262\n",
      "Epoch 837/10000\n",
      "4259/4259 [==============================] - 2s 505us/step - loss: 0.3067 - acc: 0.9813 - val_loss: 0.6804 - val_acc: 0.7270\n",
      "Epoch 838/10000\n",
      "4259/4259 [==============================] - 2s 502us/step - loss: 0.3067 - acc: 0.9825 - val_loss: 0.6803 - val_acc: 0.7266\n",
      "Epoch 839/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3066 - acc: 0.9821 - val_loss: 0.6795 - val_acc: 0.7273\n",
      "Epoch 840/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3065 - acc: 0.9824 - val_loss: 0.6802 - val_acc: 0.7255\n",
      "Epoch 841/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3065 - acc: 0.9836 - val_loss: 0.6800 - val_acc: 0.7266\n",
      "Epoch 842/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3064 - acc: 0.9833 - val_loss: 0.6809 - val_acc: 0.7259\n",
      "Epoch 843/10000\n",
      "4259/4259 [==============================] - 2s 504us/step - loss: 0.3064 - acc: 0.9834 - val_loss: 0.6802 - val_acc: 0.7273\n",
      "Epoch 844/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3063 - acc: 0.9839 - val_loss: 0.6804 - val_acc: 0.7259\n",
      "Epoch 845/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3063 - acc: 0.9840 - val_loss: 0.6807 - val_acc: 0.7262\n",
      "Epoch 846/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3063 - acc: 0.9837 - val_loss: 0.6806 - val_acc: 0.7277\n",
      "Epoch 847/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3063 - acc: 0.9836 - val_loss: 0.6802 - val_acc: 0.7255\n",
      "Epoch 848/10000\n",
      "4259/4259 [==============================] - 2s 501us/step - loss: 0.3063 - acc: 0.9846 - val_loss: 0.6809 - val_acc: 0.7277\n",
      "Epoch 849/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3063 - acc: 0.9841 - val_loss: 0.6805 - val_acc: 0.7266\n",
      "Epoch 850/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3062 - acc: 0.9837 - val_loss: 0.6807 - val_acc: 0.7255\n",
      "Epoch 851/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3063 - acc: 0.9836 - val_loss: 0.6804 - val_acc: 0.7284\n",
      "Epoch 852/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3063 - acc: 0.9830 - val_loss: 0.6806 - val_acc: 0.7288\n",
      "Epoch 853/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3064 - acc: 0.9827 - val_loss: 0.6812 - val_acc: 0.7281\n",
      "Epoch 854/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3064 - acc: 0.9827 - val_loss: 0.6810 - val_acc: 0.7266\n",
      "Epoch 855/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3066 - acc: 0.9789 - val_loss: 0.6810 - val_acc: 0.7273\n",
      "Epoch 856/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3068 - acc: 0.9804 - val_loss: 0.6810 - val_acc: 0.7240\n",
      "Epoch 857/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3072 - acc: 0.9768 - val_loss: 0.6826 - val_acc: 0.7255\n",
      "Epoch 858/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3090 - acc: 0.9768 - val_loss: 0.6830 - val_acc: 0.7215\n",
      "Epoch 859/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3085 - acc: 0.9747 - val_loss: 0.6874 - val_acc: 0.7281\n",
      "Epoch 860/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3073 - acc: 0.9771 - val_loss: 0.6861 - val_acc: 0.7251\n",
      "Epoch 861/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3070 - acc: 0.9779 - val_loss: 0.6933 - val_acc: 0.7281\n",
      "Epoch 862/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3103 - acc: 0.9700 - val_loss: 0.6881 - val_acc: 0.7230\n",
      "Epoch 863/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3154 - acc: 0.9613 - val_loss: 0.6948 - val_acc: 0.7251\n",
      "Epoch 864/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.3267 - acc: 0.9467 - val_loss: 0.6933 - val_acc: 0.7189\n",
      "Epoch 865/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3178 - acc: 0.9561 - val_loss: 0.6906 - val_acc: 0.7219\n",
      "Epoch 866/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3114 - acc: 0.9662 - val_loss: 0.6838 - val_acc: 0.7219\n",
      "Epoch 867/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3092 - acc: 0.9709 - val_loss: 0.6841 - val_acc: 0.7230\n",
      "Epoch 868/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3084 - acc: 0.9738 - val_loss: 0.6837 - val_acc: 0.7222\n",
      "Epoch 869/10000\n",
      "4259/4259 [==============================] - 2s 502us/step - loss: 0.3079 - acc: 0.9760 - val_loss: 0.6836 - val_acc: 0.7237\n",
      "Epoch 870/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3076 - acc: 0.9771 - val_loss: 0.6840 - val_acc: 0.7240\n",
      "Epoch 871/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3074 - acc: 0.9782 - val_loss: 0.6848 - val_acc: 0.7248\n",
      "Epoch 872/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3073 - acc: 0.9797 - val_loss: 0.6840 - val_acc: 0.7237\n",
      "Epoch 873/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3072 - acc: 0.9794 - val_loss: 0.6847 - val_acc: 0.7237\n",
      "Epoch 874/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3071 - acc: 0.9804 - val_loss: 0.6852 - val_acc: 0.7251\n",
      "Epoch 875/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3070 - acc: 0.9813 - val_loss: 0.6857 - val_acc: 0.7255\n",
      "Epoch 876/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3070 - acc: 0.9805 - val_loss: 0.6862 - val_acc: 0.7266\n",
      "Epoch 877/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3069 - acc: 0.9816 - val_loss: 0.6862 - val_acc: 0.7251\n",
      "Epoch 878/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3069 - acc: 0.9818 - val_loss: 0.6865 - val_acc: 0.7244\n",
      "Epoch 879/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3068 - acc: 0.9812 - val_loss: 0.6862 - val_acc: 0.7251\n",
      "Epoch 880/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3068 - acc: 0.9825 - val_loss: 0.6868 - val_acc: 0.7262\n",
      "Epoch 881/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3068 - acc: 0.9821 - val_loss: 0.6866 - val_acc: 0.7277\n",
      "Epoch 882/10000\n",
      "4259/4259 [==============================] - 2s 502us/step - loss: 0.3068 - acc: 0.9827 - val_loss: 0.6874 - val_acc: 0.7259\n",
      "Epoch 883/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3068 - acc: 0.9831 - val_loss: 0.6864 - val_acc: 0.7251\n",
      "Epoch 884/10000\n",
      "4259/4259 [==============================] - 2s 501us/step - loss: 0.3068 - acc: 0.9829 - val_loss: 0.6884 - val_acc: 0.7266\n",
      "Epoch 885/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3068 - acc: 0.9834 - val_loss: 0.6864 - val_acc: 0.7255\n",
      "Epoch 886/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3068 - acc: 0.9828 - val_loss: 0.6891 - val_acc: 0.7237\n",
      "Epoch 887/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3069 - acc: 0.9806 - val_loss: 0.6882 - val_acc: 0.7244\n",
      "Epoch 888/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3069 - acc: 0.9819 - val_loss: 0.6884 - val_acc: 0.7248\n",
      "Epoch 889/10000\n",
      "4259/4259 [==============================] - 2s 501us/step - loss: 0.3069 - acc: 0.9808 - val_loss: 0.6878 - val_acc: 0.7259\n",
      "Epoch 890/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.3072 - acc: 0.9793 - val_loss: 0.6890 - val_acc: 0.7273\n",
      "Epoch 891/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.3074 - acc: 0.9775 - val_loss: 0.6876 - val_acc: 0.7270\n",
      "Epoch 892/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3074 - acc: 0.9786 - val_loss: 0.6886 - val_acc: 0.7240\n",
      "Epoch 893/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3074 - acc: 0.9777 - val_loss: 0.6863 - val_acc: 0.7259\n",
      "Epoch 894/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3076 - acc: 0.9757 - val_loss: 0.6885 - val_acc: 0.7237\n",
      "Epoch 895/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3077 - acc: 0.9761 - val_loss: 0.6858 - val_acc: 0.7240\n",
      "Epoch 896/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3078 - acc: 0.9761 - val_loss: 0.6867 - val_acc: 0.7273\n",
      "Epoch 897/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3076 - acc: 0.9750 - val_loss: 0.6860 - val_acc: 0.7259\n",
      "Epoch 898/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3074 - acc: 0.9768 - val_loss: 0.6879 - val_acc: 0.7259\n",
      "Epoch 899/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3074 - acc: 0.9778 - val_loss: 0.6881 - val_acc: 0.7266\n",
      "Epoch 900/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3082 - acc: 0.9740 - val_loss: 0.6900 - val_acc: 0.7259\n",
      "Epoch 901/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3084 - acc: 0.9730 - val_loss: 0.6845 - val_acc: 0.7277\n",
      "Epoch 902/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3084 - acc: 0.9732 - val_loss: 0.6921 - val_acc: 0.7226\n",
      "Epoch 903/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3113 - acc: 0.9651 - val_loss: 0.6997 - val_acc: 0.7237\n",
      "Epoch 904/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3117 - acc: 0.9653 - val_loss: 0.6929 - val_acc: 0.7226\n",
      "Epoch 905/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3119 - acc: 0.9638 - val_loss: 0.6927 - val_acc: 0.7233\n",
      "Epoch 906/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3092 - acc: 0.9718 - val_loss: 0.6888 - val_acc: 0.7251\n",
      "Epoch 907/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3077 - acc: 0.9765 - val_loss: 0.6889 - val_acc: 0.7189\n",
      "Epoch 908/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3071 - acc: 0.9808 - val_loss: 0.6896 - val_acc: 0.7200\n",
      "Epoch 909/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3068 - acc: 0.9824 - val_loss: 0.6895 - val_acc: 0.7204\n",
      "Epoch 910/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3067 - acc: 0.9820 - val_loss: 0.6893 - val_acc: 0.7226\n",
      "Epoch 911/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3066 - acc: 0.9837 - val_loss: 0.6891 - val_acc: 0.7200\n",
      "Epoch 912/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3066 - acc: 0.9831 - val_loss: 0.6895 - val_acc: 0.7211\n",
      "Epoch 913/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3066 - acc: 0.9839 - val_loss: 0.6898 - val_acc: 0.7208\n",
      "Epoch 914/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9845 - val_loss: 0.6901 - val_acc: 0.7226\n",
      "Epoch 915/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9829 - val_loss: 0.6900 - val_acc: 0.7186\n",
      "Epoch 916/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3066 - acc: 0.9826 - val_loss: 0.6904 - val_acc: 0.7230\n",
      "Epoch 917/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9835 - val_loss: 0.6901 - val_acc: 0.7197\n",
      "Epoch 918/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3067 - acc: 0.9804 - val_loss: 0.6903 - val_acc: 0.7222\n",
      "Epoch 919/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3069 - acc: 0.9807 - val_loss: 0.6906 - val_acc: 0.7200\n",
      "Epoch 920/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3071 - acc: 0.9786 - val_loss: 0.6923 - val_acc: 0.7248\n",
      "Epoch 921/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3075 - acc: 0.9763 - val_loss: 0.6922 - val_acc: 0.7186\n",
      "Epoch 922/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3082 - acc: 0.9749 - val_loss: 0.6891 - val_acc: 0.7273\n",
      "Epoch 923/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3083 - acc: 0.9737 - val_loss: 0.6880 - val_acc: 0.7251\n",
      "Epoch 924/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3078 - acc: 0.9734 - val_loss: 0.6865 - val_acc: 0.7270\n",
      "Epoch 925/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3074 - acc: 0.9773 - val_loss: 0.6867 - val_acc: 0.7215\n",
      "Epoch 926/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3072 - acc: 0.9785 - val_loss: 0.6878 - val_acc: 0.7251\n",
      "Epoch 927/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3072 - acc: 0.9797 - val_loss: 0.6862 - val_acc: 0.7197\n",
      "Epoch 928/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3071 - acc: 0.9782 - val_loss: 0.6852 - val_acc: 0.7266\n",
      "Epoch 929/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3072 - acc: 0.9786 - val_loss: 0.6872 - val_acc: 0.7230\n",
      "Epoch 930/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3073 - acc: 0.9789 - val_loss: 0.6874 - val_acc: 0.7248\n",
      "Epoch 931/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3073 - acc: 0.9771 - val_loss: 0.6851 - val_acc: 0.7281\n",
      "Epoch 932/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3078 - acc: 0.9755 - val_loss: 0.6883 - val_acc: 0.7244\n",
      "Epoch 933/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3082 - acc: 0.9736 - val_loss: 0.6886 - val_acc: 0.7230\n",
      "Epoch 934/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3078 - acc: 0.9762 - val_loss: 0.6851 - val_acc: 0.7244\n",
      "Epoch 935/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3077 - acc: 0.9754 - val_loss: 0.6853 - val_acc: 0.7219\n",
      "Epoch 936/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3075 - acc: 0.9775 - val_loss: 0.6841 - val_acc: 0.7230\n",
      "Epoch 937/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3073 - acc: 0.9786 - val_loss: 0.6845 - val_acc: 0.7259\n",
      "Epoch 938/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3072 - acc: 0.9771 - val_loss: 0.6849 - val_acc: 0.7230\n",
      "Epoch 939/10000\n",
      "4259/4259 [==============================] - 2s 511us/step - loss: 0.3072 - acc: 0.9784 - val_loss: 0.6835 - val_acc: 0.7277\n",
      "Epoch 940/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3080 - acc: 0.9756 - val_loss: 0.6897 - val_acc: 0.7259\n",
      "Epoch 941/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3094 - acc: 0.9709 - val_loss: 0.6933 - val_acc: 0.7215\n",
      "Epoch 942/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3106 - acc: 0.9680 - val_loss: 0.6815 - val_acc: 0.7197\n",
      "Epoch 943/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3124 - acc: 0.9664 - val_loss: 0.6861 - val_acc: 0.7262\n",
      "Epoch 944/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3119 - acc: 0.9668 - val_loss: 0.6856 - val_acc: 0.7240\n",
      "Epoch 945/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3105 - acc: 0.9699 - val_loss: 0.6813 - val_acc: 0.7288\n",
      "Epoch 946/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3110 - acc: 0.9733 - val_loss: 0.6783 - val_acc: 0.7288\n",
      "Epoch 947/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3085 - acc: 0.9728 - val_loss: 0.6737 - val_acc: 0.7314\n",
      "Epoch 948/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3079 - acc: 0.9757 - val_loss: 0.6769 - val_acc: 0.7310\n",
      "Epoch 949/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3067 - acc: 0.9800 - val_loss: 0.6762 - val_acc: 0.7321\n",
      "Epoch 950/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3065 - acc: 0.9818 - val_loss: 0.6764 - val_acc: 0.7332\n",
      "Epoch 951/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3063 - acc: 0.9824 - val_loss: 0.6765 - val_acc: 0.7288\n",
      "Epoch 952/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3063 - acc: 0.9836 - val_loss: 0.6775 - val_acc: 0.7288\n",
      "Epoch 953/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3062 - acc: 0.9838 - val_loss: 0.6773 - val_acc: 0.7270\n",
      "Epoch 954/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3062 - acc: 0.9839 - val_loss: 0.6776 - val_acc: 0.7306\n",
      "Epoch 955/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3061 - acc: 0.9843 - val_loss: 0.6770 - val_acc: 0.7299\n",
      "Epoch 956/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3061 - acc: 0.9849 - val_loss: 0.6776 - val_acc: 0.7295\n",
      "Epoch 957/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3061 - acc: 0.9847 - val_loss: 0.6777 - val_acc: 0.7317\n",
      "Epoch 958/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9856 - val_loss: 0.6779 - val_acc: 0.7306\n",
      "Epoch 959/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3061 - acc: 0.9845 - val_loss: 0.6780 - val_acc: 0.7310\n",
      "Epoch 960/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3061 - acc: 0.9849 - val_loss: 0.6778 - val_acc: 0.7292\n",
      "Epoch 961/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3061 - acc: 0.9838 - val_loss: 0.6781 - val_acc: 0.7306\n",
      "Epoch 962/10000\n",
      "4259/4259 [==============================] - 2s 523us/step - loss: 0.3062 - acc: 0.9835 - val_loss: 0.6786 - val_acc: 0.7295\n",
      "Epoch 963/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3062 - acc: 0.9834 - val_loss: 0.6788 - val_acc: 0.7321\n",
      "Epoch 964/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3064 - acc: 0.9824 - val_loss: 0.6798 - val_acc: 0.7281\n",
      "Epoch 965/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3067 - acc: 0.9779 - val_loss: 0.6782 - val_acc: 0.7317\n",
      "Epoch 966/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3072 - acc: 0.9760 - val_loss: 0.6780 - val_acc: 0.7314\n",
      "Epoch 967/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3075 - acc: 0.9760 - val_loss: 0.6775 - val_acc: 0.7284\n",
      "Epoch 968/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3074 - acc: 0.9752 - val_loss: 0.6772 - val_acc: 0.7336\n",
      "Epoch 969/10000\n",
      "4259/4259 [==============================] - 2s 504us/step - loss: 0.3071 - acc: 0.9789 - val_loss: 0.6777 - val_acc: 0.7310\n",
      "Epoch 970/10000\n",
      "4259/4259 [==============================] - 2s 506us/step - loss: 0.3068 - acc: 0.9773 - val_loss: 0.6788 - val_acc: 0.7306\n",
      "Epoch 971/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3067 - acc: 0.9791 - val_loss: 0.6768 - val_acc: 0.7328\n",
      "Epoch 972/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3067 - acc: 0.9789 - val_loss: 0.6780 - val_acc: 0.7299\n",
      "Epoch 973/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3066 - acc: 0.9802 - val_loss: 0.6751 - val_acc: 0.7292\n",
      "Epoch 974/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3067 - acc: 0.9805 - val_loss: 0.6748 - val_acc: 0.7317\n",
      "Epoch 975/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3067 - acc: 0.9775 - val_loss: 0.6767 - val_acc: 0.7306\n",
      "Epoch 976/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3067 - acc: 0.9786 - val_loss: 0.6755 - val_acc: 0.7317\n",
      "Epoch 977/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3068 - acc: 0.9786 - val_loss: 0.6756 - val_acc: 0.7303\n",
      "Epoch 978/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3072 - acc: 0.9750 - val_loss: 0.6766 - val_acc: 0.7281\n",
      "Epoch 979/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3073 - acc: 0.9757 - val_loss: 0.6789 - val_acc: 0.7292\n",
      "Epoch 980/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3075 - acc: 0.9746 - val_loss: 0.6737 - val_acc: 0.7321\n",
      "Epoch 981/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3072 - acc: 0.9753 - val_loss: 0.6731 - val_acc: 0.7292\n",
      "Epoch 982/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3071 - acc: 0.9764 - val_loss: 0.6750 - val_acc: 0.7222\n",
      "Epoch 983/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3069 - acc: 0.9781 - val_loss: 0.6730 - val_acc: 0.7303\n",
      "Epoch 984/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3069 - acc: 0.9782 - val_loss: 0.6749 - val_acc: 0.7336\n",
      "Epoch 985/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3066 - acc: 0.9785 - val_loss: 0.6746 - val_acc: 0.7270\n",
      "Epoch 986/10000\n",
      "4259/4259 [==============================] - 2s 504us/step - loss: 0.3066 - acc: 0.9807 - val_loss: 0.6737 - val_acc: 0.7306\n",
      "Epoch 987/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3065 - acc: 0.9804 - val_loss: 0.6740 - val_acc: 0.7299\n",
      "Epoch 988/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3067 - acc: 0.9800 - val_loss: 0.6752 - val_acc: 0.7295\n",
      "Epoch 989/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3069 - acc: 0.9753 - val_loss: 0.6734 - val_acc: 0.7303\n",
      "Epoch 990/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3070 - acc: 0.9765 - val_loss: 0.6755 - val_acc: 0.7303\n",
      "Epoch 991/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3072 - acc: 0.9753 - val_loss: 0.6736 - val_acc: 0.7284\n",
      "Epoch 992/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3072 - acc: 0.9756 - val_loss: 0.6721 - val_acc: 0.7317\n",
      "Epoch 993/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3070 - acc: 0.9779 - val_loss: 0.6728 - val_acc: 0.7288\n",
      "Epoch 994/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3068 - acc: 0.9788 - val_loss: 0.6739 - val_acc: 0.7273\n",
      "Epoch 995/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3070 - acc: 0.9760 - val_loss: 0.6724 - val_acc: 0.7317\n",
      "Epoch 996/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3079 - acc: 0.9742 - val_loss: 0.6746 - val_acc: 0.7310\n",
      "Epoch 997/10000\n",
      "4259/4259 [==============================] - 2s 508us/step - loss: 0.3074 - acc: 0.9738 - val_loss: 0.6769 - val_acc: 0.7284\n",
      "Epoch 998/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3070 - acc: 0.9757 - val_loss: 0.6760 - val_acc: 0.7306\n",
      "Epoch 999/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3068 - acc: 0.9781 - val_loss: 0.6765 - val_acc: 0.7292\n",
      "Epoch 1000/10000\n",
      "4259/4259 [==============================] - 2s 542us/step - loss: 0.3065 - acc: 0.9798 - val_loss: 0.6767 - val_acc: 0.7292\n",
      "Epoch 1001/10000\n",
      "4259/4259 [==============================] - 2s 503us/step - loss: 0.3064 - acc: 0.9800 - val_loss: 0.6744 - val_acc: 0.7346\n",
      "Epoch 1002/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3063 - acc: 0.9818 - val_loss: 0.6755 - val_acc: 0.7306\n",
      "Epoch 1003/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3064 - acc: 0.9808 - val_loss: 0.6779 - val_acc: 0.7281\n",
      "Epoch 1004/10000\n",
      "4259/4259 [==============================] - 2s 511us/step - loss: 0.3064 - acc: 0.9786 - val_loss: 0.6769 - val_acc: 0.7336\n",
      "Epoch 1005/10000\n",
      "4259/4259 [==============================] - 2s 508us/step - loss: 0.3066 - acc: 0.9788 - val_loss: 0.6741 - val_acc: 0.7299\n",
      "Epoch 1006/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3067 - acc: 0.9776 - val_loss: 0.6758 - val_acc: 0.7270\n",
      "Epoch 1007/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3068 - acc: 0.9784 - val_loss: 0.6764 - val_acc: 0.7273\n",
      "Epoch 1008/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3069 - acc: 0.9764 - val_loss: 0.6746 - val_acc: 0.7244\n",
      "Epoch 1009/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3072 - acc: 0.9761 - val_loss: 0.6753 - val_acc: 0.7339\n",
      "Epoch 1010/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3074 - acc: 0.9766 - val_loss: 0.6720 - val_acc: 0.7310\n",
      "Epoch 1011/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3072 - acc: 0.9745 - val_loss: 0.6754 - val_acc: 0.7284\n",
      "Epoch 1012/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3070 - acc: 0.9786 - val_loss: 0.6723 - val_acc: 0.7295\n",
      "Epoch 1013/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3067 - acc: 0.9779 - val_loss: 0.6740 - val_acc: 0.7346\n",
      "Epoch 1014/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3066 - acc: 0.9793 - val_loss: 0.6738 - val_acc: 0.7270\n",
      "Epoch 1015/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3065 - acc: 0.9784 - val_loss: 0.6725 - val_acc: 0.7332\n",
      "Epoch 1016/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3064 - acc: 0.9800 - val_loss: 0.6735 - val_acc: 0.7321\n",
      "Epoch 1017/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3064 - acc: 0.9814 - val_loss: 0.6737 - val_acc: 0.7321\n",
      "Epoch 1018/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3071 - acc: 0.9766 - val_loss: 0.6739 - val_acc: 0.7295\n",
      "Epoch 1019/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3074 - acc: 0.9750 - val_loss: 0.6755 - val_acc: 0.7310\n",
      "Epoch 1020/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3075 - acc: 0.9735 - val_loss: 0.6745 - val_acc: 0.7299\n",
      "Epoch 1021/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3070 - acc: 0.9771 - val_loss: 0.6732 - val_acc: 0.7288\n",
      "Epoch 1022/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3068 - acc: 0.9770 - val_loss: 0.6727 - val_acc: 0.7332\n",
      "Epoch 1023/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3067 - acc: 0.9776 - val_loss: 0.6746 - val_acc: 0.7303\n",
      "Epoch 1024/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3065 - acc: 0.9797 - val_loss: 0.6725 - val_acc: 0.7317\n",
      "Epoch 1025/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3064 - acc: 0.9794 - val_loss: 0.6725 - val_acc: 0.7292\n",
      "Epoch 1026/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3064 - acc: 0.9792 - val_loss: 0.6730 - val_acc: 0.7343\n",
      "Epoch 1027/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3064 - acc: 0.9804 - val_loss: 0.6727 - val_acc: 0.7306\n",
      "Epoch 1028/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3066 - acc: 0.9788 - val_loss: 0.6725 - val_acc: 0.7292\n",
      "Epoch 1029/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3068 - acc: 0.9773 - val_loss: 0.6769 - val_acc: 0.7325\n",
      "Epoch 1030/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3069 - acc: 0.9765 - val_loss: 0.6743 - val_acc: 0.7306\n",
      "Epoch 1031/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3071 - acc: 0.9757 - val_loss: 0.6737 - val_acc: 0.7336\n",
      "Epoch 1032/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3071 - acc: 0.9744 - val_loss: 0.6749 - val_acc: 0.7317\n",
      "Epoch 1033/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3072 - acc: 0.9751 - val_loss: 0.6708 - val_acc: 0.7299\n",
      "Epoch 1034/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3070 - acc: 0.9760 - val_loss: 0.6750 - val_acc: 0.7343\n",
      "Epoch 1035/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3067 - acc: 0.9783 - val_loss: 0.6714 - val_acc: 0.7357\n",
      "Epoch 1036/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3065 - acc: 0.9803 - val_loss: 0.6734 - val_acc: 0.7321\n",
      "Epoch 1037/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3065 - acc: 0.9800 - val_loss: 0.6722 - val_acc: 0.7310\n",
      "Epoch 1038/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3067 - acc: 0.9777 - val_loss: 0.6741 - val_acc: 0.7317\n",
      "Epoch 1039/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3066 - acc: 0.9786 - val_loss: 0.6729 - val_acc: 0.7317\n",
      "Epoch 1040/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3069 - acc: 0.9782 - val_loss: 0.6705 - val_acc: 0.7350\n",
      "Epoch 1041/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3068 - acc: 0.9780 - val_loss: 0.6716 - val_acc: 0.7361\n",
      "Epoch 1042/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3068 - acc: 0.9796 - val_loss: 0.6721 - val_acc: 0.7336\n",
      "Epoch 1043/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3068 - acc: 0.9775 - val_loss: 0.6700 - val_acc: 0.7343\n",
      "Epoch 1044/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3067 - acc: 0.9772 - val_loss: 0.6736 - val_acc: 0.7336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1045/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3066 - acc: 0.9789 - val_loss: 0.6713 - val_acc: 0.7343\n",
      "Epoch 1046/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3066 - acc: 0.9791 - val_loss: 0.6722 - val_acc: 0.7368\n",
      "Epoch 1047/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3067 - acc: 0.9785 - val_loss: 0.6724 - val_acc: 0.7281\n",
      "Epoch 1048/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3067 - acc: 0.9778 - val_loss: 0.6717 - val_acc: 0.7314\n",
      "Epoch 1049/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3068 - acc: 0.9775 - val_loss: 0.6711 - val_acc: 0.7343\n",
      "Epoch 1050/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9762 - val_loss: 0.6704 - val_acc: 0.7346\n",
      "Epoch 1051/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3068 - acc: 0.9793 - val_loss: 0.6695 - val_acc: 0.7321\n",
      "Epoch 1052/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3068 - acc: 0.9793 - val_loss: 0.6714 - val_acc: 0.7339\n",
      "Epoch 1053/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3068 - acc: 0.9784 - val_loss: 0.6731 - val_acc: 0.7368\n",
      "Epoch 1054/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3068 - acc: 0.9772 - val_loss: 0.6721 - val_acc: 0.7328\n",
      "Epoch 1055/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3067 - acc: 0.9783 - val_loss: 0.6720 - val_acc: 0.7295\n",
      "Epoch 1056/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3068 - acc: 0.9788 - val_loss: 0.6706 - val_acc: 0.7292\n",
      "Epoch 1057/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3067 - acc: 0.9790 - val_loss: 0.6713 - val_acc: 0.7328\n",
      "Epoch 1058/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3067 - acc: 0.9795 - val_loss: 0.6704 - val_acc: 0.7376\n",
      "Epoch 1059/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3068 - acc: 0.9772 - val_loss: 0.6706 - val_acc: 0.7292\n",
      "Epoch 1060/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3066 - acc: 0.9807 - val_loss: 0.6740 - val_acc: 0.7339\n",
      "Epoch 1061/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3066 - acc: 0.9794 - val_loss: 0.6692 - val_acc: 0.7336\n",
      "Epoch 1062/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3067 - acc: 0.9784 - val_loss: 0.6725 - val_acc: 0.7336\n",
      "Epoch 1063/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3067 - acc: 0.9789 - val_loss: 0.6702 - val_acc: 0.7376\n",
      "Epoch 1064/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9783 - val_loss: 0.6711 - val_acc: 0.7332\n",
      "Epoch 1065/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3065 - acc: 0.9800 - val_loss: 0.6700 - val_acc: 0.7284\n",
      "Epoch 1066/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3068 - acc: 0.9764 - val_loss: 0.6698 - val_acc: 0.7321\n",
      "Epoch 1067/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9783 - val_loss: 0.6696 - val_acc: 0.7310\n",
      "Epoch 1068/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3068 - acc: 0.9763 - val_loss: 0.6710 - val_acc: 0.7346\n",
      "Epoch 1069/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3069 - acc: 0.9782 - val_loss: 0.6706 - val_acc: 0.7376\n",
      "Epoch 1070/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3068 - acc: 0.9782 - val_loss: 0.6695 - val_acc: 0.7343\n",
      "Epoch 1071/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3069 - acc: 0.9776 - val_loss: 0.6702 - val_acc: 0.7328\n",
      "Epoch 1072/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9799 - val_loss: 0.6696 - val_acc: 0.7332\n",
      "Epoch 1073/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3067 - acc: 0.9798 - val_loss: 0.6707 - val_acc: 0.7325\n",
      "Epoch 1074/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3066 - acc: 0.9794 - val_loss: 0.6709 - val_acc: 0.7354\n",
      "Epoch 1075/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3065 - acc: 0.9809 - val_loss: 0.6694 - val_acc: 0.7321\n",
      "Epoch 1076/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3065 - acc: 0.9811 - val_loss: 0.6694 - val_acc: 0.7332\n",
      "Epoch 1077/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3065 - acc: 0.9797 - val_loss: 0.6707 - val_acc: 0.7317\n",
      "Epoch 1078/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3079 - acc: 0.9761 - val_loss: 0.6845 - val_acc: 0.7211\n",
      "Epoch 1079/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3181 - acc: 0.9546 - val_loss: 0.6870 - val_acc: 0.7178\n",
      "Epoch 1080/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3161 - acc: 0.9591 - val_loss: 0.6813 - val_acc: 0.7317\n",
      "Epoch 1081/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3156 - acc: 0.9599 - val_loss: 0.6804 - val_acc: 0.7248\n",
      "Epoch 1082/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3101 - acc: 0.9690 - val_loss: 0.6772 - val_acc: 0.7277\n",
      "Epoch 1083/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3084 - acc: 0.9730 - val_loss: 0.6771 - val_acc: 0.7266\n",
      "Epoch 1084/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3072 - acc: 0.9767 - val_loss: 0.6758 - val_acc: 0.7273\n",
      "Epoch 1085/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3069 - acc: 0.9778 - val_loss: 0.6760 - val_acc: 0.7277\n",
      "Epoch 1086/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3066 - acc: 0.9790 - val_loss: 0.6759 - val_acc: 0.7266\n",
      "Epoch 1087/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3065 - acc: 0.9805 - val_loss: 0.6756 - val_acc: 0.7259\n",
      "Epoch 1088/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9808 - val_loss: 0.6748 - val_acc: 0.7255\n",
      "Epoch 1089/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3063 - acc: 0.9815 - val_loss: 0.6746 - val_acc: 0.7295\n",
      "Epoch 1090/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6744 - val_acc: 0.7266\n",
      "Epoch 1091/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9829 - val_loss: 0.6738 - val_acc: 0.7262\n",
      "Epoch 1092/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3061 - acc: 0.9837 - val_loss: 0.6746 - val_acc: 0.7273\n",
      "Epoch 1093/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9837 - val_loss: 0.6740 - val_acc: 0.7266\n",
      "Epoch 1094/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9839 - val_loss: 0.6740 - val_acc: 0.7266\n",
      "Epoch 1095/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3061 - acc: 0.9841 - val_loss: 0.6742 - val_acc: 0.7288\n",
      "Epoch 1096/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9843 - val_loss: 0.6737 - val_acc: 0.7270\n",
      "Epoch 1097/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6742 - val_acc: 0.7259\n",
      "Epoch 1098/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3060 - acc: 0.9854 - val_loss: 0.6738 - val_acc: 0.7273\n",
      "Epoch 1099/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3060 - acc: 0.9846 - val_loss: 0.6738 - val_acc: 0.7270\n",
      "Epoch 1100/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9851 - val_loss: 0.6738 - val_acc: 0.7270\n",
      "Epoch 1101/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3060 - acc: 0.9855 - val_loss: 0.6742 - val_acc: 0.7281\n",
      "Epoch 1102/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3060 - acc: 0.9849 - val_loss: 0.6739 - val_acc: 0.7281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1103/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3061 - acc: 0.9855 - val_loss: 0.6744 - val_acc: 0.7277\n",
      "Epoch 1104/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3061 - acc: 0.9834 - val_loss: 0.6746 - val_acc: 0.7277\n",
      "Epoch 1105/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9822 - val_loss: 0.6759 - val_acc: 0.7321\n",
      "Epoch 1106/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3142 - acc: 0.9654 - val_loss: 0.6961 - val_acc: 0.7240\n",
      "Epoch 1107/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3208 - acc: 0.9512 - val_loss: 0.6861 - val_acc: 0.7230\n",
      "Epoch 1108/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3134 - acc: 0.9619 - val_loss: 0.6734 - val_acc: 0.7237\n",
      "Epoch 1109/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3095 - acc: 0.9690 - val_loss: 0.6735 - val_acc: 0.7248\n",
      "Epoch 1110/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3078 - acc: 0.9737 - val_loss: 0.6746 - val_acc: 0.7266\n",
      "Epoch 1111/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3072 - acc: 0.9763 - val_loss: 0.6756 - val_acc: 0.7259\n",
      "Epoch 1112/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3069 - acc: 0.9772 - val_loss: 0.6764 - val_acc: 0.7255\n",
      "Epoch 1113/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3067 - acc: 0.9787 - val_loss: 0.6760 - val_acc: 0.7277\n",
      "Epoch 1114/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9807 - val_loss: 0.6759 - val_acc: 0.7284\n",
      "Epoch 1115/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9814 - val_loss: 0.6757 - val_acc: 0.7251\n",
      "Epoch 1116/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3063 - acc: 0.9825 - val_loss: 0.6757 - val_acc: 0.7277\n",
      "Epoch 1117/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3063 - acc: 0.9828 - val_loss: 0.6759 - val_acc: 0.7292\n",
      "Epoch 1118/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9829 - val_loss: 0.6759 - val_acc: 0.7270\n",
      "Epoch 1119/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9834 - val_loss: 0.6761 - val_acc: 0.7277\n",
      "Epoch 1120/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6762 - val_acc: 0.7277\n",
      "Epoch 1121/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9845 - val_loss: 0.6768 - val_acc: 0.7266\n",
      "Epoch 1122/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3061 - acc: 0.9843 - val_loss: 0.6761 - val_acc: 0.7273\n",
      "Epoch 1123/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3061 - acc: 0.9849 - val_loss: 0.6765 - val_acc: 0.7273\n",
      "Epoch 1124/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9846 - val_loss: 0.6764 - val_acc: 0.7270\n",
      "Epoch 1125/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3061 - acc: 0.9844 - val_loss: 0.6762 - val_acc: 0.7277\n",
      "Epoch 1126/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3060 - acc: 0.9854 - val_loss: 0.6762 - val_acc: 0.7284\n",
      "Epoch 1127/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3061 - acc: 0.9841 - val_loss: 0.6765 - val_acc: 0.7295\n",
      "Epoch 1128/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3061 - acc: 0.9843 - val_loss: 0.6760 - val_acc: 0.7284\n",
      "Epoch 1129/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3061 - acc: 0.9842 - val_loss: 0.6757 - val_acc: 0.7270\n",
      "Epoch 1130/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3062 - acc: 0.9826 - val_loss: 0.6760 - val_acc: 0.7284\n",
      "Epoch 1131/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3062 - acc: 0.9832 - val_loss: 0.6754 - val_acc: 0.7266\n",
      "Epoch 1132/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3063 - acc: 0.9813 - val_loss: 0.6750 - val_acc: 0.7281\n",
      "Epoch 1133/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9809 - val_loss: 0.6744 - val_acc: 0.7317\n",
      "Epoch 1134/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9805 - val_loss: 0.6750 - val_acc: 0.7284\n",
      "Epoch 1135/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3066 - acc: 0.9797 - val_loss: 0.6752 - val_acc: 0.7284\n",
      "Epoch 1136/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3067 - acc: 0.9775 - val_loss: 0.6738 - val_acc: 0.7292\n",
      "Epoch 1137/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3067 - acc: 0.9789 - val_loss: 0.6735 - val_acc: 0.7346\n",
      "Epoch 1138/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3067 - acc: 0.9782 - val_loss: 0.6729 - val_acc: 0.7255\n",
      "Epoch 1139/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3066 - acc: 0.9790 - val_loss: 0.6745 - val_acc: 0.7310\n",
      "Epoch 1140/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9791 - val_loss: 0.6691 - val_acc: 0.7314\n",
      "Epoch 1141/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9782 - val_loss: 0.6714 - val_acc: 0.7270\n",
      "Epoch 1142/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9800 - val_loss: 0.6698 - val_acc: 0.7310\n",
      "Epoch 1143/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9788 - val_loss: 0.6703 - val_acc: 0.7299\n",
      "Epoch 1144/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9787 - val_loss: 0.6714 - val_acc: 0.7332\n",
      "Epoch 1145/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3069 - acc: 0.9779 - val_loss: 0.6690 - val_acc: 0.7317\n",
      "Epoch 1146/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3070 - acc: 0.9757 - val_loss: 0.6705 - val_acc: 0.7273\n",
      "Epoch 1147/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3072 - acc: 0.9755 - val_loss: 0.6682 - val_acc: 0.7284\n",
      "Epoch 1148/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3070 - acc: 0.9754 - val_loss: 0.6707 - val_acc: 0.7328\n",
      "Epoch 1149/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3069 - acc: 0.9782 - val_loss: 0.6669 - val_acc: 0.7325\n",
      "Epoch 1150/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9772 - val_loss: 0.6703 - val_acc: 0.7357\n",
      "Epoch 1151/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3067 - acc: 0.9794 - val_loss: 0.6667 - val_acc: 0.7314\n",
      "Epoch 1152/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9785 - val_loss: 0.6661 - val_acc: 0.7343\n",
      "Epoch 1153/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9797 - val_loss: 0.6684 - val_acc: 0.7284\n",
      "Epoch 1154/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3063 - acc: 0.9815 - val_loss: 0.6659 - val_acc: 0.7299\n",
      "Epoch 1155/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9802 - val_loss: 0.6667 - val_acc: 0.7284\n",
      "Epoch 1156/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9803 - val_loss: 0.6664 - val_acc: 0.7306\n",
      "Epoch 1157/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9779 - val_loss: 0.6660 - val_acc: 0.7303\n",
      "Epoch 1158/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3068 - acc: 0.9780 - val_loss: 0.6670 - val_acc: 0.7310\n",
      "Epoch 1159/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3067 - acc: 0.9773 - val_loss: 0.6646 - val_acc: 0.7314\n",
      "Epoch 1160/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3069 - acc: 0.9769 - val_loss: 0.6649 - val_acc: 0.7303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1161/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3069 - acc: 0.9756 - val_loss: 0.6668 - val_acc: 0.7317\n",
      "Epoch 1162/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3067 - acc: 0.9793 - val_loss: 0.6663 - val_acc: 0.7303\n",
      "Epoch 1163/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9777 - val_loss: 0.6666 - val_acc: 0.7317\n",
      "Epoch 1164/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3065 - acc: 0.9802 - val_loss: 0.6671 - val_acc: 0.7295\n",
      "Epoch 1165/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3065 - acc: 0.9804 - val_loss: 0.6658 - val_acc: 0.7299\n",
      "Epoch 1166/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3064 - acc: 0.9799 - val_loss: 0.6662 - val_acc: 0.7332\n",
      "Epoch 1167/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3064 - acc: 0.9810 - val_loss: 0.6654 - val_acc: 0.7343\n",
      "Epoch 1168/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9806 - val_loss: 0.6644 - val_acc: 0.7314\n",
      "Epoch 1169/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3067 - acc: 0.9790 - val_loss: 0.6645 - val_acc: 0.7262\n",
      "Epoch 1170/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3068 - acc: 0.9779 - val_loss: 0.6647 - val_acc: 0.7332\n",
      "Epoch 1171/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3068 - acc: 0.9780 - val_loss: 0.6657 - val_acc: 0.7281\n",
      "Epoch 1172/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3070 - acc: 0.9775 - val_loss: 0.6674 - val_acc: 0.7365\n",
      "Epoch 1173/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3166 - acc: 0.9596 - val_loss: 0.6974 - val_acc: 0.7277\n",
      "Epoch 1174/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3231 - acc: 0.9443 - val_loss: 0.6797 - val_acc: 0.7416\n",
      "Epoch 1175/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3170 - acc: 0.9570 - val_loss: 0.6858 - val_acc: 0.7259\n",
      "Epoch 1176/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3120 - acc: 0.9662 - val_loss: 0.6792 - val_acc: 0.7303\n",
      "Epoch 1177/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3097 - acc: 0.9725 - val_loss: 0.6808 - val_acc: 0.7284\n",
      "Epoch 1178/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3089 - acc: 0.9753 - val_loss: 0.6788 - val_acc: 0.7281\n",
      "Epoch 1179/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3076 - acc: 0.9772 - val_loss: 0.6776 - val_acc: 0.7270\n",
      "Epoch 1180/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3072 - acc: 0.9790 - val_loss: 0.6780 - val_acc: 0.7273\n",
      "Epoch 1181/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3069 - acc: 0.9806 - val_loss: 0.6780 - val_acc: 0.7281\n",
      "Epoch 1182/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3067 - acc: 0.9811 - val_loss: 0.6775 - val_acc: 0.7295\n",
      "Epoch 1183/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9816 - val_loss: 0.6772 - val_acc: 0.7292\n",
      "Epoch 1184/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9813 - val_loss: 0.6771 - val_acc: 0.7295\n",
      "Epoch 1185/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3064 - acc: 0.9821 - val_loss: 0.6765 - val_acc: 0.7317\n",
      "Epoch 1186/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3063 - acc: 0.9824 - val_loss: 0.6765 - val_acc: 0.7314\n",
      "Epoch 1187/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3063 - acc: 0.9836 - val_loss: 0.6769 - val_acc: 0.7303\n",
      "Epoch 1188/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3063 - acc: 0.9824 - val_loss: 0.6763 - val_acc: 0.7310\n",
      "Epoch 1189/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9833 - val_loss: 0.6766 - val_acc: 0.7314\n",
      "Epoch 1190/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9843 - val_loss: 0.6766 - val_acc: 0.7321\n",
      "Epoch 1191/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3062 - acc: 0.9851 - val_loss: 0.6765 - val_acc: 0.7317\n",
      "Epoch 1192/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3061 - acc: 0.9843 - val_loss: 0.6760 - val_acc: 0.7292\n",
      "Epoch 1193/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9853 - val_loss: 0.6768 - val_acc: 0.7292\n",
      "Epoch 1194/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9849 - val_loss: 0.6768 - val_acc: 0.7310\n",
      "Epoch 1195/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3061 - acc: 0.9847 - val_loss: 0.6768 - val_acc: 0.7288\n",
      "Epoch 1196/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9846 - val_loss: 0.6787 - val_acc: 0.7303\n",
      "Epoch 1197/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3064 - acc: 0.9827 - val_loss: 0.6782 - val_acc: 0.7303\n",
      "Epoch 1198/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3062 - acc: 0.9829 - val_loss: 0.6779 - val_acc: 0.7295\n",
      "Epoch 1199/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9836 - val_loss: 0.6776 - val_acc: 0.7284\n",
      "Epoch 1200/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3061 - acc: 0.9852 - val_loss: 0.6775 - val_acc: 0.7306\n",
      "Epoch 1201/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3061 - acc: 0.9838 - val_loss: 0.6766 - val_acc: 0.7284\n",
      "Epoch 1202/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3061 - acc: 0.9847 - val_loss: 0.6770 - val_acc: 0.7284\n",
      "Epoch 1203/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3061 - acc: 0.9836 - val_loss: 0.6767 - val_acc: 0.7292\n",
      "Epoch 1204/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3062 - acc: 0.9839 - val_loss: 0.6769 - val_acc: 0.7295\n",
      "Epoch 1205/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3063 - acc: 0.9827 - val_loss: 0.6764 - val_acc: 0.7292\n",
      "Epoch 1206/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9807 - val_loss: 0.6776 - val_acc: 0.7314\n",
      "Epoch 1207/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9804 - val_loss: 0.6765 - val_acc: 0.7288\n",
      "Epoch 1208/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9800 - val_loss: 0.6770 - val_acc: 0.7284\n",
      "Epoch 1209/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3067 - acc: 0.9782 - val_loss: 0.6765 - val_acc: 0.7266\n",
      "Epoch 1210/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3067 - acc: 0.9785 - val_loss: 0.6753 - val_acc: 0.7284\n",
      "Epoch 1211/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9774 - val_loss: 0.6763 - val_acc: 0.7262\n",
      "Epoch 1212/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3067 - acc: 0.9786 - val_loss: 0.6747 - val_acc: 0.7325\n",
      "Epoch 1213/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3067 - acc: 0.9775 - val_loss: 0.6754 - val_acc: 0.7273\n",
      "Epoch 1214/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9790 - val_loss: 0.6752 - val_acc: 0.7306\n",
      "Epoch 1215/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3066 - acc: 0.9799 - val_loss: 0.6734 - val_acc: 0.7284\n",
      "Epoch 1216/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9792 - val_loss: 0.6756 - val_acc: 0.7303\n",
      "Epoch 1217/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3074 - acc: 0.9768 - val_loss: 0.6749 - val_acc: 0.7251\n",
      "Epoch 1218/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3074 - acc: 0.9753 - val_loss: 0.6757 - val_acc: 0.7262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1219/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3070 - acc: 0.9774 - val_loss: 0.6746 - val_acc: 0.7248\n",
      "Epoch 1220/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3065 - acc: 0.9804 - val_loss: 0.6746 - val_acc: 0.7240\n",
      "Epoch 1221/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9807 - val_loss: 0.6761 - val_acc: 0.7288\n",
      "Epoch 1222/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9815 - val_loss: 0.6742 - val_acc: 0.7310\n",
      "Epoch 1223/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9806 - val_loss: 0.6742 - val_acc: 0.7237\n",
      "Epoch 1224/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9816 - val_loss: 0.6751 - val_acc: 0.7295\n",
      "Epoch 1225/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3063 - acc: 0.9810 - val_loss: 0.6739 - val_acc: 0.7284\n",
      "Epoch 1226/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3063 - acc: 0.9833 - val_loss: 0.6727 - val_acc: 0.7295\n",
      "Epoch 1227/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3063 - acc: 0.9810 - val_loss: 0.6753 - val_acc: 0.7325\n",
      "Epoch 1228/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3067 - acc: 0.9806 - val_loss: 0.6716 - val_acc: 0.7314\n",
      "Epoch 1229/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3069 - acc: 0.9790 - val_loss: 0.6738 - val_acc: 0.7208\n",
      "Epoch 1230/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3071 - acc: 0.9765 - val_loss: 0.6736 - val_acc: 0.7299\n",
      "Epoch 1231/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3071 - acc: 0.9752 - val_loss: 0.6736 - val_acc: 0.7284\n",
      "Epoch 1232/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3070 - acc: 0.9772 - val_loss: 0.6713 - val_acc: 0.7310\n",
      "Epoch 1233/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9775 - val_loss: 0.6709 - val_acc: 0.7288\n",
      "Epoch 1234/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9794 - val_loss: 0.6717 - val_acc: 0.7354\n",
      "Epoch 1235/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9810 - val_loss: 0.6717 - val_acc: 0.7310\n",
      "Epoch 1236/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9818 - val_loss: 0.6731 - val_acc: 0.7310\n",
      "Epoch 1237/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9802 - val_loss: 0.6707 - val_acc: 0.7299\n",
      "Epoch 1238/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3067 - acc: 0.9783 - val_loss: 0.6732 - val_acc: 0.7314\n",
      "Epoch 1239/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3067 - acc: 0.9782 - val_loss: 0.6691 - val_acc: 0.7292\n",
      "Epoch 1240/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3067 - acc: 0.9784 - val_loss: 0.6727 - val_acc: 0.7299\n",
      "Epoch 1241/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3066 - acc: 0.9793 - val_loss: 0.6709 - val_acc: 0.7317\n",
      "Epoch 1242/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9802 - val_loss: 0.6727 - val_acc: 0.7259\n",
      "Epoch 1243/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3065 - acc: 0.9807 - val_loss: 0.6695 - val_acc: 0.7288\n",
      "Epoch 1244/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9800 - val_loss: 0.6728 - val_acc: 0.7281\n",
      "Epoch 1245/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9781 - val_loss: 0.6684 - val_acc: 0.7295\n",
      "Epoch 1246/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9782 - val_loss: 0.6723 - val_acc: 0.7281\n",
      "Epoch 1247/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9787 - val_loss: 0.6674 - val_acc: 0.7273\n",
      "Epoch 1248/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9793 - val_loss: 0.6698 - val_acc: 0.7266\n",
      "Epoch 1249/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3067 - acc: 0.9795 - val_loss: 0.6704 - val_acc: 0.7281\n",
      "Epoch 1250/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3070 - acc: 0.9776 - val_loss: 0.6713 - val_acc: 0.7357\n",
      "Epoch 1251/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3094 - acc: 0.9710 - val_loss: 0.6720 - val_acc: 0.7343\n",
      "Epoch 1252/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3166 - acc: 0.9584 - val_loss: 0.6803 - val_acc: 0.7211\n",
      "Epoch 1253/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3141 - acc: 0.9615 - val_loss: 0.6729 - val_acc: 0.7200\n",
      "Epoch 1254/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3138 - acc: 0.9647 - val_loss: 0.6746 - val_acc: 0.7226\n",
      "Epoch 1255/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3115 - acc: 0.9681 - val_loss: 0.6636 - val_acc: 0.7321\n",
      "Epoch 1256/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3088 - acc: 0.9739 - val_loss: 0.6666 - val_acc: 0.7292\n",
      "Epoch 1257/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3073 - acc: 0.9775 - val_loss: 0.6640 - val_acc: 0.7266\n",
      "Epoch 1258/10000\n",
      "4259/4259 [==============================] - 2s 510us/step - loss: 0.3069 - acc: 0.9791 - val_loss: 0.6648 - val_acc: 0.7281\n",
      "Epoch 1259/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3066 - acc: 0.9801 - val_loss: 0.6644 - val_acc: 0.7284\n",
      "Epoch 1260/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3065 - acc: 0.9812 - val_loss: 0.6648 - val_acc: 0.7277\n",
      "Epoch 1261/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3064 - acc: 0.9810 - val_loss: 0.6662 - val_acc: 0.7299\n",
      "Epoch 1262/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3064 - acc: 0.9819 - val_loss: 0.6631 - val_acc: 0.7299\n",
      "Epoch 1263/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3063 - acc: 0.9827 - val_loss: 0.6640 - val_acc: 0.7288\n",
      "Epoch 1264/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9828 - val_loss: 0.6637 - val_acc: 0.7277\n",
      "Epoch 1265/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3062 - acc: 0.9830 - val_loss: 0.6637 - val_acc: 0.7277\n",
      "Epoch 1266/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9836 - val_loss: 0.6641 - val_acc: 0.7288\n",
      "Epoch 1267/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3061 - acc: 0.9842 - val_loss: 0.6640 - val_acc: 0.7303\n",
      "Epoch 1268/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3061 - acc: 0.9849 - val_loss: 0.6656 - val_acc: 0.7288\n",
      "Epoch 1269/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9854 - val_loss: 0.6651 - val_acc: 0.7306\n",
      "Epoch 1270/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3060 - acc: 0.9849 - val_loss: 0.6657 - val_acc: 0.7303\n",
      "Epoch 1271/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9851 - val_loss: 0.6656 - val_acc: 0.7281\n",
      "Epoch 1272/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9864 - val_loss: 0.6660 - val_acc: 0.7303\n",
      "Epoch 1273/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9860 - val_loss: 0.6651 - val_acc: 0.7299\n",
      "Epoch 1274/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9861 - val_loss: 0.6655 - val_acc: 0.7292\n",
      "Epoch 1275/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3060 - acc: 0.9855 - val_loss: 0.6657 - val_acc: 0.7310\n",
      "Epoch 1276/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9862 - val_loss: 0.6661 - val_acc: 0.7284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1277/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3060 - acc: 0.9853 - val_loss: 0.6658 - val_acc: 0.7288\n",
      "Epoch 1278/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9855 - val_loss: 0.6660 - val_acc: 0.7299\n",
      "Epoch 1279/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3061 - acc: 0.9851 - val_loss: 0.6658 - val_acc: 0.7273\n",
      "Epoch 1280/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3062 - acc: 0.9843 - val_loss: 0.6661 - val_acc: 0.7292\n",
      "Epoch 1281/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3064 - acc: 0.9811 - val_loss: 0.6654 - val_acc: 0.7303\n",
      "Epoch 1282/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3065 - acc: 0.9811 - val_loss: 0.6654 - val_acc: 0.7314\n",
      "Epoch 1283/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3068 - acc: 0.9811 - val_loss: 0.6620 - val_acc: 0.7314\n",
      "Epoch 1284/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3068 - acc: 0.9798 - val_loss: 0.6633 - val_acc: 0.7273\n",
      "Epoch 1285/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3067 - acc: 0.9791 - val_loss: 0.6643 - val_acc: 0.7270\n",
      "Epoch 1286/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3068 - acc: 0.9789 - val_loss: 0.6630 - val_acc: 0.7295\n",
      "Epoch 1287/10000\n",
      "4259/4259 [==============================] - 2s 501us/step - loss: 0.3066 - acc: 0.9790 - val_loss: 0.6617 - val_acc: 0.7292\n",
      "Epoch 1288/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3066 - acc: 0.9807 - val_loss: 0.6640 - val_acc: 0.7277\n",
      "Epoch 1289/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3064 - acc: 0.9784 - val_loss: 0.6605 - val_acc: 0.7336\n",
      "Epoch 1290/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3064 - acc: 0.9816 - val_loss: 0.6616 - val_acc: 0.7303\n",
      "Epoch 1291/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3064 - acc: 0.9812 - val_loss: 0.6631 - val_acc: 0.7310\n",
      "Epoch 1292/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3063 - acc: 0.9819 - val_loss: 0.6612 - val_acc: 0.7314\n",
      "Epoch 1293/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3063 - acc: 0.9817 - val_loss: 0.6639 - val_acc: 0.7303\n",
      "Epoch 1294/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3069 - acc: 0.9786 - val_loss: 0.6629 - val_acc: 0.7295\n",
      "Epoch 1295/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3068 - acc: 0.9777 - val_loss: 0.6637 - val_acc: 0.7266\n",
      "Epoch 1296/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3068 - acc: 0.9787 - val_loss: 0.6629 - val_acc: 0.7270\n",
      "Epoch 1297/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3068 - acc: 0.9790 - val_loss: 0.6625 - val_acc: 0.7273\n",
      "Epoch 1298/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3065 - acc: 0.9774 - val_loss: 0.6643 - val_acc: 0.7295\n",
      "Epoch 1299/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3064 - acc: 0.9810 - val_loss: 0.6621 - val_acc: 0.7306\n",
      "Epoch 1300/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3063 - acc: 0.9817 - val_loss: 0.6619 - val_acc: 0.7295\n",
      "Epoch 1301/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3063 - acc: 0.9817 - val_loss: 0.6621 - val_acc: 0.7292\n",
      "Epoch 1302/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3064 - acc: 0.9802 - val_loss: 0.6623 - val_acc: 0.7284\n",
      "Epoch 1303/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3064 - acc: 0.9798 - val_loss: 0.6611 - val_acc: 0.7295\n",
      "Epoch 1304/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3065 - acc: 0.9797 - val_loss: 0.6634 - val_acc: 0.7270\n",
      "Epoch 1305/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3066 - acc: 0.9779 - val_loss: 0.6634 - val_acc: 0.7273\n",
      "Epoch 1306/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3067 - acc: 0.9783 - val_loss: 0.6631 - val_acc: 0.7288\n",
      "Epoch 1307/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3067 - acc: 0.9779 - val_loss: 0.6627 - val_acc: 0.7288\n",
      "Epoch 1308/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.3069 - acc: 0.9776 - val_loss: 0.6662 - val_acc: 0.7266\n",
      "Epoch 1309/10000\n",
      "4259/4259 [==============================] - 2s 505us/step - loss: 0.3074 - acc: 0.9763 - val_loss: 0.6658 - val_acc: 0.7292\n",
      "Epoch 1310/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3136 - acc: 0.9694 - val_loss: 0.6819 - val_acc: 0.7138\n",
      "Epoch 1311/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3244 - acc: 0.9479 - val_loss: 0.6811 - val_acc: 0.7299\n",
      "Epoch 1312/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3135 - acc: 0.9625 - val_loss: 0.6819 - val_acc: 0.7292\n",
      "Epoch 1313/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3096 - acc: 0.9672 - val_loss: 0.6724 - val_acc: 0.7299\n",
      "Epoch 1314/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3082 - acc: 0.9723 - val_loss: 0.6722 - val_acc: 0.7295\n",
      "Epoch 1315/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3076 - acc: 0.9744 - val_loss: 0.6729 - val_acc: 0.7273\n",
      "Epoch 1316/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3072 - acc: 0.9755 - val_loss: 0.6717 - val_acc: 0.7306\n",
      "Epoch 1317/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3070 - acc: 0.9775 - val_loss: 0.6707 - val_acc: 0.7306\n",
      "Epoch 1318/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3068 - acc: 0.9782 - val_loss: 0.6708 - val_acc: 0.7295\n",
      "Epoch 1319/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3066 - acc: 0.9789 - val_loss: 0.6706 - val_acc: 0.7295\n",
      "Epoch 1320/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3066 - acc: 0.9808 - val_loss: 0.6705 - val_acc: 0.7303\n",
      "Epoch 1321/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3065 - acc: 0.9806 - val_loss: 0.6708 - val_acc: 0.7292\n",
      "Epoch 1322/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3064 - acc: 0.9815 - val_loss: 0.6700 - val_acc: 0.7299\n",
      "Epoch 1323/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3063 - acc: 0.9822 - val_loss: 0.6701 - val_acc: 0.7310\n",
      "Epoch 1324/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3063 - acc: 0.9825 - val_loss: 0.6695 - val_acc: 0.7292\n",
      "Epoch 1325/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3062 - acc: 0.9823 - val_loss: 0.6696 - val_acc: 0.7303\n",
      "Epoch 1326/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3062 - acc: 0.9833 - val_loss: 0.6691 - val_acc: 0.7306\n",
      "Epoch 1327/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3062 - acc: 0.9827 - val_loss: 0.6695 - val_acc: 0.7303\n",
      "Epoch 1328/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3061 - acc: 0.9836 - val_loss: 0.6688 - val_acc: 0.7317\n",
      "Epoch 1329/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3061 - acc: 0.9836 - val_loss: 0.6698 - val_acc: 0.7306\n",
      "Epoch 1330/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3061 - acc: 0.9843 - val_loss: 0.6692 - val_acc: 0.7321\n",
      "Epoch 1331/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9839 - val_loss: 0.6695 - val_acc: 0.7310\n",
      "Epoch 1332/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3061 - acc: 0.9843 - val_loss: 0.6689 - val_acc: 0.7306\n",
      "Epoch 1333/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3061 - acc: 0.9847 - val_loss: 0.6693 - val_acc: 0.7284\n",
      "Epoch 1334/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9850 - val_loss: 0.6692 - val_acc: 0.7317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1335/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3061 - acc: 0.9853 - val_loss: 0.6695 - val_acc: 0.7288\n",
      "Epoch 1336/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3061 - acc: 0.9847 - val_loss: 0.6687 - val_acc: 0.7292\n",
      "Epoch 1337/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9848 - val_loss: 0.6699 - val_acc: 0.7292\n",
      "Epoch 1338/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9841 - val_loss: 0.6693 - val_acc: 0.7281\n",
      "Epoch 1339/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9844 - val_loss: 0.6691 - val_acc: 0.7292\n",
      "Epoch 1340/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3061 - acc: 0.9846 - val_loss: 0.6698 - val_acc: 0.7317\n",
      "Epoch 1341/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6686 - val_acc: 0.7325\n",
      "Epoch 1342/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3062 - acc: 0.9828 - val_loss: 0.6709 - val_acc: 0.7306\n",
      "Epoch 1343/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3063 - acc: 0.9827 - val_loss: 0.6697 - val_acc: 0.7281\n",
      "Epoch 1344/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3065 - acc: 0.9802 - val_loss: 0.6698 - val_acc: 0.7281\n",
      "Epoch 1345/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3067 - acc: 0.9788 - val_loss: 0.6688 - val_acc: 0.7292\n",
      "Epoch 1346/10000\n",
      "4259/4259 [==============================] - 2s 511us/step - loss: 0.3067 - acc: 0.9789 - val_loss: 0.6686 - val_acc: 0.7332\n",
      "Epoch 1347/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3067 - acc: 0.9793 - val_loss: 0.6701 - val_acc: 0.7262\n",
      "Epoch 1348/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3069 - acc: 0.9781 - val_loss: 0.6682 - val_acc: 0.7310\n",
      "Epoch 1349/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3066 - acc: 0.9781 - val_loss: 0.6685 - val_acc: 0.7303\n",
      "Epoch 1350/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3065 - acc: 0.9810 - val_loss: 0.6655 - val_acc: 0.7325\n",
      "Epoch 1351/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3065 - acc: 0.9803 - val_loss: 0.6667 - val_acc: 0.7321\n",
      "Epoch 1352/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9803 - val_loss: 0.6665 - val_acc: 0.7317\n",
      "Epoch 1353/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9818 - val_loss: 0.6645 - val_acc: 0.7317\n",
      "Epoch 1354/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3062 - acc: 0.9818 - val_loss: 0.6650 - val_acc: 0.7317\n",
      "Epoch 1355/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3063 - acc: 0.9823 - val_loss: 0.6655 - val_acc: 0.7295\n",
      "Epoch 1356/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3063 - acc: 0.9815 - val_loss: 0.6655 - val_acc: 0.7281\n",
      "Epoch 1357/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9809 - val_loss: 0.6637 - val_acc: 0.7310\n",
      "Epoch 1358/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3066 - acc: 0.9787 - val_loss: 0.6650 - val_acc: 0.7317\n",
      "Epoch 1359/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3067 - acc: 0.9783 - val_loss: 0.6671 - val_acc: 0.7266\n",
      "Epoch 1360/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3067 - acc: 0.9785 - val_loss: 0.6647 - val_acc: 0.7295\n",
      "Epoch 1361/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3066 - acc: 0.9791 - val_loss: 0.6647 - val_acc: 0.7317\n",
      "Epoch 1362/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9801 - val_loss: 0.6660 - val_acc: 0.7295\n",
      "Epoch 1363/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3065 - acc: 0.9803 - val_loss: 0.6632 - val_acc: 0.7332\n",
      "Epoch 1364/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3064 - acc: 0.9799 - val_loss: 0.6650 - val_acc: 0.7339\n",
      "Epoch 1365/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3064 - acc: 0.9815 - val_loss: 0.6647 - val_acc: 0.7325\n",
      "Epoch 1366/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3065 - acc: 0.9806 - val_loss: 0.6663 - val_acc: 0.7303\n",
      "Epoch 1367/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9798 - val_loss: 0.6638 - val_acc: 0.7310\n",
      "Epoch 1368/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9789 - val_loss: 0.6664 - val_acc: 0.7281\n",
      "Epoch 1369/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9789 - val_loss: 0.6652 - val_acc: 0.7295\n",
      "Epoch 1370/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3067 - acc: 0.9787 - val_loss: 0.6679 - val_acc: 0.7277\n",
      "Epoch 1371/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9795 - val_loss: 0.6651 - val_acc: 0.7295\n",
      "Epoch 1372/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9799 - val_loss: 0.6663 - val_acc: 0.7288\n",
      "Epoch 1373/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9805 - val_loss: 0.6666 - val_acc: 0.7266\n",
      "Epoch 1374/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3068 - acc: 0.9787 - val_loss: 0.6652 - val_acc: 0.7299\n",
      "Epoch 1375/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9777 - val_loss: 0.6669 - val_acc: 0.7277\n",
      "Epoch 1376/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3066 - acc: 0.9797 - val_loss: 0.6653 - val_acc: 0.7248\n",
      "Epoch 1377/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9804 - val_loss: 0.6659 - val_acc: 0.7314\n",
      "Epoch 1378/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3063 - acc: 0.9804 - val_loss: 0.6654 - val_acc: 0.7306\n",
      "Epoch 1379/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3063 - acc: 0.9819 - val_loss: 0.6662 - val_acc: 0.7310\n",
      "Epoch 1380/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3062 - acc: 0.9824 - val_loss: 0.6644 - val_acc: 0.7310\n",
      "Epoch 1381/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3065 - acc: 0.9794 - val_loss: 0.6651 - val_acc: 0.7284\n",
      "Epoch 1382/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3065 - acc: 0.9793 - val_loss: 0.6655 - val_acc: 0.7332\n",
      "Epoch 1383/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9804 - val_loss: 0.6641 - val_acc: 0.7314\n",
      "Epoch 1384/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3068 - acc: 0.9762 - val_loss: 0.6645 - val_acc: 0.7248\n",
      "Epoch 1385/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3069 - acc: 0.9770 - val_loss: 0.6651 - val_acc: 0.7273\n",
      "Epoch 1386/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3067 - acc: 0.9800 - val_loss: 0.6665 - val_acc: 0.7306\n",
      "Epoch 1387/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3065 - acc: 0.9785 - val_loss: 0.6676 - val_acc: 0.7314\n",
      "Epoch 1388/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9807 - val_loss: 0.6670 - val_acc: 0.7310\n",
      "Epoch 1389/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9804 - val_loss: 0.6669 - val_acc: 0.7295\n",
      "Epoch 1390/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9809 - val_loss: 0.6644 - val_acc: 0.7295\n",
      "Epoch 1391/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3063 - acc: 0.9799 - val_loss: 0.6631 - val_acc: 0.7295\n",
      "Epoch 1392/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3064 - acc: 0.9810 - val_loss: 0.6660 - val_acc: 0.7281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1393/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9808 - val_loss: 0.6649 - val_acc: 0.7281\n",
      "Epoch 1394/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9810 - val_loss: 0.6665 - val_acc: 0.7328\n",
      "Epoch 1395/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9782 - val_loss: 0.6640 - val_acc: 0.7292\n",
      "Epoch 1396/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9792 - val_loss: 0.6658 - val_acc: 0.7281\n",
      "Epoch 1397/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9792 - val_loss: 0.6628 - val_acc: 0.7270\n",
      "Epoch 1398/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9787 - val_loss: 0.6669 - val_acc: 0.7262\n",
      "Epoch 1399/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9795 - val_loss: 0.6680 - val_acc: 0.7317\n",
      "Epoch 1400/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3065 - acc: 0.9790 - val_loss: 0.6677 - val_acc: 0.7303\n",
      "Epoch 1401/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9805 - val_loss: 0.6663 - val_acc: 0.7288\n",
      "Epoch 1402/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3077 - acc: 0.9746 - val_loss: 0.6678 - val_acc: 0.7273\n",
      "Epoch 1403/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3177 - acc: 0.9584 - val_loss: 0.6852 - val_acc: 0.7171\n",
      "Epoch 1404/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3158 - acc: 0.9607 - val_loss: 0.6771 - val_acc: 0.7240\n",
      "Epoch 1405/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3102 - acc: 0.9685 - val_loss: 0.6716 - val_acc: 0.7284\n",
      "Epoch 1406/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3077 - acc: 0.9732 - val_loss: 0.6715 - val_acc: 0.7284\n",
      "Epoch 1407/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3070 - acc: 0.9763 - val_loss: 0.6705 - val_acc: 0.7284\n",
      "Epoch 1408/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3067 - acc: 0.9784 - val_loss: 0.6701 - val_acc: 0.7292\n",
      "Epoch 1409/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9786 - val_loss: 0.6698 - val_acc: 0.7281\n",
      "Epoch 1410/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9798 - val_loss: 0.6704 - val_acc: 0.7277\n",
      "Epoch 1411/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3063 - acc: 0.9804 - val_loss: 0.6703 - val_acc: 0.7292\n",
      "Epoch 1412/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3062 - acc: 0.9816 - val_loss: 0.6704 - val_acc: 0.7277\n",
      "Epoch 1413/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3062 - acc: 0.9821 - val_loss: 0.6708 - val_acc: 0.7281\n",
      "Epoch 1414/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6703 - val_acc: 0.7281\n",
      "Epoch 1415/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6706 - val_acc: 0.7273\n",
      "Epoch 1416/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6704 - val_acc: 0.7273\n",
      "Epoch 1417/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3060 - acc: 0.9835 - val_loss: 0.6705 - val_acc: 0.7277\n",
      "Epoch 1418/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3060 - acc: 0.9831 - val_loss: 0.6708 - val_acc: 0.7270\n",
      "Epoch 1419/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3060 - acc: 0.9838 - val_loss: 0.6705 - val_acc: 0.7284\n",
      "Epoch 1420/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6710 - val_acc: 0.7281\n",
      "Epoch 1421/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3060 - acc: 0.9849 - val_loss: 0.6711 - val_acc: 0.7270\n",
      "Epoch 1422/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6709 - val_acc: 0.7259\n",
      "Epoch 1423/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6710 - val_acc: 0.7266\n",
      "Epoch 1424/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3060 - acc: 0.9846 - val_loss: 0.6708 - val_acc: 0.7270\n",
      "Epoch 1425/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6714 - val_acc: 0.7255\n",
      "Epoch 1426/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3060 - acc: 0.9837 - val_loss: 0.6716 - val_acc: 0.7266\n",
      "Epoch 1427/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6714 - val_acc: 0.7288\n",
      "Epoch 1428/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6730 - val_acc: 0.7259\n",
      "Epoch 1429/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6716 - val_acc: 0.7281\n",
      "Epoch 1430/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3063 - acc: 0.9804 - val_loss: 0.6719 - val_acc: 0.7284\n",
      "Epoch 1431/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3064 - acc: 0.9804 - val_loss: 0.6719 - val_acc: 0.7251\n",
      "Epoch 1432/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9802 - val_loss: 0.6726 - val_acc: 0.7284\n",
      "Epoch 1433/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3065 - acc: 0.9789 - val_loss: 0.6716 - val_acc: 0.7266\n",
      "Epoch 1434/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9786 - val_loss: 0.6713 - val_acc: 0.7273\n",
      "Epoch 1435/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3068 - acc: 0.9775 - val_loss: 0.6725 - val_acc: 0.7255\n",
      "Epoch 1436/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3076 - acc: 0.9739 - val_loss: 0.6746 - val_acc: 0.7317\n",
      "Epoch 1437/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3124 - acc: 0.9615 - val_loss: 0.6788 - val_acc: 0.7277\n",
      "Epoch 1438/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3205 - acc: 0.9537 - val_loss: 0.6851 - val_acc: 0.7259\n",
      "Epoch 1439/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3159 - acc: 0.9610 - val_loss: 0.6826 - val_acc: 0.7175\n",
      "Epoch 1440/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3105 - acc: 0.9680 - val_loss: 0.6788 - val_acc: 0.7211\n",
      "Epoch 1441/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3089 - acc: 0.9719 - val_loss: 0.6793 - val_acc: 0.7266\n",
      "Epoch 1442/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3084 - acc: 0.9735 - val_loss: 0.6790 - val_acc: 0.7255\n",
      "Epoch 1443/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3075 - acc: 0.9756 - val_loss: 0.6797 - val_acc: 0.7244\n",
      "Epoch 1444/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3072 - acc: 0.9781 - val_loss: 0.6804 - val_acc: 0.7240\n",
      "Epoch 1445/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3070 - acc: 0.9788 - val_loss: 0.6792 - val_acc: 0.7262\n",
      "Epoch 1446/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3069 - acc: 0.9804 - val_loss: 0.6788 - val_acc: 0.7248\n",
      "Epoch 1447/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3068 - acc: 0.9804 - val_loss: 0.6783 - val_acc: 0.7262\n",
      "Epoch 1448/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3067 - acc: 0.9815 - val_loss: 0.6776 - val_acc: 0.7255\n",
      "Epoch 1449/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9815 - val_loss: 0.6778 - val_acc: 0.7273\n",
      "Epoch 1450/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9826 - val_loss: 0.6771 - val_acc: 0.7273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1451/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3065 - acc: 0.9826 - val_loss: 0.6771 - val_acc: 0.7281\n",
      "Epoch 1452/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9834 - val_loss: 0.6771 - val_acc: 0.7244\n",
      "Epoch 1453/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3065 - acc: 0.9837 - val_loss: 0.6769 - val_acc: 0.7284\n",
      "Epoch 1454/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9838 - val_loss: 0.6768 - val_acc: 0.7270\n",
      "Epoch 1455/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9837 - val_loss: 0.6770 - val_acc: 0.7266\n",
      "Epoch 1456/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9843 - val_loss: 0.6764 - val_acc: 0.7277\n",
      "Epoch 1457/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3064 - acc: 0.9845 - val_loss: 0.6769 - val_acc: 0.7281\n",
      "Epoch 1458/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9844 - val_loss: 0.6768 - val_acc: 0.7273\n",
      "Epoch 1459/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9839 - val_loss: 0.6764 - val_acc: 0.7281\n",
      "Epoch 1460/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3063 - acc: 0.9840 - val_loss: 0.6769 - val_acc: 0.7281\n",
      "Epoch 1461/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3063 - acc: 0.9846 - val_loss: 0.6769 - val_acc: 0.7284\n",
      "Epoch 1462/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3063 - acc: 0.9837 - val_loss: 0.6767 - val_acc: 0.7270\n",
      "Epoch 1463/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9836 - val_loss: 0.6777 - val_acc: 0.7277\n",
      "Epoch 1464/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9844 - val_loss: 0.6775 - val_acc: 0.7292\n",
      "Epoch 1465/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9835 - val_loss: 0.6772 - val_acc: 0.7270\n",
      "Epoch 1466/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9831 - val_loss: 0.6779 - val_acc: 0.7281\n",
      "Epoch 1467/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3064 - acc: 0.9825 - val_loss: 0.6769 - val_acc: 0.7292\n",
      "Epoch 1468/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3065 - acc: 0.9823 - val_loss: 0.6779 - val_acc: 0.7288\n",
      "Epoch 1469/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3067 - acc: 0.9805 - val_loss: 0.6756 - val_acc: 0.7262\n",
      "Epoch 1470/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3070 - acc: 0.9789 - val_loss: 0.6742 - val_acc: 0.7346\n",
      "Epoch 1471/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3123 - acc: 0.9703 - val_loss: 0.6907 - val_acc: 0.7135\n",
      "Epoch 1472/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3200 - acc: 0.9547 - val_loss: 0.6832 - val_acc: 0.7270\n",
      "Epoch 1473/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3124 - acc: 0.9661 - val_loss: 0.6866 - val_acc: 0.7244\n",
      "Epoch 1474/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3125 - acc: 0.9660 - val_loss: 0.6827 - val_acc: 0.7233\n",
      "Epoch 1475/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3137 - acc: 0.9619 - val_loss: 0.6861 - val_acc: 0.7193\n",
      "Epoch 1476/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3103 - acc: 0.9689 - val_loss: 0.6796 - val_acc: 0.7240\n",
      "Epoch 1477/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3088 - acc: 0.9713 - val_loss: 0.6803 - val_acc: 0.7248\n",
      "Epoch 1478/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3079 - acc: 0.9743 - val_loss: 0.6799 - val_acc: 0.7259\n",
      "Epoch 1479/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3076 - acc: 0.9757 - val_loss: 0.6800 - val_acc: 0.7255\n",
      "Epoch 1480/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3073 - acc: 0.9761 - val_loss: 0.6803 - val_acc: 0.7255\n",
      "Epoch 1481/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3071 - acc: 0.9776 - val_loss: 0.6798 - val_acc: 0.7237\n",
      "Epoch 1482/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3070 - acc: 0.9782 - val_loss: 0.6806 - val_acc: 0.7277\n",
      "Epoch 1483/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9797 - val_loss: 0.6811 - val_acc: 0.7248\n",
      "Epoch 1484/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9797 - val_loss: 0.6810 - val_acc: 0.7281\n",
      "Epoch 1485/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3067 - acc: 0.9806 - val_loss: 0.6803 - val_acc: 0.7255\n",
      "Epoch 1486/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9813 - val_loss: 0.6795 - val_acc: 0.7281\n",
      "Epoch 1487/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9807 - val_loss: 0.6795 - val_acc: 0.7284\n",
      "Epoch 1488/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9814 - val_loss: 0.6791 - val_acc: 0.7288\n",
      "Epoch 1489/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9811 - val_loss: 0.6787 - val_acc: 0.7262\n",
      "Epoch 1490/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9822 - val_loss: 0.6786 - val_acc: 0.7230\n",
      "Epoch 1491/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9822 - val_loss: 0.6789 - val_acc: 0.7262\n",
      "Epoch 1492/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3064 - acc: 0.9825 - val_loss: 0.6788 - val_acc: 0.7255\n",
      "Epoch 1493/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3063 - acc: 0.9828 - val_loss: 0.6787 - val_acc: 0.7273\n",
      "Epoch 1494/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3063 - acc: 0.9829 - val_loss: 0.6785 - val_acc: 0.7273\n",
      "Epoch 1495/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3063 - acc: 0.9826 - val_loss: 0.6785 - val_acc: 0.7273\n",
      "Epoch 1496/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3063 - acc: 0.9834 - val_loss: 0.6778 - val_acc: 0.7266\n",
      "Epoch 1497/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3063 - acc: 0.9827 - val_loss: 0.6788 - val_acc: 0.7259\n",
      "Epoch 1498/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3063 - acc: 0.9833 - val_loss: 0.6779 - val_acc: 0.7237\n",
      "Epoch 1499/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3063 - acc: 0.9831 - val_loss: 0.6775 - val_acc: 0.7273\n",
      "Epoch 1500/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9833 - val_loss: 0.6783 - val_acc: 0.7262\n",
      "Epoch 1501/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3062 - acc: 0.9831 - val_loss: 0.6788 - val_acc: 0.7259\n",
      "Epoch 1502/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3062 - acc: 0.9833 - val_loss: 0.6789 - val_acc: 0.7270\n",
      "Epoch 1503/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3063 - acc: 0.9840 - val_loss: 0.6791 - val_acc: 0.7251\n",
      "Epoch 1504/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9835 - val_loss: 0.6786 - val_acc: 0.7270\n",
      "Epoch 1505/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3063 - acc: 0.9829 - val_loss: 0.6790 - val_acc: 0.7248\n",
      "Epoch 1506/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3063 - acc: 0.9825 - val_loss: 0.6791 - val_acc: 0.7255\n",
      "Epoch 1507/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3063 - acc: 0.9830 - val_loss: 0.6786 - val_acc: 0.7277\n",
      "Epoch 1508/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9800 - val_loss: 0.6787 - val_acc: 0.7277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1509/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9816 - val_loss: 0.6796 - val_acc: 0.7277\n",
      "Epoch 1510/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3070 - acc: 0.9789 - val_loss: 0.6800 - val_acc: 0.7259\n",
      "Epoch 1511/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3069 - acc: 0.9779 - val_loss: 0.6763 - val_acc: 0.7248\n",
      "Epoch 1512/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3071 - acc: 0.9780 - val_loss: 0.6760 - val_acc: 0.7288\n",
      "Epoch 1513/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9793 - val_loss: 0.6760 - val_acc: 0.7332\n",
      "Epoch 1514/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3066 - acc: 0.9794 - val_loss: 0.6737 - val_acc: 0.7332\n",
      "Epoch 1515/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3065 - acc: 0.9807 - val_loss: 0.6743 - val_acc: 0.7306\n",
      "Epoch 1516/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9809 - val_loss: 0.6740 - val_acc: 0.7303\n",
      "Epoch 1517/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9815 - val_loss: 0.6748 - val_acc: 0.7317\n",
      "Epoch 1518/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9814 - val_loss: 0.6749 - val_acc: 0.7277\n",
      "Epoch 1519/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9811 - val_loss: 0.6738 - val_acc: 0.7321\n",
      "Epoch 1520/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9818 - val_loss: 0.6744 - val_acc: 0.7310\n",
      "Epoch 1521/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3065 - acc: 0.9800 - val_loss: 0.6745 - val_acc: 0.7317\n",
      "Epoch 1522/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9788 - val_loss: 0.6757 - val_acc: 0.7317\n",
      "Epoch 1523/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3067 - acc: 0.9781 - val_loss: 0.6739 - val_acc: 0.7270\n",
      "Epoch 1524/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3067 - acc: 0.9790 - val_loss: 0.6735 - val_acc: 0.7306\n",
      "Epoch 1525/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9790 - val_loss: 0.6718 - val_acc: 0.7332\n",
      "Epoch 1526/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9782 - val_loss: 0.6744 - val_acc: 0.7255\n",
      "Epoch 1527/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9786 - val_loss: 0.6707 - val_acc: 0.7314\n",
      "Epoch 1528/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3067 - acc: 0.9786 - val_loss: 0.6697 - val_acc: 0.7295\n",
      "Epoch 1529/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3136 - acc: 0.9658 - val_loss: 0.6818 - val_acc: 0.7277\n",
      "Epoch 1530/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3155 - acc: 0.9592 - val_loss: 0.6795 - val_acc: 0.7226\n",
      "Epoch 1531/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3102 - acc: 0.9691 - val_loss: 0.6794 - val_acc: 0.7306\n",
      "Epoch 1532/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3076 - acc: 0.9753 - val_loss: 0.6777 - val_acc: 0.7277\n",
      "Epoch 1533/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3072 - acc: 0.9770 - val_loss: 0.6765 - val_acc: 0.7361\n",
      "Epoch 1534/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9790 - val_loss: 0.6749 - val_acc: 0.7303\n",
      "Epoch 1535/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9816 - val_loss: 0.6760 - val_acc: 0.7325\n",
      "Epoch 1536/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3063 - acc: 0.9814 - val_loss: 0.6767 - val_acc: 0.7303\n",
      "Epoch 1537/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3062 - acc: 0.9830 - val_loss: 0.6767 - val_acc: 0.7306\n",
      "Epoch 1538/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3062 - acc: 0.9833 - val_loss: 0.6769 - val_acc: 0.7321\n",
      "Epoch 1539/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3061 - acc: 0.9843 - val_loss: 0.6771 - val_acc: 0.7306\n",
      "Epoch 1540/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3061 - acc: 0.9848 - val_loss: 0.6774 - val_acc: 0.7295\n",
      "Epoch 1541/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3060 - acc: 0.9850 - val_loss: 0.6774 - val_acc: 0.7288\n",
      "Epoch 1542/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9849 - val_loss: 0.6775 - val_acc: 0.7284\n",
      "Epoch 1543/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3060 - acc: 0.9848 - val_loss: 0.6775 - val_acc: 0.7281\n",
      "Epoch 1544/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3060 - acc: 0.9853 - val_loss: 0.6774 - val_acc: 0.7288\n",
      "Epoch 1545/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9858 - val_loss: 0.6771 - val_acc: 0.7303\n",
      "Epoch 1546/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3060 - acc: 0.9854 - val_loss: 0.6777 - val_acc: 0.7288\n",
      "Epoch 1547/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9859 - val_loss: 0.6774 - val_acc: 0.7310\n",
      "Epoch 1548/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3060 - acc: 0.9861 - val_loss: 0.6773 - val_acc: 0.7299\n",
      "Epoch 1549/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3060 - acc: 0.9858 - val_loss: 0.6772 - val_acc: 0.7277\n",
      "Epoch 1550/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3060 - acc: 0.9851 - val_loss: 0.6781 - val_acc: 0.7303\n",
      "Epoch 1551/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9844 - val_loss: 0.6774 - val_acc: 0.7306\n",
      "Epoch 1552/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3067 - acc: 0.9817 - val_loss: 0.6809 - val_acc: 0.7270\n",
      "Epoch 1553/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3079 - acc: 0.9723 - val_loss: 0.6794 - val_acc: 0.7244\n",
      "Epoch 1554/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3072 - acc: 0.9766 - val_loss: 0.6821 - val_acc: 0.7273\n",
      "Epoch 1555/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3069 - acc: 0.9784 - val_loss: 0.6806 - val_acc: 0.7281\n",
      "Epoch 1556/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3065 - acc: 0.9783 - val_loss: 0.6804 - val_acc: 0.7259\n",
      "Epoch 1557/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6803 - val_acc: 0.7281\n",
      "Epoch 1558/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3061 - acc: 0.9837 - val_loss: 0.6791 - val_acc: 0.7295\n",
      "Epoch 1559/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6794 - val_acc: 0.7295\n",
      "Epoch 1560/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3060 - acc: 0.9839 - val_loss: 0.6801 - val_acc: 0.7303\n",
      "Epoch 1561/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9835 - val_loss: 0.6798 - val_acc: 0.7284\n",
      "Epoch 1562/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6806 - val_acc: 0.7295\n",
      "Epoch 1563/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3063 - acc: 0.9818 - val_loss: 0.6804 - val_acc: 0.7284\n",
      "Epoch 1564/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3064 - acc: 0.9802 - val_loss: 0.6800 - val_acc: 0.7299\n",
      "Epoch 1565/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9786 - val_loss: 0.6790 - val_acc: 0.7277\n",
      "Epoch 1566/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3067 - acc: 0.9799 - val_loss: 0.6784 - val_acc: 0.7284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1567/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3067 - acc: 0.9774 - val_loss: 0.6790 - val_acc: 0.7321\n",
      "Epoch 1568/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3067 - acc: 0.9786 - val_loss: 0.6795 - val_acc: 0.7259\n",
      "Epoch 1569/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3067 - acc: 0.9784 - val_loss: 0.6812 - val_acc: 0.7321\n",
      "Epoch 1570/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3070 - acc: 0.9761 - val_loss: 0.6748 - val_acc: 0.7237\n",
      "Epoch 1571/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3068 - acc: 0.9782 - val_loss: 0.6756 - val_acc: 0.7270\n",
      "Epoch 1572/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3065 - acc: 0.9780 - val_loss: 0.6767 - val_acc: 0.7266\n",
      "Epoch 1573/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9799 - val_loss: 0.6737 - val_acc: 0.7284\n",
      "Epoch 1574/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9811 - val_loss: 0.6726 - val_acc: 0.7306\n",
      "Epoch 1575/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3063 - acc: 0.9815 - val_loss: 0.6785 - val_acc: 0.7281\n",
      "Epoch 1576/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3063 - acc: 0.9811 - val_loss: 0.6758 - val_acc: 0.7288\n",
      "Epoch 1577/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9804 - val_loss: 0.6791 - val_acc: 0.7281\n",
      "Epoch 1578/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9812 - val_loss: 0.6798 - val_acc: 0.7339\n",
      "Epoch 1579/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9797 - val_loss: 0.6757 - val_acc: 0.7284\n",
      "Epoch 1580/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9797 - val_loss: 0.6784 - val_acc: 0.7288\n",
      "Epoch 1581/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9804 - val_loss: 0.6762 - val_acc: 0.7292\n",
      "Epoch 1582/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9787 - val_loss: 0.6762 - val_acc: 0.7277\n",
      "Epoch 1583/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9789 - val_loss: 0.6774 - val_acc: 0.7306\n",
      "Epoch 1584/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9794 - val_loss: 0.6743 - val_acc: 0.7303\n",
      "Epoch 1585/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9780 - val_loss: 0.6746 - val_acc: 0.7317\n",
      "Epoch 1586/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3068 - acc: 0.9778 - val_loss: 0.6772 - val_acc: 0.7321\n",
      "Epoch 1587/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9786 - val_loss: 0.6764 - val_acc: 0.7299\n",
      "Epoch 1588/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9786 - val_loss: 0.6728 - val_acc: 0.7284\n",
      "Epoch 1589/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9782 - val_loss: 0.6737 - val_acc: 0.7306\n",
      "Epoch 1590/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3064 - acc: 0.9800 - val_loss: 0.6738 - val_acc: 0.7314\n",
      "Epoch 1591/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6733 - val_acc: 0.7314\n",
      "Epoch 1592/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3063 - acc: 0.9799 - val_loss: 0.6737 - val_acc: 0.7325\n",
      "Epoch 1593/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3063 - acc: 0.9804 - val_loss: 0.6740 - val_acc: 0.7292\n",
      "Epoch 1594/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9797 - val_loss: 0.6718 - val_acc: 0.7328\n",
      "Epoch 1595/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9777 - val_loss: 0.6737 - val_acc: 0.7270\n",
      "Epoch 1596/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9785 - val_loss: 0.6731 - val_acc: 0.7288\n",
      "Epoch 1597/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3066 - acc: 0.9769 - val_loss: 0.6737 - val_acc: 0.7306\n",
      "Epoch 1598/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3066 - acc: 0.9786 - val_loss: 0.6683 - val_acc: 0.7325\n",
      "Epoch 1599/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9768 - val_loss: 0.6718 - val_acc: 0.7332\n",
      "Epoch 1600/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9800 - val_loss: 0.6721 - val_acc: 0.7303\n",
      "Epoch 1601/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9795 - val_loss: 0.6713 - val_acc: 0.7325\n",
      "Epoch 1602/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9772 - val_loss: 0.6705 - val_acc: 0.7277\n",
      "Epoch 1603/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3069 - acc: 0.9777 - val_loss: 0.6695 - val_acc: 0.7310\n",
      "Epoch 1604/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3098 - acc: 0.9671 - val_loss: 0.6685 - val_acc: 0.7156\n",
      "Epoch 1605/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3157 - acc: 0.9581 - val_loss: 0.6760 - val_acc: 0.7277\n",
      "Epoch 1606/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3205 - acc: 0.9563 - val_loss: 0.6873 - val_acc: 0.7244\n",
      "Epoch 1607/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3125 - acc: 0.9630 - val_loss: 0.6860 - val_acc: 0.7299\n",
      "Epoch 1608/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3091 - acc: 0.9713 - val_loss: 0.6807 - val_acc: 0.7284\n",
      "Epoch 1609/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3080 - acc: 0.9743 - val_loss: 0.6810 - val_acc: 0.7361\n",
      "Epoch 1610/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3074 - acc: 0.9752 - val_loss: 0.6817 - val_acc: 0.7332\n",
      "Epoch 1611/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3069 - acc: 0.9773 - val_loss: 0.6799 - val_acc: 0.7321\n",
      "Epoch 1612/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3067 - acc: 0.9782 - val_loss: 0.6790 - val_acc: 0.7325\n",
      "Epoch 1613/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9792 - val_loss: 0.6786 - val_acc: 0.7346\n",
      "Epoch 1614/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9796 - val_loss: 0.6786 - val_acc: 0.7361\n",
      "Epoch 1615/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3063 - acc: 0.9800 - val_loss: 0.6778 - val_acc: 0.7339\n",
      "Epoch 1616/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3062 - acc: 0.9809 - val_loss: 0.6783 - val_acc: 0.7336\n",
      "Epoch 1617/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3062 - acc: 0.9814 - val_loss: 0.6781 - val_acc: 0.7339\n",
      "Epoch 1618/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6780 - val_acc: 0.7336\n",
      "Epoch 1619/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3061 - acc: 0.9826 - val_loss: 0.6779 - val_acc: 0.7346\n",
      "Epoch 1620/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3061 - acc: 0.9831 - val_loss: 0.6781 - val_acc: 0.7325\n",
      "Epoch 1621/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6779 - val_acc: 0.7354\n",
      "Epoch 1622/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6775 - val_acc: 0.7336\n",
      "Epoch 1623/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6777 - val_acc: 0.7339\n",
      "Epoch 1624/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6778 - val_acc: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1625/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3060 - acc: 0.9842 - val_loss: 0.6779 - val_acc: 0.7332\n",
      "Epoch 1626/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6776 - val_acc: 0.7343\n",
      "Epoch 1627/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6778 - val_acc: 0.7336\n",
      "Epoch 1628/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6780 - val_acc: 0.7343\n",
      "Epoch 1629/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6777 - val_acc: 0.7357\n",
      "Epoch 1630/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6776 - val_acc: 0.7328\n",
      "Epoch 1631/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3060 - acc: 0.9845 - val_loss: 0.6778 - val_acc: 0.7368\n",
      "Epoch 1632/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6774 - val_acc: 0.7332\n",
      "Epoch 1633/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6776 - val_acc: 0.7350\n",
      "Epoch 1634/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3060 - acc: 0.9842 - val_loss: 0.6775 - val_acc: 0.7372\n",
      "Epoch 1635/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9832 - val_loss: 0.6779 - val_acc: 0.7350\n",
      "Epoch 1636/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6773 - val_acc: 0.7365\n",
      "Epoch 1637/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3066 - acc: 0.9789 - val_loss: 0.6755 - val_acc: 0.7317\n",
      "Epoch 1638/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3066 - acc: 0.9786 - val_loss: 0.6780 - val_acc: 0.7357\n",
      "Epoch 1639/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3066 - acc: 0.9769 - val_loss: 0.6783 - val_acc: 0.7339\n",
      "Epoch 1640/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3065 - acc: 0.9779 - val_loss: 0.6760 - val_acc: 0.7306\n",
      "Epoch 1641/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9794 - val_loss: 0.6745 - val_acc: 0.7299\n",
      "Epoch 1642/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3063 - acc: 0.9802 - val_loss: 0.6759 - val_acc: 0.7321\n",
      "Epoch 1643/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3062 - acc: 0.9798 - val_loss: 0.6746 - val_acc: 0.7361\n",
      "Epoch 1644/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3062 - acc: 0.9817 - val_loss: 0.6754 - val_acc: 0.7310\n",
      "Epoch 1645/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3062 - acc: 0.9805 - val_loss: 0.6749 - val_acc: 0.7357\n",
      "Epoch 1646/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3062 - acc: 0.9813 - val_loss: 0.6756 - val_acc: 0.7328\n",
      "Epoch 1647/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3064 - acc: 0.9797 - val_loss: 0.6751 - val_acc: 0.7339\n",
      "Epoch 1648/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3063 - acc: 0.9800 - val_loss: 0.6745 - val_acc: 0.7336\n",
      "Epoch 1649/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3065 - acc: 0.9772 - val_loss: 0.6752 - val_acc: 0.7325\n",
      "Epoch 1650/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3066 - acc: 0.9793 - val_loss: 0.6734 - val_acc: 0.7354\n",
      "Epoch 1651/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3067 - acc: 0.9771 - val_loss: 0.6734 - val_acc: 0.7339\n",
      "Epoch 1652/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3066 - acc: 0.9777 - val_loss: 0.6714 - val_acc: 0.7299\n",
      "Epoch 1653/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3065 - acc: 0.9778 - val_loss: 0.6727 - val_acc: 0.7336\n",
      "Epoch 1654/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3064 - acc: 0.9782 - val_loss: 0.6694 - val_acc: 0.7343\n",
      "Epoch 1655/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3064 - acc: 0.9794 - val_loss: 0.6742 - val_acc: 0.7368\n",
      "Epoch 1656/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9775 - val_loss: 0.6715 - val_acc: 0.7332\n",
      "Epoch 1657/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3064 - acc: 0.9782 - val_loss: 0.6730 - val_acc: 0.7343\n",
      "Epoch 1658/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3065 - acc: 0.9793 - val_loss: 0.6727 - val_acc: 0.7310\n",
      "Epoch 1659/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3065 - acc: 0.9793 - val_loss: 0.6708 - val_acc: 0.7357\n",
      "Epoch 1660/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3068 - acc: 0.9773 - val_loss: 0.6726 - val_acc: 0.7292\n",
      "Epoch 1661/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3102 - acc: 0.9697 - val_loss: 0.6760 - val_acc: 0.7288\n",
      "Epoch 1662/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3192 - acc: 0.9537 - val_loss: 0.6792 - val_acc: 0.7339\n",
      "Epoch 1663/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3134 - acc: 0.9616 - val_loss: 0.6806 - val_acc: 0.7288\n",
      "Epoch 1664/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3095 - acc: 0.9700 - val_loss: 0.6756 - val_acc: 0.7357\n",
      "Epoch 1665/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3079 - acc: 0.9762 - val_loss: 0.6746 - val_acc: 0.7336\n",
      "Epoch 1666/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3073 - acc: 0.9771 - val_loss: 0.6727 - val_acc: 0.7325\n",
      "Epoch 1667/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3068 - acc: 0.9779 - val_loss: 0.6712 - val_acc: 0.7343\n",
      "Epoch 1668/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3066 - acc: 0.9804 - val_loss: 0.6716 - val_acc: 0.7365\n",
      "Epoch 1669/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3065 - acc: 0.9814 - val_loss: 0.6705 - val_acc: 0.7339\n",
      "Epoch 1670/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3063 - acc: 0.9825 - val_loss: 0.6709 - val_acc: 0.7350\n",
      "Epoch 1671/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3062 - acc: 0.9830 - val_loss: 0.6706 - val_acc: 0.7343\n",
      "Epoch 1672/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9836 - val_loss: 0.6706 - val_acc: 0.7343\n",
      "Epoch 1673/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6708 - val_acc: 0.7336\n",
      "Epoch 1674/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3061 - acc: 0.9844 - val_loss: 0.6708 - val_acc: 0.7332\n",
      "Epoch 1675/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3061 - acc: 0.9848 - val_loss: 0.6704 - val_acc: 0.7343\n",
      "Epoch 1676/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9848 - val_loss: 0.6708 - val_acc: 0.7350\n",
      "Epoch 1677/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3060 - acc: 0.9858 - val_loss: 0.6705 - val_acc: 0.7343\n",
      "Epoch 1678/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3060 - acc: 0.9854 - val_loss: 0.6708 - val_acc: 0.7357\n",
      "Epoch 1679/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3060 - acc: 0.9851 - val_loss: 0.6705 - val_acc: 0.7336\n",
      "Epoch 1680/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3060 - acc: 0.9855 - val_loss: 0.6707 - val_acc: 0.7339\n",
      "Epoch 1681/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3059 - acc: 0.9859 - val_loss: 0.6701 - val_acc: 0.7336\n",
      "Epoch 1682/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3059 - acc: 0.9857 - val_loss: 0.6703 - val_acc: 0.7343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1683/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3059 - acc: 0.9853 - val_loss: 0.6703 - val_acc: 0.7332\n",
      "Epoch 1684/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3059 - acc: 0.9859 - val_loss: 0.6702 - val_acc: 0.7357\n",
      "Epoch 1685/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3059 - acc: 0.9861 - val_loss: 0.6709 - val_acc: 0.7343\n",
      "Epoch 1686/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6705 - val_acc: 0.7336\n",
      "Epoch 1687/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3060 - acc: 0.9853 - val_loss: 0.6703 - val_acc: 0.7336\n",
      "Epoch 1688/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6699 - val_acc: 0.7368\n",
      "Epoch 1689/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6711 - val_acc: 0.7343\n",
      "Epoch 1690/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3061 - acc: 0.9836 - val_loss: 0.6689 - val_acc: 0.7332\n",
      "Epoch 1691/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3062 - acc: 0.9828 - val_loss: 0.6706 - val_acc: 0.7336\n",
      "Epoch 1692/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3063 - acc: 0.9811 - val_loss: 0.6699 - val_acc: 0.7365\n",
      "Epoch 1693/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9803 - val_loss: 0.6698 - val_acc: 0.7325\n",
      "Epoch 1694/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3064 - acc: 0.9808 - val_loss: 0.6682 - val_acc: 0.7303\n",
      "Epoch 1695/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3064 - acc: 0.9799 - val_loss: 0.6687 - val_acc: 0.7339\n",
      "Epoch 1696/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9800 - val_loss: 0.6706 - val_acc: 0.7310\n",
      "Epoch 1697/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3064 - acc: 0.9800 - val_loss: 0.6684 - val_acc: 0.7383\n",
      "Epoch 1698/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3065 - acc: 0.9804 - val_loss: 0.6687 - val_acc: 0.7365\n",
      "Epoch 1699/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3064 - acc: 0.9800 - val_loss: 0.6675 - val_acc: 0.7343\n",
      "Epoch 1700/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3063 - acc: 0.9813 - val_loss: 0.6688 - val_acc: 0.7372\n",
      "Epoch 1701/10000\n",
      "4259/4259 [==============================] - 2s 459us/step - loss: 0.3063 - acc: 0.9804 - val_loss: 0.6690 - val_acc: 0.7350\n",
      "Epoch 1702/10000\n",
      "4259/4259 [==============================] - 2s 458us/step - loss: 0.3064 - acc: 0.9806 - val_loss: 0.6662 - val_acc: 0.7325\n",
      "Epoch 1703/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3064 - acc: 0.9794 - val_loss: 0.6670 - val_acc: 0.7350\n",
      "Epoch 1704/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3064 - acc: 0.9809 - val_loss: 0.6713 - val_acc: 0.7336\n",
      "Epoch 1705/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3065 - acc: 0.9789 - val_loss: 0.6664 - val_acc: 0.7346\n",
      "Epoch 1706/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3071 - acc: 0.9776 - val_loss: 0.6630 - val_acc: 0.7317\n",
      "Epoch 1707/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3095 - acc: 0.9701 - val_loss: 0.6732 - val_acc: 0.7251\n",
      "Epoch 1708/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3094 - acc: 0.9692 - val_loss: 0.6763 - val_acc: 0.7325\n",
      "Epoch 1709/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3114 - acc: 0.9666 - val_loss: 0.6685 - val_acc: 0.7357\n",
      "Epoch 1710/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3084 - acc: 0.9730 - val_loss: 0.6681 - val_acc: 0.7295\n",
      "Epoch 1711/10000\n",
      "4259/4259 [==============================] - 2s 460us/step - loss: 0.3070 - acc: 0.9776 - val_loss: 0.6683 - val_acc: 0.7325\n",
      "Epoch 1712/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3064 - acc: 0.9802 - val_loss: 0.6670 - val_acc: 0.7317\n",
      "Epoch 1713/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3062 - acc: 0.9826 - val_loss: 0.6677 - val_acc: 0.7339\n",
      "Epoch 1714/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3061 - acc: 0.9839 - val_loss: 0.6671 - val_acc: 0.7357\n",
      "Epoch 1715/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6672 - val_acc: 0.7332\n",
      "Epoch 1716/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3060 - acc: 0.9838 - val_loss: 0.6673 - val_acc: 0.7350\n",
      "Epoch 1717/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6669 - val_acc: 0.7368\n",
      "Epoch 1718/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6671 - val_acc: 0.7354\n",
      "Epoch 1719/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6670 - val_acc: 0.7357\n",
      "Epoch 1720/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6673 - val_acc: 0.7336\n",
      "Epoch 1721/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6669 - val_acc: 0.7328\n",
      "Epoch 1722/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9859 - val_loss: 0.6673 - val_acc: 0.7328\n",
      "Epoch 1723/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3059 - acc: 0.9855 - val_loss: 0.6673 - val_acc: 0.7343\n",
      "Epoch 1724/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3059 - acc: 0.9853 - val_loss: 0.6671 - val_acc: 0.7336\n",
      "Epoch 1725/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3059 - acc: 0.9858 - val_loss: 0.6671 - val_acc: 0.7339\n",
      "Epoch 1726/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6668 - val_acc: 0.7343\n",
      "Epoch 1727/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6669 - val_acc: 0.7357\n",
      "Epoch 1728/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6677 - val_acc: 0.7354\n",
      "Epoch 1729/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3062 - acc: 0.9821 - val_loss: 0.6670 - val_acc: 0.7398\n",
      "Epoch 1730/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3067 - acc: 0.9793 - val_loss: 0.6657 - val_acc: 0.7350\n",
      "Epoch 1731/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3067 - acc: 0.9782 - val_loss: 0.6664 - val_acc: 0.7365\n",
      "Epoch 1732/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3066 - acc: 0.9790 - val_loss: 0.6663 - val_acc: 0.7336\n",
      "Epoch 1733/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3068 - acc: 0.9779 - val_loss: 0.6661 - val_acc: 0.7343\n",
      "Epoch 1734/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3065 - acc: 0.9777 - val_loss: 0.6650 - val_acc: 0.7328\n",
      "Epoch 1735/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3063 - acc: 0.9824 - val_loss: 0.6641 - val_acc: 0.7350\n",
      "Epoch 1736/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9815 - val_loss: 0.6647 - val_acc: 0.7361\n",
      "Epoch 1737/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6635 - val_acc: 0.7343\n",
      "Epoch 1738/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3061 - acc: 0.9824 - val_loss: 0.6652 - val_acc: 0.7350\n",
      "Epoch 1739/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6627 - val_acc: 0.7354\n",
      "Epoch 1740/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3062 - acc: 0.9821 - val_loss: 0.6639 - val_acc: 0.7387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1741/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6649 - val_acc: 0.7284\n",
      "Epoch 1742/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3063 - acc: 0.9808 - val_loss: 0.6652 - val_acc: 0.7343\n",
      "Epoch 1743/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3064 - acc: 0.9786 - val_loss: 0.6613 - val_acc: 0.7357\n",
      "Epoch 1744/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3066 - acc: 0.9794 - val_loss: 0.6650 - val_acc: 0.7292\n",
      "Epoch 1745/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3066 - acc: 0.9786 - val_loss: 0.6639 - val_acc: 0.7354\n",
      "Epoch 1746/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3067 - acc: 0.9784 - val_loss: 0.6610 - val_acc: 0.7310\n",
      "Epoch 1747/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3065 - acc: 0.9785 - val_loss: 0.6660 - val_acc: 0.7317\n",
      "Epoch 1748/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3064 - acc: 0.9809 - val_loss: 0.6636 - val_acc: 0.7325\n",
      "Epoch 1749/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3063 - acc: 0.9817 - val_loss: 0.6669 - val_acc: 0.7361\n",
      "Epoch 1750/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6641 - val_acc: 0.7314\n",
      "Epoch 1751/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3063 - acc: 0.9803 - val_loss: 0.6623 - val_acc: 0.7350\n",
      "Epoch 1752/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9819 - val_loss: 0.6627 - val_acc: 0.7350\n",
      "Epoch 1753/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3063 - acc: 0.9800 - val_loss: 0.6656 - val_acc: 0.7332\n",
      "Epoch 1754/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6611 - val_acc: 0.7328\n",
      "Epoch 1755/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3064 - acc: 0.9805 - val_loss: 0.6601 - val_acc: 0.7310\n",
      "Epoch 1756/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3066 - acc: 0.9805 - val_loss: 0.6626 - val_acc: 0.7357\n",
      "Epoch 1757/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3079 - acc: 0.9744 - val_loss: 0.6648 - val_acc: 0.7292\n",
      "Epoch 1758/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3133 - acc: 0.9634 - val_loss: 0.6761 - val_acc: 0.7299\n",
      "Epoch 1759/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3132 - acc: 0.9610 - val_loss: 0.6637 - val_acc: 0.7266\n",
      "Epoch 1760/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3094 - acc: 0.9700 - val_loss: 0.6667 - val_acc: 0.7255\n",
      "Epoch 1761/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3087 - acc: 0.9738 - val_loss: 0.6637 - val_acc: 0.7219\n",
      "Epoch 1762/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3076 - acc: 0.9746 - val_loss: 0.6644 - val_acc: 0.7233\n",
      "Epoch 1763/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3068 - acc: 0.9777 - val_loss: 0.6636 - val_acc: 0.7237\n",
      "Epoch 1764/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3065 - acc: 0.9798 - val_loss: 0.6645 - val_acc: 0.7240\n",
      "Epoch 1765/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3064 - acc: 0.9808 - val_loss: 0.6659 - val_acc: 0.7233\n",
      "Epoch 1766/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3063 - acc: 0.9813 - val_loss: 0.6647 - val_acc: 0.7266\n",
      "Epoch 1767/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3062 - acc: 0.9820 - val_loss: 0.6653 - val_acc: 0.7273\n",
      "Epoch 1768/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6659 - val_acc: 0.7281\n",
      "Epoch 1769/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6655 - val_acc: 0.7266\n",
      "Epoch 1770/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6657 - val_acc: 0.7270\n",
      "Epoch 1771/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6658 - val_acc: 0.7266\n",
      "Epoch 1772/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6656 - val_acc: 0.7270\n",
      "Epoch 1773/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3060 - acc: 0.9842 - val_loss: 0.6661 - val_acc: 0.7273\n",
      "Epoch 1774/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3060 - acc: 0.9850 - val_loss: 0.6662 - val_acc: 0.7262\n",
      "Epoch 1775/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6666 - val_acc: 0.7262\n",
      "Epoch 1776/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6665 - val_acc: 0.7259\n",
      "Epoch 1777/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6665 - val_acc: 0.7259\n",
      "Epoch 1778/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6663 - val_acc: 0.7266\n",
      "Epoch 1779/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6663 - val_acc: 0.7273\n",
      "Epoch 1780/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6660 - val_acc: 0.7262\n",
      "Epoch 1781/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6668 - val_acc: 0.7259\n",
      "Epoch 1782/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6658 - val_acc: 0.7281\n",
      "Epoch 1783/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6671 - val_acc: 0.7259\n",
      "Epoch 1784/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6662 - val_acc: 0.7295\n",
      "Epoch 1785/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3061 - acc: 0.9831 - val_loss: 0.6665 - val_acc: 0.7270\n",
      "Epoch 1786/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9817 - val_loss: 0.6665 - val_acc: 0.7317\n",
      "Epoch 1787/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3062 - acc: 0.9808 - val_loss: 0.6668 - val_acc: 0.7317\n",
      "Epoch 1788/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3063 - acc: 0.9806 - val_loss: 0.6665 - val_acc: 0.7303\n",
      "Epoch 1789/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3067 - acc: 0.9767 - val_loss: 0.6644 - val_acc: 0.7281\n",
      "Epoch 1790/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3074 - acc: 0.9741 - val_loss: 0.6641 - val_acc: 0.7303\n",
      "Epoch 1791/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3075 - acc: 0.9722 - val_loss: 0.6682 - val_acc: 0.7262\n",
      "Epoch 1792/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3092 - acc: 0.9688 - val_loss: 0.6734 - val_acc: 0.7321\n",
      "Epoch 1793/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3104 - acc: 0.9650 - val_loss: 0.6671 - val_acc: 0.7346\n",
      "Epoch 1794/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3077 - acc: 0.9739 - val_loss: 0.6693 - val_acc: 0.7343\n",
      "Epoch 1795/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3071 - acc: 0.9782 - val_loss: 0.6704 - val_acc: 0.7292\n",
      "Epoch 1796/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3074 - acc: 0.9764 - val_loss: 0.6662 - val_acc: 0.7372\n",
      "Epoch 1797/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3082 - acc: 0.9725 - val_loss: 0.6737 - val_acc: 0.7303\n",
      "Epoch 1798/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3068 - acc: 0.9779 - val_loss: 0.6705 - val_acc: 0.7317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1799/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3064 - acc: 0.9806 - val_loss: 0.6691 - val_acc: 0.7365\n",
      "Epoch 1800/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9806 - val_loss: 0.6703 - val_acc: 0.7346\n",
      "Epoch 1801/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6686 - val_acc: 0.7317\n",
      "Epoch 1802/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3060 - acc: 0.9835 - val_loss: 0.6689 - val_acc: 0.7336\n",
      "Epoch 1803/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6687 - val_acc: 0.7339\n",
      "Epoch 1804/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6697 - val_acc: 0.7314\n",
      "Epoch 1805/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6690 - val_acc: 0.7332\n",
      "Epoch 1806/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6695 - val_acc: 0.7325\n",
      "Epoch 1807/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3059 - acc: 0.9853 - val_loss: 0.6689 - val_acc: 0.7317\n",
      "Epoch 1808/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6696 - val_acc: 0.7310\n",
      "Epoch 1809/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9860 - val_loss: 0.6693 - val_acc: 0.7317\n",
      "Epoch 1810/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6692 - val_acc: 0.7299\n",
      "Epoch 1811/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6691 - val_acc: 0.7336\n",
      "Epoch 1812/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6695 - val_acc: 0.7325\n",
      "Epoch 1813/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6697 - val_acc: 0.7336\n",
      "Epoch 1814/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6700 - val_acc: 0.7310\n",
      "Epoch 1815/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9834 - val_loss: 0.6694 - val_acc: 0.7292\n",
      "Epoch 1816/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9823 - val_loss: 0.6715 - val_acc: 0.7299\n",
      "Epoch 1817/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3063 - acc: 0.9794 - val_loss: 0.6682 - val_acc: 0.7306\n",
      "Epoch 1818/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3065 - acc: 0.9783 - val_loss: 0.6696 - val_acc: 0.7310\n",
      "Epoch 1819/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3067 - acc: 0.9768 - val_loss: 0.6695 - val_acc: 0.7317\n",
      "Epoch 1820/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3066 - acc: 0.9773 - val_loss: 0.6672 - val_acc: 0.7350\n",
      "Epoch 1821/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3064 - acc: 0.9784 - val_loss: 0.6670 - val_acc: 0.7321\n",
      "Epoch 1822/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3063 - acc: 0.9786 - val_loss: 0.6690 - val_acc: 0.7292\n",
      "Epoch 1823/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3064 - acc: 0.9788 - val_loss: 0.6673 - val_acc: 0.7350\n",
      "Epoch 1824/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3064 - acc: 0.9793 - val_loss: 0.6677 - val_acc: 0.7325\n",
      "Epoch 1825/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3063 - acc: 0.9791 - val_loss: 0.6698 - val_acc: 0.7306\n",
      "Epoch 1826/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3063 - acc: 0.9800 - val_loss: 0.6641 - val_acc: 0.7328\n",
      "Epoch 1827/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3062 - acc: 0.9794 - val_loss: 0.6688 - val_acc: 0.7303\n",
      "Epoch 1828/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6697 - val_acc: 0.7310\n",
      "Epoch 1829/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3063 - acc: 0.9804 - val_loss: 0.6687 - val_acc: 0.7317\n",
      "Epoch 1830/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3063 - acc: 0.9796 - val_loss: 0.6684 - val_acc: 0.7292\n",
      "Epoch 1831/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3064 - acc: 0.9780 - val_loss: 0.6661 - val_acc: 0.7339\n",
      "Epoch 1832/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3064 - acc: 0.9776 - val_loss: 0.6668 - val_acc: 0.7310\n",
      "Epoch 1833/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3064 - acc: 0.9780 - val_loss: 0.6667 - val_acc: 0.7288\n",
      "Epoch 1834/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3064 - acc: 0.9766 - val_loss: 0.6662 - val_acc: 0.7314\n",
      "Epoch 1835/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3063 - acc: 0.9785 - val_loss: 0.6647 - val_acc: 0.7346\n",
      "Epoch 1836/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3063 - acc: 0.9785 - val_loss: 0.6646 - val_acc: 0.7336\n",
      "Epoch 1837/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3063 - acc: 0.9794 - val_loss: 0.6657 - val_acc: 0.7321\n",
      "Epoch 1838/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3063 - acc: 0.9798 - val_loss: 0.6636 - val_acc: 0.7336\n",
      "Epoch 1839/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3063 - acc: 0.9796 - val_loss: 0.6660 - val_acc: 0.7292\n",
      "Epoch 1840/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3064 - acc: 0.9789 - val_loss: 0.6637 - val_acc: 0.7281\n",
      "Epoch 1841/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3065 - acc: 0.9780 - val_loss: 0.6632 - val_acc: 0.7292\n",
      "Epoch 1842/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3064 - acc: 0.9767 - val_loss: 0.6630 - val_acc: 0.7328\n",
      "Epoch 1843/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3065 - acc: 0.9768 - val_loss: 0.6625 - val_acc: 0.7339\n",
      "Epoch 1844/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3068 - acc: 0.9771 - val_loss: 0.6627 - val_acc: 0.7350\n",
      "Epoch 1845/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3065 - acc: 0.9782 - val_loss: 0.6640 - val_acc: 0.7346\n",
      "Epoch 1846/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3063 - acc: 0.9797 - val_loss: 0.6640 - val_acc: 0.7284\n",
      "Epoch 1847/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3061 - acc: 0.9814 - val_loss: 0.6640 - val_acc: 0.7325\n",
      "Epoch 1848/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6638 - val_acc: 0.7343\n",
      "Epoch 1849/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6626 - val_acc: 0.7354\n",
      "Epoch 1850/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9812 - val_loss: 0.6631 - val_acc: 0.7365\n",
      "Epoch 1851/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3061 - acc: 0.9808 - val_loss: 0.6618 - val_acc: 0.7346\n",
      "Epoch 1852/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9805 - val_loss: 0.6642 - val_acc: 0.7310\n",
      "Epoch 1853/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3062 - acc: 0.9797 - val_loss: 0.6629 - val_acc: 0.7325\n",
      "Epoch 1854/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6637 - val_acc: 0.7288\n",
      "Epoch 1855/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3063 - acc: 0.9789 - val_loss: 0.6638 - val_acc: 0.7299\n",
      "Epoch 1856/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3064 - acc: 0.9779 - val_loss: 0.6630 - val_acc: 0.7354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1857/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3065 - acc: 0.9778 - val_loss: 0.6635 - val_acc: 0.7336\n",
      "Epoch 1858/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3064 - acc: 0.9793 - val_loss: 0.6638 - val_acc: 0.7325\n",
      "Epoch 1859/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3065 - acc: 0.9786 - val_loss: 0.6628 - val_acc: 0.7343\n",
      "Epoch 1860/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3065 - acc: 0.9789 - val_loss: 0.6618 - val_acc: 0.7350\n",
      "Epoch 1861/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3065 - acc: 0.9807 - val_loss: 0.6636 - val_acc: 0.7314\n",
      "Epoch 1862/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3064 - acc: 0.9762 - val_loss: 0.6605 - val_acc: 0.7332\n",
      "Epoch 1863/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3064 - acc: 0.9791 - val_loss: 0.6633 - val_acc: 0.7303\n",
      "Epoch 1864/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3063 - acc: 0.9804 - val_loss: 0.6604 - val_acc: 0.7325\n",
      "Epoch 1865/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6619 - val_acc: 0.7306\n",
      "Epoch 1866/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9802 - val_loss: 0.6610 - val_acc: 0.7336\n",
      "Epoch 1867/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6612 - val_acc: 0.7343\n",
      "Epoch 1868/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3063 - acc: 0.9798 - val_loss: 0.6595 - val_acc: 0.7328\n",
      "Epoch 1869/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3063 - acc: 0.9799 - val_loss: 0.6625 - val_acc: 0.7336\n",
      "Epoch 1870/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3063 - acc: 0.9796 - val_loss: 0.6612 - val_acc: 0.7346\n",
      "Epoch 1871/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3063 - acc: 0.9786 - val_loss: 0.6625 - val_acc: 0.7343\n",
      "Epoch 1872/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6584 - val_acc: 0.7332\n",
      "Epoch 1873/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9803 - val_loss: 0.6598 - val_acc: 0.7346\n",
      "Epoch 1874/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3062 - acc: 0.9809 - val_loss: 0.6613 - val_acc: 0.7339\n",
      "Epoch 1875/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6576 - val_acc: 0.7303\n",
      "Epoch 1876/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3064 - acc: 0.9805 - val_loss: 0.6585 - val_acc: 0.7332\n",
      "Epoch 1877/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3064 - acc: 0.9771 - val_loss: 0.6603 - val_acc: 0.7354\n",
      "Epoch 1878/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3065 - acc: 0.9786 - val_loss: 0.6610 - val_acc: 0.7295\n",
      "Epoch 1879/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3073 - acc: 0.9769 - val_loss: 0.6601 - val_acc: 0.7343\n",
      "Epoch 1880/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3068 - acc: 0.9789 - val_loss: 0.6617 - val_acc: 0.7325\n",
      "Epoch 1881/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3063 - acc: 0.9788 - val_loss: 0.6602 - val_acc: 0.7321\n",
      "Epoch 1882/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6586 - val_acc: 0.7361\n",
      "Epoch 1883/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3060 - acc: 0.9820 - val_loss: 0.6593 - val_acc: 0.7314\n",
      "Epoch 1884/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6606 - val_acc: 0.7317\n",
      "Epoch 1885/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6587 - val_acc: 0.7317\n",
      "Epoch 1886/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6594 - val_acc: 0.7303\n",
      "Epoch 1887/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6598 - val_acc: 0.7339\n",
      "Epoch 1888/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3061 - acc: 0.9814 - val_loss: 0.6610 - val_acc: 0.7317\n",
      "Epoch 1889/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6601 - val_acc: 0.7350\n",
      "Epoch 1890/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3062 - acc: 0.9806 - val_loss: 0.6593 - val_acc: 0.7350\n",
      "Epoch 1891/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3063 - acc: 0.9803 - val_loss: 0.6583 - val_acc: 0.7343\n",
      "Epoch 1892/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3063 - acc: 0.9789 - val_loss: 0.6579 - val_acc: 0.7339\n",
      "Epoch 1893/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3064 - acc: 0.9806 - val_loss: 0.6611 - val_acc: 0.7295\n",
      "Epoch 1894/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3070 - acc: 0.9758 - val_loss: 0.6582 - val_acc: 0.7295\n",
      "Epoch 1895/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3074 - acc: 0.9721 - val_loss: 0.6621 - val_acc: 0.7281\n",
      "Epoch 1896/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3080 - acc: 0.9713 - val_loss: 0.6598 - val_acc: 0.7412\n",
      "Epoch 1897/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3067 - acc: 0.9767 - val_loss: 0.6634 - val_acc: 0.7361\n",
      "Epoch 1898/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3063 - acc: 0.9810 - val_loss: 0.6620 - val_acc: 0.7343\n",
      "Epoch 1899/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3060 - acc: 0.9831 - val_loss: 0.6617 - val_acc: 0.7361\n",
      "Epoch 1900/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6613 - val_acc: 0.7368\n",
      "Epoch 1901/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9853 - val_loss: 0.6619 - val_acc: 0.7357\n",
      "Epoch 1902/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3058 - acc: 0.9845 - val_loss: 0.6622 - val_acc: 0.7357\n",
      "Epoch 1903/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6603 - val_acc: 0.7361\n",
      "Epoch 1904/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6607 - val_acc: 0.7372\n",
      "Epoch 1905/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3058 - acc: 0.9853 - val_loss: 0.6608 - val_acc: 0.7368\n",
      "Epoch 1906/10000\n",
      "4259/4259 [==============================] - 2s 504us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6613 - val_acc: 0.7365\n",
      "Epoch 1907/10000\n",
      "4259/4259 [==============================] - 2s 499us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6614 - val_acc: 0.7387\n",
      "Epoch 1908/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6601 - val_acc: 0.7346\n",
      "Epoch 1909/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3062 - acc: 0.9797 - val_loss: 0.6612 - val_acc: 0.7343\n",
      "Epoch 1910/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3064 - acc: 0.9793 - val_loss: 0.6615 - val_acc: 0.7354\n",
      "Epoch 1911/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3067 - acc: 0.9768 - val_loss: 0.6633 - val_acc: 0.7365\n",
      "Epoch 1912/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3068 - acc: 0.9763 - val_loss: 0.6608 - val_acc: 0.7365\n",
      "Epoch 1913/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3066 - acc: 0.9769 - val_loss: 0.6596 - val_acc: 0.7346\n",
      "Epoch 1914/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3065 - acc: 0.9779 - val_loss: 0.6578 - val_acc: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1915/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6585 - val_acc: 0.7354\n",
      "Epoch 1916/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6574 - val_acc: 0.7387\n",
      "Epoch 1917/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6588 - val_acc: 0.7357\n",
      "Epoch 1918/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9808 - val_loss: 0.6578 - val_acc: 0.7357\n",
      "Epoch 1919/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6589 - val_acc: 0.7372\n",
      "Epoch 1920/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9806 - val_loss: 0.6579 - val_acc: 0.7368\n",
      "Epoch 1921/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9803 - val_loss: 0.6605 - val_acc: 0.7365\n",
      "Epoch 1922/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9800 - val_loss: 0.6582 - val_acc: 0.7365\n",
      "Epoch 1923/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3063 - acc: 0.9806 - val_loss: 0.6598 - val_acc: 0.7361\n",
      "Epoch 1924/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3064 - acc: 0.9797 - val_loss: 0.6588 - val_acc: 0.7336\n",
      "Epoch 1925/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3065 - acc: 0.9792 - val_loss: 0.6609 - val_acc: 0.7346\n",
      "Epoch 1926/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3073 - acc: 0.9735 - val_loss: 0.6637 - val_acc: 0.7394\n",
      "Epoch 1927/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3075 - acc: 0.9743 - val_loss: 0.6625 - val_acc: 0.7343\n",
      "Epoch 1928/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3071 - acc: 0.9746 - val_loss: 0.6690 - val_acc: 0.7317\n",
      "Epoch 1929/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3183 - acc: 0.9595 - val_loss: 0.6816 - val_acc: 0.7284\n",
      "Epoch 1930/10000\n",
      "4259/4259 [==============================] - 2s 501us/step - loss: 0.3123 - acc: 0.9657 - val_loss: 0.6765 - val_acc: 0.7288\n",
      "Epoch 1931/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3089 - acc: 0.9709 - val_loss: 0.6686 - val_acc: 0.7368\n",
      "Epoch 1932/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3076 - acc: 0.9747 - val_loss: 0.6651 - val_acc: 0.7325\n",
      "Epoch 1933/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3071 - acc: 0.9774 - val_loss: 0.6650 - val_acc: 0.7368\n",
      "Epoch 1934/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3068 - acc: 0.9794 - val_loss: 0.6653 - val_acc: 0.7332\n",
      "Epoch 1935/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3065 - acc: 0.9794 - val_loss: 0.6636 - val_acc: 0.7336\n",
      "Epoch 1936/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3063 - acc: 0.9804 - val_loss: 0.6634 - val_acc: 0.7346\n",
      "Epoch 1937/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3063 - acc: 0.9811 - val_loss: 0.6631 - val_acc: 0.7350\n",
      "Epoch 1938/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9826 - val_loss: 0.6627 - val_acc: 0.7346\n",
      "Epoch 1939/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6622 - val_acc: 0.7346\n",
      "Epoch 1940/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3061 - acc: 0.9836 - val_loss: 0.6625 - val_acc: 0.7361\n",
      "Epoch 1941/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6624 - val_acc: 0.7350\n",
      "Epoch 1942/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3060 - acc: 0.9850 - val_loss: 0.6624 - val_acc: 0.7354\n",
      "Epoch 1943/10000\n",
      "4259/4259 [==============================] - 2s 519us/step - loss: 0.3060 - acc: 0.9849 - val_loss: 0.6626 - val_acc: 0.7365\n",
      "Epoch 1944/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3060 - acc: 0.9850 - val_loss: 0.6624 - val_acc: 0.7368\n",
      "Epoch 1945/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3060 - acc: 0.9847 - val_loss: 0.6629 - val_acc: 0.7361\n",
      "Epoch 1946/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9852 - val_loss: 0.6627 - val_acc: 0.7357\n",
      "Epoch 1947/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3060 - acc: 0.9851 - val_loss: 0.6628 - val_acc: 0.7336\n",
      "Epoch 1948/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6625 - val_acc: 0.7376\n",
      "Epoch 1949/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9855 - val_loss: 0.6626 - val_acc: 0.7354\n",
      "Epoch 1950/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9861 - val_loss: 0.6625 - val_acc: 0.7346\n",
      "Epoch 1951/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6625 - val_acc: 0.7361\n",
      "Epoch 1952/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9855 - val_loss: 0.6625 - val_acc: 0.7365\n",
      "Epoch 1953/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9857 - val_loss: 0.6629 - val_acc: 0.7361\n",
      "Epoch 1954/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9858 - val_loss: 0.6632 - val_acc: 0.7357\n",
      "Epoch 1955/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6633 - val_acc: 0.7361\n",
      "Epoch 1956/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6626 - val_acc: 0.7350\n",
      "Epoch 1957/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9859 - val_loss: 0.6623 - val_acc: 0.7365\n",
      "Epoch 1958/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3072 - acc: 0.9774 - val_loss: 0.6703 - val_acc: 0.7303\n",
      "Epoch 1959/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3092 - acc: 0.9696 - val_loss: 0.6692 - val_acc: 0.7240\n",
      "Epoch 1960/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3089 - acc: 0.9708 - val_loss: 0.6734 - val_acc: 0.7288\n",
      "Epoch 1961/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3104 - acc: 0.9672 - val_loss: 0.6742 - val_acc: 0.7262\n",
      "Epoch 1962/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3080 - acc: 0.9733 - val_loss: 0.6761 - val_acc: 0.7295\n",
      "Epoch 1963/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3068 - acc: 0.9789 - val_loss: 0.6737 - val_acc: 0.7328\n",
      "Epoch 1964/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3064 - acc: 0.9809 - val_loss: 0.6735 - val_acc: 0.7325\n",
      "Epoch 1965/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6734 - val_acc: 0.7339\n",
      "Epoch 1966/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6726 - val_acc: 0.7339\n",
      "Epoch 1967/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9842 - val_loss: 0.6726 - val_acc: 0.7332\n",
      "Epoch 1968/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6725 - val_acc: 0.7317\n",
      "Epoch 1969/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6725 - val_acc: 0.7346\n",
      "Epoch 1970/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6723 - val_acc: 0.7354\n",
      "Epoch 1971/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6724 - val_acc: 0.7346\n",
      "Epoch 1972/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9859 - val_loss: 0.6723 - val_acc: 0.7354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1973/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6721 - val_acc: 0.7354\n",
      "Epoch 1974/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3059 - acc: 0.9859 - val_loss: 0.6723 - val_acc: 0.7350\n",
      "Epoch 1975/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3059 - acc: 0.9863 - val_loss: 0.6719 - val_acc: 0.7343\n",
      "Epoch 1976/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9865 - val_loss: 0.6723 - val_acc: 0.7357\n",
      "Epoch 1977/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3059 - acc: 0.9860 - val_loss: 0.6718 - val_acc: 0.7332\n",
      "Epoch 1978/10000\n",
      "4259/4259 [==============================] - 2s 514us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6716 - val_acc: 0.7354\n",
      "Epoch 1979/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3059 - acc: 0.9853 - val_loss: 0.6718 - val_acc: 0.7317\n",
      "Epoch 1980/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6722 - val_acc: 0.7365\n",
      "Epoch 1981/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6714 - val_acc: 0.7339\n",
      "Epoch 1982/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.3060 - acc: 0.9837 - val_loss: 0.6716 - val_acc: 0.7361\n",
      "Epoch 1983/10000\n",
      "4259/4259 [==============================] - 2s 507us/step - loss: 0.3062 - acc: 0.9819 - val_loss: 0.6714 - val_acc: 0.7325\n",
      "Epoch 1984/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3063 - acc: 0.9808 - val_loss: 0.6699 - val_acc: 0.7390\n",
      "Epoch 1985/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3064 - acc: 0.9793 - val_loss: 0.6702 - val_acc: 0.7346\n",
      "Epoch 1986/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3063 - acc: 0.9793 - val_loss: 0.6684 - val_acc: 0.7368\n",
      "Epoch 1987/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3064 - acc: 0.9800 - val_loss: 0.6697 - val_acc: 0.7379\n",
      "Epoch 1988/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6694 - val_acc: 0.7361\n",
      "Epoch 1989/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3063 - acc: 0.9815 - val_loss: 0.6695 - val_acc: 0.7354\n",
      "Epoch 1990/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3062 - acc: 0.9816 - val_loss: 0.6679 - val_acc: 0.7325\n",
      "Epoch 1991/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3061 - acc: 0.9812 - val_loss: 0.6689 - val_acc: 0.7328\n",
      "Epoch 1992/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3061 - acc: 0.9828 - val_loss: 0.6672 - val_acc: 0.7376\n",
      "Epoch 1993/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6694 - val_acc: 0.7354\n",
      "Epoch 1994/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6667 - val_acc: 0.7372\n",
      "Epoch 1995/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3062 - acc: 0.9822 - val_loss: 0.6680 - val_acc: 0.7354\n",
      "Epoch 1996/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3063 - acc: 0.9797 - val_loss: 0.6686 - val_acc: 0.7346\n",
      "Epoch 1997/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3065 - acc: 0.9782 - val_loss: 0.6669 - val_acc: 0.7332\n",
      "Epoch 1998/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3064 - acc: 0.9797 - val_loss: 0.6656 - val_acc: 0.7387\n",
      "Epoch 1999/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3065 - acc: 0.9788 - val_loss: 0.6673 - val_acc: 0.7332\n",
      "Epoch 2000/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3064 - acc: 0.9794 - val_loss: 0.6672 - val_acc: 0.7328\n",
      "Epoch 2001/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3063 - acc: 0.9805 - val_loss: 0.6645 - val_acc: 0.7354\n",
      "Epoch 2002/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3063 - acc: 0.9805 - val_loss: 0.6661 - val_acc: 0.7394\n",
      "Epoch 2003/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3066 - acc: 0.9782 - val_loss: 0.6671 - val_acc: 0.7332\n",
      "Epoch 2004/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3067 - acc: 0.9766 - val_loss: 0.6670 - val_acc: 0.7372\n",
      "Epoch 2005/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3064 - acc: 0.9797 - val_loss: 0.6637 - val_acc: 0.7354\n",
      "Epoch 2006/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3062 - acc: 0.9808 - val_loss: 0.6661 - val_acc: 0.7394\n",
      "Epoch 2007/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3061 - acc: 0.9804 - val_loss: 0.6650 - val_acc: 0.7398\n",
      "Epoch 2008/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6654 - val_acc: 0.7383\n",
      "Epoch 2009/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9819 - val_loss: 0.6681 - val_acc: 0.7387\n",
      "Epoch 2010/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9832 - val_loss: 0.6645 - val_acc: 0.7372\n",
      "Epoch 2011/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3063 - acc: 0.9804 - val_loss: 0.6648 - val_acc: 0.7357\n",
      "Epoch 2012/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3064 - acc: 0.9797 - val_loss: 0.6664 - val_acc: 0.7361\n",
      "Epoch 2013/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3064 - acc: 0.9801 - val_loss: 0.6669 - val_acc: 0.7357\n",
      "Epoch 2014/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3064 - acc: 0.9786 - val_loss: 0.6628 - val_acc: 0.7354\n",
      "Epoch 2015/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3063 - acc: 0.9801 - val_loss: 0.6657 - val_acc: 0.7376\n",
      "Epoch 2016/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3062 - acc: 0.9796 - val_loss: 0.6675 - val_acc: 0.7332\n",
      "Epoch 2017/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3062 - acc: 0.9818 - val_loss: 0.6653 - val_acc: 0.7328\n",
      "Epoch 2018/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6653 - val_acc: 0.7350\n",
      "Epoch 2019/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3062 - acc: 0.9812 - val_loss: 0.6653 - val_acc: 0.7339\n",
      "Epoch 2020/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3062 - acc: 0.9809 - val_loss: 0.6634 - val_acc: 0.7372\n",
      "Epoch 2021/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3063 - acc: 0.9789 - val_loss: 0.6648 - val_acc: 0.7365\n",
      "Epoch 2022/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3062 - acc: 0.9796 - val_loss: 0.6635 - val_acc: 0.7346\n",
      "Epoch 2023/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3065 - acc: 0.9795 - val_loss: 0.6622 - val_acc: 0.7317\n",
      "Epoch 2024/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3126 - acc: 0.9618 - val_loss: 0.6782 - val_acc: 0.7390\n",
      "Epoch 2025/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3125 - acc: 0.9628 - val_loss: 0.6827 - val_acc: 0.7314\n",
      "Epoch 2026/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3083 - acc: 0.9733 - val_loss: 0.6806 - val_acc: 0.7383\n",
      "Epoch 2027/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3075 - acc: 0.9759 - val_loss: 0.6775 - val_acc: 0.7339\n",
      "Epoch 2028/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3066 - acc: 0.9797 - val_loss: 0.6715 - val_acc: 0.7354\n",
      "Epoch 2029/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3065 - acc: 0.9794 - val_loss: 0.6753 - val_acc: 0.7321\n",
      "Epoch 2030/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3065 - acc: 0.9804 - val_loss: 0.6724 - val_acc: 0.7368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2031/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3062 - acc: 0.9821 - val_loss: 0.6722 - val_acc: 0.7357\n",
      "Epoch 2032/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6725 - val_acc: 0.7357\n",
      "Epoch 2033/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6721 - val_acc: 0.7361\n",
      "Epoch 2034/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3060 - acc: 0.9835 - val_loss: 0.6718 - val_acc: 0.7357\n",
      "Epoch 2035/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6720 - val_acc: 0.7354\n",
      "Epoch 2036/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6723 - val_acc: 0.7354\n",
      "Epoch 2037/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6715 - val_acc: 0.7357\n",
      "Epoch 2038/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6717 - val_acc: 0.7357\n",
      "Epoch 2039/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6717 - val_acc: 0.7361\n",
      "Epoch 2040/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9853 - val_loss: 0.6711 - val_acc: 0.7343\n",
      "Epoch 2041/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9855 - val_loss: 0.6712 - val_acc: 0.7354\n",
      "Epoch 2042/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9853 - val_loss: 0.6705 - val_acc: 0.7361\n",
      "Epoch 2043/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3073 - acc: 0.9807 - val_loss: 0.6764 - val_acc: 0.7343\n",
      "Epoch 2044/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3106 - acc: 0.9726 - val_loss: 0.6871 - val_acc: 0.7346\n",
      "Epoch 2045/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3172 - acc: 0.9607 - val_loss: 0.6869 - val_acc: 0.7306\n",
      "Epoch 2046/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3124 - acc: 0.9689 - val_loss: 0.6819 - val_acc: 0.7270\n",
      "Epoch 2047/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3091 - acc: 0.9764 - val_loss: 0.6788 - val_acc: 0.7244\n",
      "Epoch 2048/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3083 - acc: 0.9779 - val_loss: 0.6792 - val_acc: 0.7237\n",
      "Epoch 2049/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3078 - acc: 0.9791 - val_loss: 0.6788 - val_acc: 0.7240\n",
      "Epoch 2050/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3076 - acc: 0.9807 - val_loss: 0.6778 - val_acc: 0.7262\n",
      "Epoch 2051/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3074 - acc: 0.9801 - val_loss: 0.6764 - val_acc: 0.7248\n",
      "Epoch 2052/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3072 - acc: 0.9815 - val_loss: 0.6771 - val_acc: 0.7277\n",
      "Epoch 2053/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3071 - acc: 0.9821 - val_loss: 0.6763 - val_acc: 0.7281\n",
      "Epoch 2054/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3070 - acc: 0.9829 - val_loss: 0.6764 - val_acc: 0.7288\n",
      "Epoch 2055/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3070 - acc: 0.9826 - val_loss: 0.6757 - val_acc: 0.7266\n",
      "Epoch 2056/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3069 - acc: 0.9825 - val_loss: 0.6760 - val_acc: 0.7284\n",
      "Epoch 2057/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3069 - acc: 0.9832 - val_loss: 0.6750 - val_acc: 0.7284\n",
      "Epoch 2058/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3068 - acc: 0.9830 - val_loss: 0.6743 - val_acc: 0.7303\n",
      "Epoch 2059/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3068 - acc: 0.9840 - val_loss: 0.6747 - val_acc: 0.7317\n",
      "Epoch 2060/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3068 - acc: 0.9846 - val_loss: 0.6741 - val_acc: 0.7325\n",
      "Epoch 2061/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3067 - acc: 0.9848 - val_loss: 0.6742 - val_acc: 0.7332\n",
      "Epoch 2062/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3067 - acc: 0.9847 - val_loss: 0.6738 - val_acc: 0.7328\n",
      "Epoch 2063/10000\n",
      "4259/4259 [==============================] - 2s 506us/step - loss: 0.3067 - acc: 0.9849 - val_loss: 0.6740 - val_acc: 0.7328\n",
      "Epoch 2064/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3067 - acc: 0.9847 - val_loss: 0.6737 - val_acc: 0.7336\n",
      "Epoch 2065/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3067 - acc: 0.9850 - val_loss: 0.6735 - val_acc: 0.7328\n",
      "Epoch 2066/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3067 - acc: 0.9846 - val_loss: 0.6736 - val_acc: 0.7325\n",
      "Epoch 2067/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3067 - acc: 0.9857 - val_loss: 0.6734 - val_acc: 0.7321\n",
      "Epoch 2068/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3067 - acc: 0.9847 - val_loss: 0.6733 - val_acc: 0.7325\n",
      "Epoch 2069/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3067 - acc: 0.9851 - val_loss: 0.6729 - val_acc: 0.7336\n",
      "Epoch 2070/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3067 - acc: 0.9847 - val_loss: 0.6728 - val_acc: 0.7314\n",
      "Epoch 2071/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3067 - acc: 0.9856 - val_loss: 0.6729 - val_acc: 0.7332\n",
      "Epoch 2072/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3067 - acc: 0.9842 - val_loss: 0.6725 - val_acc: 0.7332\n",
      "Epoch 2073/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3067 - acc: 0.9856 - val_loss: 0.6730 - val_acc: 0.7314\n",
      "Epoch 2074/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3067 - acc: 0.9854 - val_loss: 0.6721 - val_acc: 0.7328\n",
      "Epoch 2075/10000\n",
      "4259/4259 [==============================] - 2s 507us/step - loss: 0.3067 - acc: 0.9844 - val_loss: 0.6728 - val_acc: 0.7332\n",
      "Epoch 2076/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3067 - acc: 0.9840 - val_loss: 0.6715 - val_acc: 0.7336\n",
      "Epoch 2077/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3068 - acc: 0.9834 - val_loss: 0.6726 - val_acc: 0.7336\n",
      "Epoch 2078/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3069 - acc: 0.9828 - val_loss: 0.6716 - val_acc: 0.7310\n",
      "Epoch 2079/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3070 - acc: 0.9816 - val_loss: 0.6693 - val_acc: 0.7266\n",
      "Epoch 2080/10000\n",
      "4259/4259 [==============================] - 2s 507us/step - loss: 0.3081 - acc: 0.9785 - val_loss: 0.6702 - val_acc: 0.7240\n",
      "Epoch 2081/10000\n",
      "4259/4259 [==============================] - 2s 499us/step - loss: 0.3075 - acc: 0.9759 - val_loss: 0.6721 - val_acc: 0.7292\n",
      "Epoch 2082/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3092 - acc: 0.9708 - val_loss: 0.6750 - val_acc: 0.7259\n",
      "Epoch 2083/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3094 - acc: 0.9720 - val_loss: 0.6700 - val_acc: 0.7277\n",
      "Epoch 2084/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3090 - acc: 0.9703 - val_loss: 0.6738 - val_acc: 0.7251\n",
      "Epoch 2085/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3073 - acc: 0.9745 - val_loss: 0.6729 - val_acc: 0.7273\n",
      "Epoch 2086/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3066 - acc: 0.9786 - val_loss: 0.6707 - val_acc: 0.7295\n",
      "Epoch 2087/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3063 - acc: 0.9810 - val_loss: 0.6705 - val_acc: 0.7288\n",
      "Epoch 2088/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6706 - val_acc: 0.7273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2089/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6702 - val_acc: 0.7270\n",
      "Epoch 2090/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6698 - val_acc: 0.7270\n",
      "Epoch 2091/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6700 - val_acc: 0.7273\n",
      "Epoch 2092/10000\n",
      "4259/4259 [==============================] - 2s 515us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6699 - val_acc: 0.7277\n",
      "Epoch 2093/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9834 - val_loss: 0.6702 - val_acc: 0.7270\n",
      "Epoch 2094/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6697 - val_acc: 0.7270\n",
      "Epoch 2095/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6701 - val_acc: 0.7262\n",
      "Epoch 2096/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6699 - val_acc: 0.7273\n",
      "Epoch 2097/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6704 - val_acc: 0.7262\n",
      "Epoch 2098/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6705 - val_acc: 0.7277\n",
      "Epoch 2099/10000\n",
      "4259/4259 [==============================] - 2s 463us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6701 - val_acc: 0.7266\n",
      "Epoch 2100/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6705 - val_acc: 0.7270\n",
      "Epoch 2101/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9839 - val_loss: 0.6698 - val_acc: 0.7277\n",
      "Epoch 2102/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6702 - val_acc: 0.7266\n",
      "Epoch 2103/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6704 - val_acc: 0.7266\n",
      "Epoch 2104/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9820 - val_loss: 0.6707 - val_acc: 0.7284\n",
      "Epoch 2105/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6700 - val_acc: 0.7273\n",
      "Epoch 2106/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9810 - val_loss: 0.6707 - val_acc: 0.7255\n",
      "Epoch 2107/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9786 - val_loss: 0.6696 - val_acc: 0.7255\n",
      "Epoch 2108/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9799 - val_loss: 0.6712 - val_acc: 0.7262\n",
      "Epoch 2109/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9794 - val_loss: 0.6698 - val_acc: 0.7237\n",
      "Epoch 2110/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3063 - acc: 0.9797 - val_loss: 0.6691 - val_acc: 0.7310\n",
      "Epoch 2111/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6686 - val_acc: 0.7292\n",
      "Epoch 2112/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9789 - val_loss: 0.6696 - val_acc: 0.7259\n",
      "Epoch 2113/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9806 - val_loss: 0.6701 - val_acc: 0.7273\n",
      "Epoch 2114/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6680 - val_acc: 0.7310\n",
      "Epoch 2115/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9818 - val_loss: 0.6692 - val_acc: 0.7288\n",
      "Epoch 2116/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9808 - val_loss: 0.6675 - val_acc: 0.7303\n",
      "Epoch 2117/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6680 - val_acc: 0.7266\n",
      "Epoch 2118/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9808 - val_loss: 0.6677 - val_acc: 0.7321\n",
      "Epoch 2119/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9787 - val_loss: 0.6697 - val_acc: 0.7314\n",
      "Epoch 2120/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9798 - val_loss: 0.6674 - val_acc: 0.7262\n",
      "Epoch 2121/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9791 - val_loss: 0.6676 - val_acc: 0.7281\n",
      "Epoch 2122/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9805 - val_loss: 0.6665 - val_acc: 0.7317\n",
      "Epoch 2123/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3064 - acc: 0.9791 - val_loss: 0.6651 - val_acc: 0.7317\n",
      "Epoch 2124/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3063 - acc: 0.9800 - val_loss: 0.6668 - val_acc: 0.7288\n",
      "Epoch 2125/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3066 - acc: 0.9775 - val_loss: 0.6700 - val_acc: 0.7295\n",
      "Epoch 2126/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3098 - acc: 0.9739 - val_loss: 0.6718 - val_acc: 0.7281\n",
      "Epoch 2127/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3194 - acc: 0.9569 - val_loss: 0.6774 - val_acc: 0.7262\n",
      "Epoch 2128/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3125 - acc: 0.9675 - val_loss: 0.6687 - val_acc: 0.7284\n",
      "Epoch 2129/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3085 - acc: 0.9721 - val_loss: 0.6704 - val_acc: 0.7281\n",
      "Epoch 2130/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3077 - acc: 0.9749 - val_loss: 0.6695 - val_acc: 0.7284\n",
      "Epoch 2131/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3075 - acc: 0.9770 - val_loss: 0.6709 - val_acc: 0.7273\n",
      "Epoch 2132/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3083 - acc: 0.9746 - val_loss: 0.6666 - val_acc: 0.7266\n",
      "Epoch 2133/10000\n",
      "4259/4259 [==============================] - 2s 531us/step - loss: 0.3073 - acc: 0.9747 - val_loss: 0.6699 - val_acc: 0.7233\n",
      "Epoch 2134/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3069 - acc: 0.9761 - val_loss: 0.6688 - val_acc: 0.7222\n",
      "Epoch 2135/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3067 - acc: 0.9782 - val_loss: 0.6696 - val_acc: 0.7211\n",
      "Epoch 2136/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3064 - acc: 0.9793 - val_loss: 0.6689 - val_acc: 0.7222\n",
      "Epoch 2137/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3063 - acc: 0.9802 - val_loss: 0.6693 - val_acc: 0.7230\n",
      "Epoch 2138/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6687 - val_acc: 0.7230\n",
      "Epoch 2139/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3062 - acc: 0.9822 - val_loss: 0.6690 - val_acc: 0.7219\n",
      "Epoch 2140/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6686 - val_acc: 0.7233\n",
      "Epoch 2141/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6686 - val_acc: 0.7197\n",
      "Epoch 2142/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6682 - val_acc: 0.7222\n",
      "Epoch 2143/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6686 - val_acc: 0.7237\n",
      "Epoch 2144/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3060 - acc: 0.9837 - val_loss: 0.6681 - val_acc: 0.7255\n",
      "Epoch 2145/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6680 - val_acc: 0.7230\n",
      "Epoch 2146/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6680 - val_acc: 0.7244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2147/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6681 - val_acc: 0.7240\n",
      "Epoch 2148/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6679 - val_acc: 0.7233\n",
      "Epoch 2149/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6676 - val_acc: 0.7233\n",
      "Epoch 2150/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6675 - val_acc: 0.7248\n",
      "Epoch 2151/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6677 - val_acc: 0.7248\n",
      "Epoch 2152/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6681 - val_acc: 0.7251\n",
      "Epoch 2153/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6672 - val_acc: 0.7251\n",
      "Epoch 2154/10000\n",
      "4259/4259 [==============================] - 2s 499us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6676 - val_acc: 0.7248\n",
      "Epoch 2155/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3059 - acc: 0.9848 - val_loss: 0.6675 - val_acc: 0.7251\n",
      "Epoch 2156/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6671 - val_acc: 0.7262\n",
      "Epoch 2157/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6674 - val_acc: 0.7237\n",
      "Epoch 2158/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6674 - val_acc: 0.7233\n",
      "Epoch 2159/10000\n",
      "4259/4259 [==============================] - 2s 515us/step - loss: 0.3060 - acc: 0.9832 - val_loss: 0.6682 - val_acc: 0.7248\n",
      "Epoch 2160/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6668 - val_acc: 0.7281\n",
      "Epoch 2161/10000\n",
      "4259/4259 [==============================] - 2s 515us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6681 - val_acc: 0.7255\n",
      "Epoch 2162/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6664 - val_acc: 0.7251\n",
      "Epoch 2163/10000\n",
      "4259/4259 [==============================] - 2s 524us/step - loss: 0.3063 - acc: 0.9811 - val_loss: 0.6677 - val_acc: 0.7273\n",
      "Epoch 2164/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3064 - acc: 0.9789 - val_loss: 0.6681 - val_acc: 0.7270\n",
      "Epoch 2165/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3063 - acc: 0.9794 - val_loss: 0.6677 - val_acc: 0.7255\n",
      "Epoch 2166/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3066 - acc: 0.9791 - val_loss: 0.6648 - val_acc: 0.7219\n",
      "Epoch 2167/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3064 - acc: 0.9782 - val_loss: 0.6646 - val_acc: 0.7244\n",
      "Epoch 2168/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3062 - acc: 0.9805 - val_loss: 0.6655 - val_acc: 0.7273\n",
      "Epoch 2169/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6653 - val_acc: 0.7273\n",
      "Epoch 2170/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6654 - val_acc: 0.7244\n",
      "Epoch 2171/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6653 - val_acc: 0.7222\n",
      "Epoch 2172/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6652 - val_acc: 0.7270\n",
      "Epoch 2173/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3061 - acc: 0.9809 - val_loss: 0.6652 - val_acc: 0.7277\n",
      "Epoch 2174/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9810 - val_loss: 0.6654 - val_acc: 0.7251\n",
      "Epoch 2175/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3063 - acc: 0.9792 - val_loss: 0.6659 - val_acc: 0.7292\n",
      "Epoch 2176/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3064 - acc: 0.9789 - val_loss: 0.6644 - val_acc: 0.7270\n",
      "Epoch 2177/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3064 - acc: 0.9779 - val_loss: 0.6651 - val_acc: 0.7299\n",
      "Epoch 2178/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3064 - acc: 0.9784 - val_loss: 0.6627 - val_acc: 0.7303\n",
      "Epoch 2179/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3065 - acc: 0.9784 - val_loss: 0.6621 - val_acc: 0.7299\n",
      "Epoch 2180/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3064 - acc: 0.9793 - val_loss: 0.6624 - val_acc: 0.7270\n",
      "Epoch 2181/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3069 - acc: 0.9769 - val_loss: 0.6644 - val_acc: 0.7277\n",
      "Epoch 2182/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3066 - acc: 0.9778 - val_loss: 0.6643 - val_acc: 0.7306\n",
      "Epoch 2183/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3063 - acc: 0.9797 - val_loss: 0.6630 - val_acc: 0.7310\n",
      "Epoch 2184/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9810 - val_loss: 0.6638 - val_acc: 0.7299\n",
      "Epoch 2185/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3065 - acc: 0.9815 - val_loss: 0.6674 - val_acc: 0.7284\n",
      "Epoch 2186/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3164 - acc: 0.9603 - val_loss: 0.6875 - val_acc: 0.7277\n",
      "Epoch 2187/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3214 - acc: 0.9524 - val_loss: 0.6832 - val_acc: 0.7262\n",
      "Epoch 2188/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3103 - acc: 0.9677 - val_loss: 0.6747 - val_acc: 0.7310\n",
      "Epoch 2189/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3083 - acc: 0.9730 - val_loss: 0.6723 - val_acc: 0.7314\n",
      "Epoch 2190/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3076 - acc: 0.9740 - val_loss: 0.6713 - val_acc: 0.7339\n",
      "Epoch 2191/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3072 - acc: 0.9769 - val_loss: 0.6706 - val_acc: 0.7328\n",
      "Epoch 2192/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3069 - acc: 0.9777 - val_loss: 0.6698 - val_acc: 0.7328\n",
      "Epoch 2193/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3068 - acc: 0.9792 - val_loss: 0.6701 - val_acc: 0.7336\n",
      "Epoch 2194/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3067 - acc: 0.9794 - val_loss: 0.6696 - val_acc: 0.7376\n",
      "Epoch 2195/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3065 - acc: 0.9797 - val_loss: 0.6692 - val_acc: 0.7361\n",
      "Epoch 2196/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9807 - val_loss: 0.6690 - val_acc: 0.7376\n",
      "Epoch 2197/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9812 - val_loss: 0.6689 - val_acc: 0.7372\n",
      "Epoch 2198/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9818 - val_loss: 0.6688 - val_acc: 0.7365\n",
      "Epoch 2199/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9825 - val_loss: 0.6693 - val_acc: 0.7365\n",
      "Epoch 2200/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9829 - val_loss: 0.6685 - val_acc: 0.7361\n",
      "Epoch 2201/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9834 - val_loss: 0.6688 - val_acc: 0.7365\n",
      "Epoch 2202/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9836 - val_loss: 0.6684 - val_acc: 0.7350\n",
      "Epoch 2203/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9835 - val_loss: 0.6680 - val_acc: 0.7368\n",
      "Epoch 2204/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3062 - acc: 0.9836 - val_loss: 0.6680 - val_acc: 0.7357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2205/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6683 - val_acc: 0.7365\n",
      "Epoch 2206/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6682 - val_acc: 0.7354\n",
      "Epoch 2207/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9838 - val_loss: 0.6680 - val_acc: 0.7357\n",
      "Epoch 2208/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6686 - val_acc: 0.7357\n",
      "Epoch 2209/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6674 - val_acc: 0.7343\n",
      "Epoch 2210/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6703 - val_acc: 0.7361\n",
      "Epoch 2211/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9838 - val_loss: 0.6696 - val_acc: 0.7343\n",
      "Epoch 2212/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6693 - val_acc: 0.7354\n",
      "Epoch 2213/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6692 - val_acc: 0.7365\n",
      "Epoch 2214/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6692 - val_acc: 0.7350\n",
      "Epoch 2215/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6693 - val_acc: 0.7350\n",
      "Epoch 2216/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6692 - val_acc: 0.7350\n",
      "Epoch 2217/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6695 - val_acc: 0.7332\n",
      "Epoch 2218/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6693 - val_acc: 0.7372\n",
      "Epoch 2219/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6687 - val_acc: 0.7379\n",
      "Epoch 2220/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9812 - val_loss: 0.6684 - val_acc: 0.7339\n",
      "Epoch 2221/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9812 - val_loss: 0.6683 - val_acc: 0.7321\n",
      "Epoch 2222/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3063 - acc: 0.9801 - val_loss: 0.6683 - val_acc: 0.7350\n",
      "Epoch 2223/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3063 - acc: 0.9806 - val_loss: 0.6706 - val_acc: 0.7321\n",
      "Epoch 2224/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3062 - acc: 0.9816 - val_loss: 0.6691 - val_acc: 0.7336\n",
      "Epoch 2225/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3062 - acc: 0.9794 - val_loss: 0.6675 - val_acc: 0.7336\n",
      "Epoch 2226/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3062 - acc: 0.9797 - val_loss: 0.6669 - val_acc: 0.7357\n",
      "Epoch 2227/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3062 - acc: 0.9801 - val_loss: 0.6670 - val_acc: 0.7310\n",
      "Epoch 2228/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3064 - acc: 0.9789 - val_loss: 0.6668 - val_acc: 0.7346\n",
      "Epoch 2229/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3063 - acc: 0.9798 - val_loss: 0.6649 - val_acc: 0.7372\n",
      "Epoch 2230/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3068 - acc: 0.9780 - val_loss: 0.6720 - val_acc: 0.7328\n",
      "Epoch 2231/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3068 - acc: 0.9764 - val_loss: 0.6694 - val_acc: 0.7325\n",
      "Epoch 2232/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3068 - acc: 0.9782 - val_loss: 0.6751 - val_acc: 0.7368\n",
      "Epoch 2233/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3069 - acc: 0.9777 - val_loss: 0.6692 - val_acc: 0.7317\n",
      "Epoch 2234/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9798 - val_loss: 0.6692 - val_acc: 0.7310\n",
      "Epoch 2235/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9797 - val_loss: 0.6693 - val_acc: 0.7314\n",
      "Epoch 2236/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3062 - acc: 0.9819 - val_loss: 0.6691 - val_acc: 0.7321\n",
      "Epoch 2237/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6675 - val_acc: 0.7310\n",
      "Epoch 2238/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6696 - val_acc: 0.7321\n",
      "Epoch 2239/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6695 - val_acc: 0.7314\n",
      "Epoch 2240/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6679 - val_acc: 0.7310\n",
      "Epoch 2241/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9817 - val_loss: 0.6694 - val_acc: 0.7325\n",
      "Epoch 2242/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6683 - val_acc: 0.7310\n",
      "Epoch 2243/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9797 - val_loss: 0.6668 - val_acc: 0.7306\n",
      "Epoch 2244/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9790 - val_loss: 0.6686 - val_acc: 0.7314\n",
      "Epoch 2245/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3064 - acc: 0.9792 - val_loss: 0.6681 - val_acc: 0.7292\n",
      "Epoch 2246/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3064 - acc: 0.9800 - val_loss: 0.6674 - val_acc: 0.7328\n",
      "Epoch 2247/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9789 - val_loss: 0.6660 - val_acc: 0.7354\n",
      "Epoch 2248/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3065 - acc: 0.9777 - val_loss: 0.6684 - val_acc: 0.7336\n",
      "Epoch 2249/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3072 - acc: 0.9735 - val_loss: 0.6683 - val_acc: 0.7306\n",
      "Epoch 2250/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3073 - acc: 0.9745 - val_loss: 0.6691 - val_acc: 0.7259\n",
      "Epoch 2251/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3068 - acc: 0.9771 - val_loss: 0.6676 - val_acc: 0.7292\n",
      "Epoch 2252/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3063 - acc: 0.9800 - val_loss: 0.6660 - val_acc: 0.7303\n",
      "Epoch 2253/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6669 - val_acc: 0.7314\n",
      "Epoch 2254/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6664 - val_acc: 0.7292\n",
      "Epoch 2255/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6668 - val_acc: 0.7325\n",
      "Epoch 2256/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6662 - val_acc: 0.7317\n",
      "Epoch 2257/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9856 - val_loss: 0.6667 - val_acc: 0.7310\n",
      "Epoch 2258/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6669 - val_acc: 0.7328\n",
      "Epoch 2259/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9837 - val_loss: 0.6672 - val_acc: 0.7317\n",
      "Epoch 2260/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6677 - val_acc: 0.7306\n",
      "Epoch 2261/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9814 - val_loss: 0.6673 - val_acc: 0.7346\n",
      "Epoch 2262/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9790 - val_loss: 0.6667 - val_acc: 0.7328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2263/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3068 - acc: 0.9768 - val_loss: 0.6648 - val_acc: 0.7357\n",
      "Epoch 2264/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3068 - acc: 0.9767 - val_loss: 0.6666 - val_acc: 0.7343\n",
      "Epoch 2265/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3068 - acc: 0.9775 - val_loss: 0.6648 - val_acc: 0.7343\n",
      "Epoch 2266/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9777 - val_loss: 0.6657 - val_acc: 0.7365\n",
      "Epoch 2267/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6644 - val_acc: 0.7332\n",
      "Epoch 2268/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9814 - val_loss: 0.6648 - val_acc: 0.7332\n",
      "Epoch 2269/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6636 - val_acc: 0.7350\n",
      "Epoch 2270/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6636 - val_acc: 0.7328\n",
      "Epoch 2271/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6649 - val_acc: 0.7361\n",
      "Epoch 2272/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9806 - val_loss: 0.6640 - val_acc: 0.7339\n",
      "Epoch 2273/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9814 - val_loss: 0.6630 - val_acc: 0.7350\n",
      "Epoch 2274/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9813 - val_loss: 0.6646 - val_acc: 0.7336\n",
      "Epoch 2275/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9805 - val_loss: 0.6630 - val_acc: 0.7379\n",
      "Epoch 2276/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9800 - val_loss: 0.6634 - val_acc: 0.7365\n",
      "Epoch 2277/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9781 - val_loss: 0.6624 - val_acc: 0.7346\n",
      "Epoch 2278/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9813 - val_loss: 0.6615 - val_acc: 0.7350\n",
      "Epoch 2279/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9779 - val_loss: 0.6631 - val_acc: 0.7321\n",
      "Epoch 2280/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9786 - val_loss: 0.6626 - val_acc: 0.7350\n",
      "Epoch 2281/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9797 - val_loss: 0.6628 - val_acc: 0.7368\n",
      "Epoch 2282/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9797 - val_loss: 0.6647 - val_acc: 0.7354\n",
      "Epoch 2283/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3137 - acc: 0.9682 - val_loss: 0.6737 - val_acc: 0.7281\n",
      "Epoch 2284/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3144 - acc: 0.9628 - val_loss: 0.6741 - val_acc: 0.7295\n",
      "Epoch 2285/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3106 - acc: 0.9695 - val_loss: 0.6723 - val_acc: 0.7372\n",
      "Epoch 2286/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3099 - acc: 0.9719 - val_loss: 0.6733 - val_acc: 0.7233\n",
      "Epoch 2287/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3097 - acc: 0.9709 - val_loss: 0.6705 - val_acc: 0.7281\n",
      "Epoch 2288/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3119 - acc: 0.9681 - val_loss: 0.6720 - val_acc: 0.7299\n",
      "Epoch 2289/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3080 - acc: 0.9743 - val_loss: 0.6706 - val_acc: 0.7295\n",
      "Epoch 2290/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3071 - acc: 0.9773 - val_loss: 0.6685 - val_acc: 0.7321\n",
      "Epoch 2291/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3068 - acc: 0.9782 - val_loss: 0.6678 - val_acc: 0.7295\n",
      "Epoch 2292/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3067 - acc: 0.9796 - val_loss: 0.6674 - val_acc: 0.7299\n",
      "Epoch 2293/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3065 - acc: 0.9804 - val_loss: 0.6670 - val_acc: 0.7295\n",
      "Epoch 2294/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9807 - val_loss: 0.6665 - val_acc: 0.7284\n",
      "Epoch 2295/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3064 - acc: 0.9808 - val_loss: 0.6665 - val_acc: 0.7288\n",
      "Epoch 2296/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3063 - acc: 0.9822 - val_loss: 0.6661 - val_acc: 0.7299\n",
      "Epoch 2297/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9825 - val_loss: 0.6662 - val_acc: 0.7292\n",
      "Epoch 2298/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9823 - val_loss: 0.6661 - val_acc: 0.7295\n",
      "Epoch 2299/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9824 - val_loss: 0.6659 - val_acc: 0.7288\n",
      "Epoch 2300/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9828 - val_loss: 0.6656 - val_acc: 0.7295\n",
      "Epoch 2301/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3062 - acc: 0.9836 - val_loss: 0.6655 - val_acc: 0.7295\n",
      "Epoch 2302/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9833 - val_loss: 0.6659 - val_acc: 0.7284\n",
      "Epoch 2303/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3062 - acc: 0.9836 - val_loss: 0.6658 - val_acc: 0.7284\n",
      "Epoch 2304/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6660 - val_acc: 0.7277\n",
      "Epoch 2305/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9845 - val_loss: 0.6653 - val_acc: 0.7273\n",
      "Epoch 2306/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6645 - val_acc: 0.7277\n",
      "Epoch 2307/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3061 - acc: 0.9845 - val_loss: 0.6646 - val_acc: 0.7281\n",
      "Epoch 2308/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3061 - acc: 0.9839 - val_loss: 0.6648 - val_acc: 0.7266\n",
      "Epoch 2309/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9844 - val_loss: 0.6662 - val_acc: 0.7251\n",
      "Epoch 2310/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3062 - acc: 0.9835 - val_loss: 0.6651 - val_acc: 0.7255\n",
      "Epoch 2311/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9841 - val_loss: 0.6653 - val_acc: 0.7266\n",
      "Epoch 2312/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9839 - val_loss: 0.6645 - val_acc: 0.7284\n",
      "Epoch 2313/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9855 - val_loss: 0.6637 - val_acc: 0.7262\n",
      "Epoch 2314/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3060 - acc: 0.9850 - val_loss: 0.6641 - val_acc: 0.7295\n",
      "Epoch 2315/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9854 - val_loss: 0.6639 - val_acc: 0.7281\n",
      "Epoch 2316/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3061 - acc: 0.9854 - val_loss: 0.6648 - val_acc: 0.7266\n",
      "Epoch 2317/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3061 - acc: 0.9852 - val_loss: 0.6643 - val_acc: 0.7255\n",
      "Epoch 2318/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6640 - val_acc: 0.7277\n",
      "Epoch 2319/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3062 - acc: 0.9840 - val_loss: 0.6633 - val_acc: 0.7295\n",
      "Epoch 2320/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9841 - val_loss: 0.6641 - val_acc: 0.7251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2321/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3063 - acc: 0.9833 - val_loss: 0.6646 - val_acc: 0.7284\n",
      "Epoch 2322/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3064 - acc: 0.9816 - val_loss: 0.6628 - val_acc: 0.7284\n",
      "Epoch 2323/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3065 - acc: 0.9799 - val_loss: 0.6634 - val_acc: 0.7237\n",
      "Epoch 2324/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3064 - acc: 0.9821 - val_loss: 0.6638 - val_acc: 0.7306\n",
      "Epoch 2325/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3064 - acc: 0.9814 - val_loss: 0.6623 - val_acc: 0.7273\n",
      "Epoch 2326/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3064 - acc: 0.9818 - val_loss: 0.6628 - val_acc: 0.7299\n",
      "Epoch 2327/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3063 - acc: 0.9813 - val_loss: 0.6617 - val_acc: 0.7299\n",
      "Epoch 2328/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3063 - acc: 0.9821 - val_loss: 0.6629 - val_acc: 0.7284\n",
      "Epoch 2329/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3063 - acc: 0.9817 - val_loss: 0.6612 - val_acc: 0.7284\n",
      "Epoch 2330/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3063 - acc: 0.9814 - val_loss: 0.6612 - val_acc: 0.7262\n",
      "Epoch 2331/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9811 - val_loss: 0.6616 - val_acc: 0.7273\n",
      "Epoch 2332/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3064 - acc: 0.9808 - val_loss: 0.6637 - val_acc: 0.7292\n",
      "Epoch 2333/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3064 - acc: 0.9808 - val_loss: 0.6612 - val_acc: 0.7270\n",
      "Epoch 2334/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3063 - acc: 0.9821 - val_loss: 0.6611 - val_acc: 0.7332\n",
      "Epoch 2335/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3063 - acc: 0.9802 - val_loss: 0.6617 - val_acc: 0.7306\n",
      "Epoch 2336/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3065 - acc: 0.9806 - val_loss: 0.6629 - val_acc: 0.7288\n",
      "Epoch 2337/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9805 - val_loss: 0.6604 - val_acc: 0.7339\n",
      "Epoch 2338/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3065 - acc: 0.9800 - val_loss: 0.6621 - val_acc: 0.7266\n",
      "Epoch 2339/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3065 - acc: 0.9804 - val_loss: 0.6592 - val_acc: 0.7295\n",
      "Epoch 2340/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3064 - acc: 0.9815 - val_loss: 0.6595 - val_acc: 0.7251\n",
      "Epoch 2341/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9811 - val_loss: 0.6606 - val_acc: 0.7270\n",
      "Epoch 2342/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3063 - acc: 0.9819 - val_loss: 0.6605 - val_acc: 0.7292\n",
      "Epoch 2343/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3063 - acc: 0.9806 - val_loss: 0.6618 - val_acc: 0.7306\n",
      "Epoch 2344/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3065 - acc: 0.9798 - val_loss: 0.6603 - val_acc: 0.7339\n",
      "Epoch 2345/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3065 - acc: 0.9805 - val_loss: 0.6601 - val_acc: 0.7310\n",
      "Epoch 2346/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3064 - acc: 0.9799 - val_loss: 0.6622 - val_acc: 0.7306\n",
      "Epoch 2347/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9810 - val_loss: 0.6590 - val_acc: 0.7314\n",
      "Epoch 2348/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9804 - val_loss: 0.6593 - val_acc: 0.7361\n",
      "Epoch 2349/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9794 - val_loss: 0.6593 - val_acc: 0.7306\n",
      "Epoch 2350/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3066 - acc: 0.9788 - val_loss: 0.6639 - val_acc: 0.7350\n",
      "Epoch 2351/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3067 - acc: 0.9767 - val_loss: 0.6583 - val_acc: 0.7295\n",
      "Epoch 2352/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3066 - acc: 0.9800 - val_loss: 0.6605 - val_acc: 0.7321\n",
      "Epoch 2353/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3066 - acc: 0.9793 - val_loss: 0.6604 - val_acc: 0.7346\n",
      "Epoch 2354/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9804 - val_loss: 0.6587 - val_acc: 0.7306\n",
      "Epoch 2355/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3068 - acc: 0.9792 - val_loss: 0.6660 - val_acc: 0.7361\n",
      "Epoch 2356/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3075 - acc: 0.9766 - val_loss: 0.6671 - val_acc: 0.7273\n",
      "Epoch 2357/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3100 - acc: 0.9693 - val_loss: 0.6747 - val_acc: 0.7303\n",
      "Epoch 2358/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3112 - acc: 0.9673 - val_loss: 0.6737 - val_acc: 0.7306\n",
      "Epoch 2359/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3081 - acc: 0.9740 - val_loss: 0.6704 - val_acc: 0.7248\n",
      "Epoch 2360/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3070 - acc: 0.9775 - val_loss: 0.6684 - val_acc: 0.7273\n",
      "Epoch 2361/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9812 - val_loss: 0.6683 - val_acc: 0.7262\n",
      "Epoch 2362/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3064 - acc: 0.9800 - val_loss: 0.6692 - val_acc: 0.7317\n",
      "Epoch 2363/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6696 - val_acc: 0.7303\n",
      "Epoch 2364/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6669 - val_acc: 0.7303\n",
      "Epoch 2365/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9803 - val_loss: 0.6676 - val_acc: 0.7325\n",
      "Epoch 2366/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6657 - val_acc: 0.7310\n",
      "Epoch 2367/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9820 - val_loss: 0.6660 - val_acc: 0.7299\n",
      "Epoch 2368/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6655 - val_acc: 0.7306\n",
      "Epoch 2369/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6653 - val_acc: 0.7314\n",
      "Epoch 2370/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6661 - val_acc: 0.7306\n",
      "Epoch 2371/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6653 - val_acc: 0.7310\n",
      "Epoch 2372/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9846 - val_loss: 0.6656 - val_acc: 0.7306\n",
      "Epoch 2373/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9848 - val_loss: 0.6654 - val_acc: 0.7306\n",
      "Epoch 2374/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9841 - val_loss: 0.6658 - val_acc: 0.7310\n",
      "Epoch 2375/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6655 - val_acc: 0.7314\n",
      "Epoch 2376/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9845 - val_loss: 0.6654 - val_acc: 0.7317\n",
      "Epoch 2377/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6657 - val_acc: 0.7314\n",
      "Epoch 2378/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9845 - val_loss: 0.6659 - val_acc: 0.7317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2379/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9853 - val_loss: 0.6664 - val_acc: 0.7328\n",
      "Epoch 2380/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6662 - val_acc: 0.7288\n",
      "Epoch 2381/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9809 - val_loss: 0.6655 - val_acc: 0.7306\n",
      "Epoch 2382/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3064 - acc: 0.9798 - val_loss: 0.6650 - val_acc: 0.7310\n",
      "Epoch 2383/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9797 - val_loss: 0.6653 - val_acc: 0.7346\n",
      "Epoch 2384/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9803 - val_loss: 0.6646 - val_acc: 0.7284\n",
      "Epoch 2385/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9820 - val_loss: 0.6638 - val_acc: 0.7292\n",
      "Epoch 2386/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9812 - val_loss: 0.6624 - val_acc: 0.7325\n",
      "Epoch 2387/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9814 - val_loss: 0.6656 - val_acc: 0.7292\n",
      "Epoch 2388/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9809 - val_loss: 0.6623 - val_acc: 0.7306\n",
      "Epoch 2389/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6636 - val_acc: 0.7310\n",
      "Epoch 2390/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6639 - val_acc: 0.7310\n",
      "Epoch 2391/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6623 - val_acc: 0.7317\n",
      "Epoch 2392/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9809 - val_loss: 0.6656 - val_acc: 0.7299\n",
      "Epoch 2393/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6617 - val_acc: 0.7314\n",
      "Epoch 2394/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9797 - val_loss: 0.6647 - val_acc: 0.7295\n",
      "Epoch 2395/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9784 - val_loss: 0.6637 - val_acc: 0.7306\n",
      "Epoch 2396/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9776 - val_loss: 0.6617 - val_acc: 0.7354\n",
      "Epoch 2397/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9798 - val_loss: 0.6615 - val_acc: 0.7321\n",
      "Epoch 2398/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9798 - val_loss: 0.6619 - val_acc: 0.7336\n",
      "Epoch 2399/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6617 - val_acc: 0.7314\n",
      "Epoch 2400/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9816 - val_loss: 0.6614 - val_acc: 0.7325\n",
      "Epoch 2401/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6614 - val_acc: 0.7310\n",
      "Epoch 2402/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6609 - val_acc: 0.7314\n",
      "Epoch 2403/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9813 - val_loss: 0.6620 - val_acc: 0.7350\n",
      "Epoch 2404/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9812 - val_loss: 0.6607 - val_acc: 0.7310\n",
      "Epoch 2405/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9789 - val_loss: 0.6633 - val_acc: 0.7288\n",
      "Epoch 2406/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3079 - acc: 0.9719 - val_loss: 0.6730 - val_acc: 0.7314\n",
      "Epoch 2407/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3087 - acc: 0.9710 - val_loss: 0.6708 - val_acc: 0.7321\n",
      "Epoch 2408/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3073 - acc: 0.9743 - val_loss: 0.6661 - val_acc: 0.7317\n",
      "Epoch 2409/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9822 - val_loss: 0.6648 - val_acc: 0.7328\n",
      "Epoch 2410/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3064 - acc: 0.9818 - val_loss: 0.6653 - val_acc: 0.7350\n",
      "Epoch 2411/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9834 - val_loss: 0.6638 - val_acc: 0.7368\n",
      "Epoch 2412/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6631 - val_acc: 0.7350\n",
      "Epoch 2413/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9858 - val_loss: 0.6632 - val_acc: 0.7325\n",
      "Epoch 2414/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6632 - val_acc: 0.7328\n",
      "Epoch 2415/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9867 - val_loss: 0.6635 - val_acc: 0.7339\n",
      "Epoch 2416/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3058 - acc: 0.9861 - val_loss: 0.6637 - val_acc: 0.7343\n",
      "Epoch 2417/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9865 - val_loss: 0.6637 - val_acc: 0.7336\n",
      "Epoch 2418/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9864 - val_loss: 0.6635 - val_acc: 0.7336\n",
      "Epoch 2419/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9871 - val_loss: 0.6637 - val_acc: 0.7339\n",
      "Epoch 2420/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9866 - val_loss: 0.6632 - val_acc: 0.7346\n",
      "Epoch 2421/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9856 - val_loss: 0.6654 - val_acc: 0.7350\n",
      "Epoch 2422/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9839 - val_loss: 0.6632 - val_acc: 0.7328\n",
      "Epoch 2423/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6633 - val_acc: 0.7339\n",
      "Epoch 2424/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9814 - val_loss: 0.6641 - val_acc: 0.7332\n",
      "Epoch 2425/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3064 - acc: 0.9801 - val_loss: 0.6621 - val_acc: 0.7405\n",
      "Epoch 2426/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3065 - acc: 0.9783 - val_loss: 0.6640 - val_acc: 0.7328\n",
      "Epoch 2427/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3065 - acc: 0.9795 - val_loss: 0.6616 - val_acc: 0.7368\n",
      "Epoch 2428/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9805 - val_loss: 0.6632 - val_acc: 0.7303\n",
      "Epoch 2429/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6607 - val_acc: 0.7321\n",
      "Epoch 2430/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9823 - val_loss: 0.6618 - val_acc: 0.7361\n",
      "Epoch 2431/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6607 - val_acc: 0.7321\n",
      "Epoch 2432/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6606 - val_acc: 0.7325\n",
      "Epoch 2433/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9818 - val_loss: 0.6622 - val_acc: 0.7346\n",
      "Epoch 2434/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9802 - val_loss: 0.6597 - val_acc: 0.7317\n",
      "Epoch 2435/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9816 - val_loss: 0.6616 - val_acc: 0.7372\n",
      "Epoch 2436/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9777 - val_loss: 0.6626 - val_acc: 0.7325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2437/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9779 - val_loss: 0.6620 - val_acc: 0.7346\n",
      "Epoch 2438/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9809 - val_loss: 0.6604 - val_acc: 0.7336\n",
      "Epoch 2439/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6599 - val_acc: 0.7383\n",
      "Epoch 2440/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9839 - val_loss: 0.6593 - val_acc: 0.7336\n",
      "Epoch 2441/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6612 - val_acc: 0.7354\n",
      "Epoch 2442/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9819 - val_loss: 0.6615 - val_acc: 0.7343\n",
      "Epoch 2443/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9823 - val_loss: 0.6591 - val_acc: 0.7357\n",
      "Epoch 2444/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6617 - val_acc: 0.7332\n",
      "Epoch 2445/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9800 - val_loss: 0.6618 - val_acc: 0.7361\n",
      "Epoch 2446/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9812 - val_loss: 0.6604 - val_acc: 0.7310\n",
      "Epoch 2447/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9809 - val_loss: 0.6598 - val_acc: 0.7368\n",
      "Epoch 2448/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9795 - val_loss: 0.6613 - val_acc: 0.7354\n",
      "Epoch 2449/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3134 - acc: 0.9624 - val_loss: 0.6717 - val_acc: 0.7310\n",
      "Epoch 2450/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3148 - acc: 0.9572 - val_loss: 0.6797 - val_acc: 0.7255\n",
      "Epoch 2451/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3110 - acc: 0.9628 - val_loss: 0.6720 - val_acc: 0.7288\n",
      "Epoch 2452/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3082 - acc: 0.9717 - val_loss: 0.6643 - val_acc: 0.7303\n",
      "Epoch 2453/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3071 - acc: 0.9751 - val_loss: 0.6645 - val_acc: 0.7288\n",
      "Epoch 2454/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3067 - acc: 0.9780 - val_loss: 0.6658 - val_acc: 0.7288\n",
      "Epoch 2455/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9793 - val_loss: 0.6655 - val_acc: 0.7303\n",
      "Epoch 2456/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9800 - val_loss: 0.6655 - val_acc: 0.7295\n",
      "Epoch 2457/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9801 - val_loss: 0.6651 - val_acc: 0.7281\n",
      "Epoch 2458/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9821 - val_loss: 0.6654 - val_acc: 0.7273\n",
      "Epoch 2459/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6647 - val_acc: 0.7292\n",
      "Epoch 2460/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6651 - val_acc: 0.7284\n",
      "Epoch 2461/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9832 - val_loss: 0.6652 - val_acc: 0.7288\n",
      "Epoch 2462/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6654 - val_acc: 0.7277\n",
      "Epoch 2463/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6649 - val_acc: 0.7281\n",
      "Epoch 2464/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6652 - val_acc: 0.7277\n",
      "Epoch 2465/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6649 - val_acc: 0.7292\n",
      "Epoch 2466/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9848 - val_loss: 0.6650 - val_acc: 0.7288\n",
      "Epoch 2467/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6647 - val_acc: 0.7299\n",
      "Epoch 2468/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6647 - val_acc: 0.7299\n",
      "Epoch 2469/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6649 - val_acc: 0.7303\n",
      "Epoch 2470/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6647 - val_acc: 0.7292\n",
      "Epoch 2471/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6649 - val_acc: 0.7303\n",
      "Epoch 2472/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6647 - val_acc: 0.7299\n",
      "Epoch 2473/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9859 - val_loss: 0.6643 - val_acc: 0.7317\n",
      "Epoch 2474/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9855 - val_loss: 0.6646 - val_acc: 0.7310\n",
      "Epoch 2475/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9859 - val_loss: 0.6644 - val_acc: 0.7317\n",
      "Epoch 2476/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6645 - val_acc: 0.7314\n",
      "Epoch 2477/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9857 - val_loss: 0.6642 - val_acc: 0.7306\n",
      "Epoch 2478/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6631 - val_acc: 0.7321\n",
      "Epoch 2479/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6640 - val_acc: 0.7336\n",
      "Epoch 2480/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6636 - val_acc: 0.7299\n",
      "Epoch 2481/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6647 - val_acc: 0.7321\n",
      "Epoch 2482/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9830 - val_loss: 0.6632 - val_acc: 0.7346\n",
      "Epoch 2483/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9820 - val_loss: 0.6642 - val_acc: 0.7299\n",
      "Epoch 2484/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9801 - val_loss: 0.6620 - val_acc: 0.7288\n",
      "Epoch 2485/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9815 - val_loss: 0.6620 - val_acc: 0.7310\n",
      "Epoch 2486/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9797 - val_loss: 0.6616 - val_acc: 0.7336\n",
      "Epoch 2487/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9816 - val_loss: 0.6606 - val_acc: 0.7336\n",
      "Epoch 2488/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6601 - val_acc: 0.7361\n",
      "Epoch 2489/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6614 - val_acc: 0.7314\n",
      "Epoch 2490/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6614 - val_acc: 0.7357\n",
      "Epoch 2491/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6600 - val_acc: 0.7368\n",
      "Epoch 2492/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6604 - val_acc: 0.7357\n",
      "Epoch 2493/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9833 - val_loss: 0.6601 - val_acc: 0.7346\n",
      "Epoch 2494/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6589 - val_acc: 0.7328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2495/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9819 - val_loss: 0.6608 - val_acc: 0.7343\n",
      "Epoch 2496/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3062 - acc: 0.9815 - val_loss: 0.6616 - val_acc: 0.7368\n",
      "Epoch 2497/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6590 - val_acc: 0.7339\n",
      "Epoch 2498/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3062 - acc: 0.9795 - val_loss: 0.6611 - val_acc: 0.7368\n",
      "Epoch 2499/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9815 - val_loss: 0.6618 - val_acc: 0.7365\n",
      "Epoch 2500/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3064 - acc: 0.9796 - val_loss: 0.6640 - val_acc: 0.7339\n",
      "Epoch 2501/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3067 - acc: 0.9769 - val_loss: 0.6696 - val_acc: 0.7325\n",
      "Epoch 2502/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3068 - acc: 0.9790 - val_loss: 0.6677 - val_acc: 0.7284\n",
      "Epoch 2503/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3074 - acc: 0.9748 - val_loss: 0.6713 - val_acc: 0.7266\n",
      "Epoch 2504/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3074 - acc: 0.9751 - val_loss: 0.6651 - val_acc: 0.7277\n",
      "Epoch 2505/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3089 - acc: 0.9743 - val_loss: 0.6754 - val_acc: 0.7306\n",
      "Epoch 2506/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3078 - acc: 0.9746 - val_loss: 0.6680 - val_acc: 0.7343\n",
      "Epoch 2507/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3067 - acc: 0.9775 - val_loss: 0.6751 - val_acc: 0.7292\n",
      "Epoch 2508/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9793 - val_loss: 0.6724 - val_acc: 0.7314\n",
      "Epoch 2509/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6723 - val_acc: 0.7325\n",
      "Epoch 2510/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9814 - val_loss: 0.6719 - val_acc: 0.7346\n",
      "Epoch 2511/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9835 - val_loss: 0.6712 - val_acc: 0.7332\n",
      "Epoch 2512/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9830 - val_loss: 0.6719 - val_acc: 0.7325\n",
      "Epoch 2513/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6714 - val_acc: 0.7346\n",
      "Epoch 2514/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6721 - val_acc: 0.7332\n",
      "Epoch 2515/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6719 - val_acc: 0.7343\n",
      "Epoch 2516/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6721 - val_acc: 0.7332\n",
      "Epoch 2517/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6720 - val_acc: 0.7325\n",
      "Epoch 2518/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6717 - val_acc: 0.7339\n",
      "Epoch 2519/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9860 - val_loss: 0.6714 - val_acc: 0.7328\n",
      "Epoch 2520/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9848 - val_loss: 0.6714 - val_acc: 0.7317\n",
      "Epoch 2521/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6698 - val_acc: 0.7328\n",
      "Epoch 2522/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9846 - val_loss: 0.6716 - val_acc: 0.7310\n",
      "Epoch 2523/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6709 - val_acc: 0.7314\n",
      "Epoch 2524/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6708 - val_acc: 0.7303\n",
      "Epoch 2525/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6699 - val_acc: 0.7354\n",
      "Epoch 2526/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6703 - val_acc: 0.7295\n",
      "Epoch 2527/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6706 - val_acc: 0.7303\n",
      "Epoch 2528/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9813 - val_loss: 0.6693 - val_acc: 0.7328\n",
      "Epoch 2529/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9804 - val_loss: 0.6708 - val_acc: 0.7314\n",
      "Epoch 2530/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3063 - acc: 0.9804 - val_loss: 0.6693 - val_acc: 0.7295\n",
      "Epoch 2531/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9796 - val_loss: 0.6692 - val_acc: 0.7328\n",
      "Epoch 2532/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3061 - acc: 0.9828 - val_loss: 0.6687 - val_acc: 0.7314\n",
      "Epoch 2533/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6690 - val_acc: 0.7332\n",
      "Epoch 2534/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9832 - val_loss: 0.6691 - val_acc: 0.7325\n",
      "Epoch 2535/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6682 - val_acc: 0.7310\n",
      "Epoch 2536/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6688 - val_acc: 0.7295\n",
      "Epoch 2537/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6667 - val_acc: 0.7317\n",
      "Epoch 2538/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9820 - val_loss: 0.6690 - val_acc: 0.7339\n",
      "Epoch 2539/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9812 - val_loss: 0.6675 - val_acc: 0.7284\n",
      "Epoch 2540/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9810 - val_loss: 0.6671 - val_acc: 0.7350\n",
      "Epoch 2541/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3062 - acc: 0.9805 - val_loss: 0.6685 - val_acc: 0.7299\n",
      "Epoch 2542/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9831 - val_loss: 0.6661 - val_acc: 0.7328\n",
      "Epoch 2543/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9815 - val_loss: 0.6671 - val_acc: 0.7314\n",
      "Epoch 2544/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6661 - val_acc: 0.7317\n",
      "Epoch 2545/10000\n",
      "4259/4259 [==============================] - 2s 461us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6677 - val_acc: 0.7328\n",
      "Epoch 2546/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6646 - val_acc: 0.7343\n",
      "Epoch 2547/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9830 - val_loss: 0.6656 - val_acc: 0.7310\n",
      "Epoch 2548/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6665 - val_acc: 0.7317\n",
      "Epoch 2549/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9805 - val_loss: 0.6706 - val_acc: 0.7317\n",
      "Epoch 2550/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9792 - val_loss: 0.6666 - val_acc: 0.7306\n",
      "Epoch 2551/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9800 - val_loss: 0.6705 - val_acc: 0.7314\n",
      "Epoch 2552/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9793 - val_loss: 0.6695 - val_acc: 0.7281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2553/10000\n",
      "4259/4259 [==============================] - 2s 462us/step - loss: 0.3061 - acc: 0.9801 - val_loss: 0.6698 - val_acc: 0.7325\n",
      "Epoch 2554/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9806 - val_loss: 0.6697 - val_acc: 0.7321\n",
      "Epoch 2555/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9820 - val_loss: 0.6695 - val_acc: 0.7314\n",
      "Epoch 2556/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6680 - val_acc: 0.7350\n",
      "Epoch 2557/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6678 - val_acc: 0.7292\n",
      "Epoch 2558/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6697 - val_acc: 0.7328\n",
      "Epoch 2559/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6674 - val_acc: 0.7328\n",
      "Epoch 2560/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6685 - val_acc: 0.7332\n",
      "Epoch 2561/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9783 - val_loss: 0.6680 - val_acc: 0.7368\n",
      "Epoch 2562/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3062 - acc: 0.9795 - val_loss: 0.6665 - val_acc: 0.7317\n",
      "Epoch 2563/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9806 - val_loss: 0.6675 - val_acc: 0.7321\n",
      "Epoch 2564/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9814 - val_loss: 0.6685 - val_acc: 0.7332\n",
      "Epoch 2565/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9812 - val_loss: 0.6666 - val_acc: 0.7343\n",
      "Epoch 2566/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6681 - val_acc: 0.7339\n",
      "Epoch 2567/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9809 - val_loss: 0.6668 - val_acc: 0.7317\n",
      "Epoch 2568/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6690 - val_acc: 0.7328\n",
      "Epoch 2569/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3072 - acc: 0.9746 - val_loss: 0.6710 - val_acc: 0.7270\n",
      "Epoch 2570/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3123 - acc: 0.9667 - val_loss: 0.6767 - val_acc: 0.7292\n",
      "Epoch 2571/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3112 - acc: 0.9662 - val_loss: 0.6815 - val_acc: 0.7310\n",
      "Epoch 2572/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3086 - acc: 0.9712 - val_loss: 0.6711 - val_acc: 0.7332\n",
      "Epoch 2573/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3077 - acc: 0.9748 - val_loss: 0.6804 - val_acc: 0.7248\n",
      "Epoch 2574/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3091 - acc: 0.9710 - val_loss: 0.6770 - val_acc: 0.7270\n",
      "Epoch 2575/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3070 - acc: 0.9764 - val_loss: 0.6767 - val_acc: 0.7266\n",
      "Epoch 2576/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3066 - acc: 0.9778 - val_loss: 0.6759 - val_acc: 0.7277\n",
      "Epoch 2577/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9793 - val_loss: 0.6749 - val_acc: 0.7292\n",
      "Epoch 2578/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9800 - val_loss: 0.6735 - val_acc: 0.7295\n",
      "Epoch 2579/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9804 - val_loss: 0.6738 - val_acc: 0.7295\n",
      "Epoch 2580/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9809 - val_loss: 0.6735 - val_acc: 0.7295\n",
      "Epoch 2581/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6740 - val_acc: 0.7288\n",
      "Epoch 2582/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6740 - val_acc: 0.7277\n",
      "Epoch 2583/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9822 - val_loss: 0.6740 - val_acc: 0.7284\n",
      "Epoch 2584/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9824 - val_loss: 0.6742 - val_acc: 0.7281\n",
      "Epoch 2585/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9834 - val_loss: 0.6743 - val_acc: 0.7277\n",
      "Epoch 2586/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9832 - val_loss: 0.6738 - val_acc: 0.7281\n",
      "Epoch 2587/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9831 - val_loss: 0.6742 - val_acc: 0.7284\n",
      "Epoch 2588/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9829 - val_loss: 0.6742 - val_acc: 0.7251\n",
      "Epoch 2589/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6745 - val_acc: 0.7273\n",
      "Epoch 2590/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9840 - val_loss: 0.6742 - val_acc: 0.7281\n",
      "Epoch 2591/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9841 - val_loss: 0.6747 - val_acc: 0.7277\n",
      "Epoch 2592/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9841 - val_loss: 0.6744 - val_acc: 0.7295\n",
      "Epoch 2593/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6748 - val_acc: 0.7270\n",
      "Epoch 2594/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9843 - val_loss: 0.6748 - val_acc: 0.7292\n",
      "Epoch 2595/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9842 - val_loss: 0.6744 - val_acc: 0.7295\n",
      "Epoch 2596/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9844 - val_loss: 0.6747 - val_acc: 0.7284\n",
      "Epoch 2597/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9848 - val_loss: 0.6746 - val_acc: 0.7277\n",
      "Epoch 2598/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9848 - val_loss: 0.6741 - val_acc: 0.7292\n",
      "Epoch 2599/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6743 - val_acc: 0.7284\n",
      "Epoch 2600/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9844 - val_loss: 0.6743 - val_acc: 0.7295\n",
      "Epoch 2601/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9840 - val_loss: 0.6751 - val_acc: 0.7277\n",
      "Epoch 2602/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6749 - val_acc: 0.7277\n",
      "Epoch 2603/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6737 - val_acc: 0.7310\n",
      "Epoch 2604/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6742 - val_acc: 0.7303\n",
      "Epoch 2605/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6738 - val_acc: 0.7273\n",
      "Epoch 2606/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9801 - val_loss: 0.6720 - val_acc: 0.7277\n",
      "Epoch 2607/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9795 - val_loss: 0.6756 - val_acc: 0.7321\n",
      "Epoch 2608/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9801 - val_loss: 0.6732 - val_acc: 0.7240\n",
      "Epoch 2609/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9810 - val_loss: 0.6733 - val_acc: 0.7306\n",
      "Epoch 2610/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9791 - val_loss: 0.6722 - val_acc: 0.7306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2611/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9792 - val_loss: 0.6760 - val_acc: 0.7273\n",
      "Epoch 2612/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3068 - acc: 0.9776 - val_loss: 0.6726 - val_acc: 0.7317\n",
      "Epoch 2613/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3063 - acc: 0.9792 - val_loss: 0.6739 - val_acc: 0.7317\n",
      "Epoch 2614/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6734 - val_acc: 0.7303\n",
      "Epoch 2615/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6754 - val_acc: 0.7306\n",
      "Epoch 2616/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6731 - val_acc: 0.7288\n",
      "Epoch 2617/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6747 - val_acc: 0.7281\n",
      "Epoch 2618/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6739 - val_acc: 0.7299\n",
      "Epoch 2619/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9828 - val_loss: 0.6746 - val_acc: 0.7306\n",
      "Epoch 2620/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9826 - val_loss: 0.6741 - val_acc: 0.7277\n",
      "Epoch 2621/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6743 - val_acc: 0.7314\n",
      "Epoch 2622/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6753 - val_acc: 0.7303\n",
      "Epoch 2623/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6762 - val_acc: 0.7343\n",
      "Epoch 2624/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6748 - val_acc: 0.7310\n",
      "Epoch 2625/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9800 - val_loss: 0.6736 - val_acc: 0.7295\n",
      "Epoch 2626/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3064 - acc: 0.9782 - val_loss: 0.6712 - val_acc: 0.7303\n",
      "Epoch 2627/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3064 - acc: 0.9789 - val_loss: 0.6745 - val_acc: 0.7288\n",
      "Epoch 2628/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3082 - acc: 0.9761 - val_loss: 0.6725 - val_acc: 0.7273\n",
      "Epoch 2629/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3169 - acc: 0.9613 - val_loss: 0.6810 - val_acc: 0.7167\n",
      "Epoch 2630/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3121 - acc: 0.9630 - val_loss: 0.6750 - val_acc: 0.7230\n",
      "Epoch 2631/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3086 - acc: 0.9705 - val_loss: 0.6721 - val_acc: 0.7270\n",
      "Epoch 2632/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3074 - acc: 0.9737 - val_loss: 0.6724 - val_acc: 0.7270\n",
      "Epoch 2633/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3070 - acc: 0.9746 - val_loss: 0.6719 - val_acc: 0.7266\n",
      "Epoch 2634/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3069 - acc: 0.9761 - val_loss: 0.6734 - val_acc: 0.7281\n",
      "Epoch 2635/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3066 - acc: 0.9777 - val_loss: 0.6734 - val_acc: 0.7277\n",
      "Epoch 2636/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3065 - acc: 0.9781 - val_loss: 0.6732 - val_acc: 0.7277\n",
      "Epoch 2637/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3064 - acc: 0.9793 - val_loss: 0.6737 - val_acc: 0.7288\n",
      "Epoch 2638/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3063 - acc: 0.9789 - val_loss: 0.6736 - val_acc: 0.7240\n",
      "Epoch 2639/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3062 - acc: 0.9793 - val_loss: 0.6738 - val_acc: 0.7266\n",
      "Epoch 2640/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6743 - val_acc: 0.7251\n",
      "Epoch 2641/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6745 - val_acc: 0.7255\n",
      "Epoch 2642/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6740 - val_acc: 0.7266\n",
      "Epoch 2643/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6736 - val_acc: 0.7292\n",
      "Epoch 2644/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6738 - val_acc: 0.7266\n",
      "Epoch 2645/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6736 - val_acc: 0.7266\n",
      "Epoch 2646/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6735 - val_acc: 0.7273\n",
      "Epoch 2647/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6736 - val_acc: 0.7251\n",
      "Epoch 2648/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6735 - val_acc: 0.7262\n",
      "Epoch 2649/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6733 - val_acc: 0.7255\n",
      "Epoch 2650/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6731 - val_acc: 0.7273\n",
      "Epoch 2651/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6730 - val_acc: 0.7259\n",
      "Epoch 2652/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9834 - val_loss: 0.6729 - val_acc: 0.7273\n",
      "Epoch 2653/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6734 - val_acc: 0.7284\n",
      "Epoch 2654/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6730 - val_acc: 0.7284\n",
      "Epoch 2655/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6730 - val_acc: 0.7270\n",
      "Epoch 2656/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6733 - val_acc: 0.7277\n",
      "Epoch 2657/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9831 - val_loss: 0.6729 - val_acc: 0.7273\n",
      "Epoch 2658/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6726 - val_acc: 0.7277\n",
      "Epoch 2659/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6729 - val_acc: 0.7262\n",
      "Epoch 2660/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6725 - val_acc: 0.7281\n",
      "Epoch 2661/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6730 - val_acc: 0.7266\n",
      "Epoch 2662/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3059 - acc: 0.9832 - val_loss: 0.6726 - val_acc: 0.7255\n",
      "Epoch 2663/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6729 - val_acc: 0.7284\n",
      "Epoch 2664/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3061 - acc: 0.9836 - val_loss: 0.6739 - val_acc: 0.7273\n",
      "Epoch 2665/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3068 - acc: 0.9779 - val_loss: 0.6822 - val_acc: 0.7178\n",
      "Epoch 2666/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3112 - acc: 0.9649 - val_loss: 0.6804 - val_acc: 0.7240\n",
      "Epoch 2667/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3087 - acc: 0.9718 - val_loss: 0.6693 - val_acc: 0.7292\n",
      "Epoch 2668/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3072 - acc: 0.9758 - val_loss: 0.6687 - val_acc: 0.7332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2669/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3072 - acc: 0.9768 - val_loss: 0.6766 - val_acc: 0.7314\n",
      "Epoch 2670/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3073 - acc: 0.9768 - val_loss: 0.6762 - val_acc: 0.7317\n",
      "Epoch 2671/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3067 - acc: 0.9807 - val_loss: 0.6755 - val_acc: 0.7314\n",
      "Epoch 2672/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3083 - acc: 0.9767 - val_loss: 0.6814 - val_acc: 0.7288\n",
      "Epoch 2673/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3082 - acc: 0.9728 - val_loss: 0.6817 - val_acc: 0.7288\n",
      "Epoch 2674/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3070 - acc: 0.9790 - val_loss: 0.6782 - val_acc: 0.7303\n",
      "Epoch 2675/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3065 - acc: 0.9801 - val_loss: 0.6784 - val_acc: 0.7299\n",
      "Epoch 2676/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3063 - acc: 0.9821 - val_loss: 0.6777 - val_acc: 0.7306\n",
      "Epoch 2677/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3062 - acc: 0.9826 - val_loss: 0.6772 - val_acc: 0.7314\n",
      "Epoch 2678/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3061 - acc: 0.9834 - val_loss: 0.6770 - val_acc: 0.7306\n",
      "Epoch 2679/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9838 - val_loss: 0.6768 - val_acc: 0.7299\n",
      "Epoch 2680/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9835 - val_loss: 0.6764 - val_acc: 0.7277\n",
      "Epoch 2681/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3060 - acc: 0.9837 - val_loss: 0.6766 - val_acc: 0.7303\n",
      "Epoch 2682/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3061 - acc: 0.9843 - val_loss: 0.6774 - val_acc: 0.7284\n",
      "Epoch 2683/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6759 - val_acc: 0.7306\n",
      "Epoch 2684/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6764 - val_acc: 0.7314\n",
      "Epoch 2685/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6761 - val_acc: 0.7310\n",
      "Epoch 2686/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6758 - val_acc: 0.7295\n",
      "Epoch 2687/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6760 - val_acc: 0.7310\n",
      "Epoch 2688/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6758 - val_acc: 0.7303\n",
      "Epoch 2689/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9853 - val_loss: 0.6764 - val_acc: 0.7306\n",
      "Epoch 2690/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6760 - val_acc: 0.7299\n",
      "Epoch 2691/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6759 - val_acc: 0.7310\n",
      "Epoch 2692/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9856 - val_loss: 0.6744 - val_acc: 0.7321\n",
      "Epoch 2693/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9856 - val_loss: 0.6757 - val_acc: 0.7292\n",
      "Epoch 2694/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3059 - acc: 0.9859 - val_loss: 0.6749 - val_acc: 0.7306\n",
      "Epoch 2695/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6754 - val_acc: 0.7343\n",
      "Epoch 2696/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6752 - val_acc: 0.7306\n",
      "Epoch 2697/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3060 - acc: 0.9847 - val_loss: 0.6746 - val_acc: 0.7365\n",
      "Epoch 2698/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3060 - acc: 0.9838 - val_loss: 0.6754 - val_acc: 0.7314\n",
      "Epoch 2699/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3061 - acc: 0.9832 - val_loss: 0.6749 - val_acc: 0.7303\n",
      "Epoch 2700/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3079 - acc: 0.9764 - val_loss: 0.6803 - val_acc: 0.7379\n",
      "Epoch 2701/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3102 - acc: 0.9707 - val_loss: 0.6814 - val_acc: 0.7281\n",
      "Epoch 2702/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3118 - acc: 0.9642 - val_loss: 0.6798 - val_acc: 0.7303\n",
      "Epoch 2703/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3102 - acc: 0.9681 - val_loss: 0.6821 - val_acc: 0.7343\n",
      "Epoch 2704/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3107 - acc: 0.9685 - val_loss: 0.6915 - val_acc: 0.7284\n",
      "Epoch 2705/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3107 - acc: 0.9667 - val_loss: 0.6849 - val_acc: 0.7328\n",
      "Epoch 2706/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3088 - acc: 0.9719 - val_loss: 0.6833 - val_acc: 0.7299\n",
      "Epoch 2707/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3077 - acc: 0.9750 - val_loss: 0.6837 - val_acc: 0.7303\n",
      "Epoch 2708/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3073 - acc: 0.9768 - val_loss: 0.6827 - val_acc: 0.7336\n",
      "Epoch 2709/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3071 - acc: 0.9779 - val_loss: 0.6843 - val_acc: 0.7325\n",
      "Epoch 2710/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3069 - acc: 0.9781 - val_loss: 0.6840 - val_acc: 0.7328\n",
      "Epoch 2711/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3068 - acc: 0.9797 - val_loss: 0.6830 - val_acc: 0.7350\n",
      "Epoch 2712/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3067 - acc: 0.9801 - val_loss: 0.6830 - val_acc: 0.7336\n",
      "Epoch 2713/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3071 - acc: 0.9780 - val_loss: 0.6762 - val_acc: 0.7321\n",
      "Epoch 2714/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3083 - acc: 0.9727 - val_loss: 0.6759 - val_acc: 0.7357\n",
      "Epoch 2715/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3067 - acc: 0.9777 - val_loss: 0.6746 - val_acc: 0.7379\n",
      "Epoch 2716/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3064 - acc: 0.9786 - val_loss: 0.6752 - val_acc: 0.7376\n",
      "Epoch 2717/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6756 - val_acc: 0.7365\n",
      "Epoch 2718/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3062 - acc: 0.9816 - val_loss: 0.6754 - val_acc: 0.7361\n",
      "Epoch 2719/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6757 - val_acc: 0.7354\n",
      "Epoch 2720/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6761 - val_acc: 0.7361\n",
      "Epoch 2721/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6760 - val_acc: 0.7365\n",
      "Epoch 2722/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6759 - val_acc: 0.7357\n",
      "Epoch 2723/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3060 - acc: 0.9831 - val_loss: 0.6759 - val_acc: 0.7365\n",
      "Epoch 2724/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3060 - acc: 0.9832 - val_loss: 0.6755 - val_acc: 0.7357\n",
      "Epoch 2725/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3060 - acc: 0.9832 - val_loss: 0.6757 - val_acc: 0.7372\n",
      "Epoch 2726/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6756 - val_acc: 0.7361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2727/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6754 - val_acc: 0.7354\n",
      "Epoch 2728/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6756 - val_acc: 0.7357\n",
      "Epoch 2729/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6755 - val_acc: 0.7357\n",
      "Epoch 2730/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6751 - val_acc: 0.7354\n",
      "Epoch 2731/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6754 - val_acc: 0.7361\n",
      "Epoch 2732/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6755 - val_acc: 0.7368\n",
      "Epoch 2733/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6753 - val_acc: 0.7357\n",
      "Epoch 2734/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6754 - val_acc: 0.7361\n",
      "Epoch 2735/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6754 - val_acc: 0.7346\n",
      "Epoch 2736/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6752 - val_acc: 0.7343\n",
      "Epoch 2737/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6747 - val_acc: 0.7354\n",
      "Epoch 2738/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6748 - val_acc: 0.7350\n",
      "Epoch 2739/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6748 - val_acc: 0.7361\n",
      "Epoch 2740/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6753 - val_acc: 0.7350\n",
      "Epoch 2741/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6739 - val_acc: 0.7379\n",
      "Epoch 2742/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6747 - val_acc: 0.7383\n",
      "Epoch 2743/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3062 - acc: 0.9812 - val_loss: 0.6763 - val_acc: 0.7361\n",
      "Epoch 2744/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3063 - acc: 0.9811 - val_loss: 0.6728 - val_acc: 0.7357\n",
      "Epoch 2745/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3064 - acc: 0.9797 - val_loss: 0.6734 - val_acc: 0.7401\n",
      "Epoch 2746/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3064 - acc: 0.9790 - val_loss: 0.6754 - val_acc: 0.7328\n",
      "Epoch 2747/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3063 - acc: 0.9801 - val_loss: 0.6767 - val_acc: 0.7361\n",
      "Epoch 2748/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9815 - val_loss: 0.6729 - val_acc: 0.7354\n",
      "Epoch 2749/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6737 - val_acc: 0.7365\n",
      "Epoch 2750/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6728 - val_acc: 0.7368\n",
      "Epoch 2751/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9831 - val_loss: 0.6735 - val_acc: 0.7357\n",
      "Epoch 2752/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6723 - val_acc: 0.7376\n",
      "Epoch 2753/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6726 - val_acc: 0.7361\n",
      "Epoch 2754/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9816 - val_loss: 0.6727 - val_acc: 0.7357\n",
      "Epoch 2755/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6716 - val_acc: 0.7361\n",
      "Epoch 2756/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3062 - acc: 0.9803 - val_loss: 0.6738 - val_acc: 0.7379\n",
      "Epoch 2757/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3065 - acc: 0.9791 - val_loss: 0.6740 - val_acc: 0.7379\n",
      "Epoch 2758/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3067 - acc: 0.9771 - val_loss: 0.6738 - val_acc: 0.7332\n",
      "Epoch 2759/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3082 - acc: 0.9710 - val_loss: 0.6776 - val_acc: 0.7346\n",
      "Epoch 2760/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3202 - acc: 0.9568 - val_loss: 0.6824 - val_acc: 0.7295\n",
      "Epoch 2761/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3135 - acc: 0.9641 - val_loss: 0.6781 - val_acc: 0.7303\n",
      "Epoch 2762/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3095 - acc: 0.9708 - val_loss: 0.6776 - val_acc: 0.7266\n",
      "Epoch 2763/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3078 - acc: 0.9739 - val_loss: 0.6714 - val_acc: 0.7292\n",
      "Epoch 2764/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3071 - acc: 0.9775 - val_loss: 0.6693 - val_acc: 0.7284\n",
      "Epoch 2765/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3068 - acc: 0.9784 - val_loss: 0.6694 - val_acc: 0.7306\n",
      "Epoch 2766/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3066 - acc: 0.9802 - val_loss: 0.6685 - val_acc: 0.7306\n",
      "Epoch 2767/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3065 - acc: 0.9809 - val_loss: 0.6701 - val_acc: 0.7295\n",
      "Epoch 2768/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3064 - acc: 0.9818 - val_loss: 0.6704 - val_acc: 0.7288\n",
      "Epoch 2769/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3063 - acc: 0.9821 - val_loss: 0.6694 - val_acc: 0.7299\n",
      "Epoch 2770/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3062 - acc: 0.9826 - val_loss: 0.6695 - val_acc: 0.7281\n",
      "Epoch 2771/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3062 - acc: 0.9834 - val_loss: 0.6690 - val_acc: 0.7277\n",
      "Epoch 2772/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6690 - val_acc: 0.7288\n",
      "Epoch 2773/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3061 - acc: 0.9837 - val_loss: 0.6681 - val_acc: 0.7281\n",
      "Epoch 2774/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3060 - acc: 0.9845 - val_loss: 0.6683 - val_acc: 0.7284\n",
      "Epoch 2775/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3060 - acc: 0.9853 - val_loss: 0.6681 - val_acc: 0.7281\n",
      "Epoch 2776/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3060 - acc: 0.9847 - val_loss: 0.6676 - val_acc: 0.7273\n",
      "Epoch 2777/10000\n",
      "4259/4259 [==============================] - 2s 508us/step - loss: 0.3060 - acc: 0.9853 - val_loss: 0.6680 - val_acc: 0.7288\n",
      "Epoch 2778/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9851 - val_loss: 0.6678 - val_acc: 0.7273\n",
      "Epoch 2779/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3060 - acc: 0.9854 - val_loss: 0.6681 - val_acc: 0.7270\n",
      "Epoch 2780/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3060 - acc: 0.9851 - val_loss: 0.6679 - val_acc: 0.7277\n",
      "Epoch 2781/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9858 - val_loss: 0.6679 - val_acc: 0.7277\n",
      "Epoch 2782/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9857 - val_loss: 0.6677 - val_acc: 0.7273\n",
      "Epoch 2783/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3059 - acc: 0.9864 - val_loss: 0.6680 - val_acc: 0.7281\n",
      "Epoch 2784/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9857 - val_loss: 0.6676 - val_acc: 0.7295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2785/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9858 - val_loss: 0.6676 - val_acc: 0.7284\n",
      "Epoch 2786/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9861 - val_loss: 0.6678 - val_acc: 0.7281\n",
      "Epoch 2787/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9865 - val_loss: 0.6675 - val_acc: 0.7303\n",
      "Epoch 2788/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6668 - val_acc: 0.7273\n",
      "Epoch 2789/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9853 - val_loss: 0.6670 - val_acc: 0.7273\n",
      "Epoch 2790/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9857 - val_loss: 0.6674 - val_acc: 0.7299\n",
      "Epoch 2791/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3060 - acc: 0.9851 - val_loss: 0.6659 - val_acc: 0.7317\n",
      "Epoch 2792/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6680 - val_acc: 0.7310\n",
      "Epoch 2793/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9835 - val_loss: 0.6673 - val_acc: 0.7310\n",
      "Epoch 2794/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3063 - acc: 0.9814 - val_loss: 0.6666 - val_acc: 0.7317\n",
      "Epoch 2795/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3063 - acc: 0.9824 - val_loss: 0.6638 - val_acc: 0.7325\n",
      "Epoch 2796/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3063 - acc: 0.9814 - val_loss: 0.6655 - val_acc: 0.7314\n",
      "Epoch 2797/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3067 - acc: 0.9782 - val_loss: 0.6707 - val_acc: 0.7317\n",
      "Epoch 2798/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3069 - acc: 0.9788 - val_loss: 0.6688 - val_acc: 0.7306\n",
      "Epoch 2799/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3106 - acc: 0.9690 - val_loss: 0.6782 - val_acc: 0.7328\n",
      "Epoch 2800/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3237 - acc: 0.9497 - val_loss: 0.6800 - val_acc: 0.7208\n",
      "Epoch 2801/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3140 - acc: 0.9624 - val_loss: 0.6799 - val_acc: 0.7226\n",
      "Epoch 2802/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3097 - acc: 0.9685 - val_loss: 0.6742 - val_acc: 0.7288\n",
      "Epoch 2803/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3084 - acc: 0.9717 - val_loss: 0.6781 - val_acc: 0.7259\n",
      "Epoch 2804/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3078 - acc: 0.9736 - val_loss: 0.6770 - val_acc: 0.7306\n",
      "Epoch 2805/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3079 - acc: 0.9748 - val_loss: 0.6769 - val_acc: 0.7321\n",
      "Epoch 2806/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3070 - acc: 0.9770 - val_loss: 0.6771 - val_acc: 0.7354\n",
      "Epoch 2807/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3068 - acc: 0.9783 - val_loss: 0.6770 - val_acc: 0.7357\n",
      "Epoch 2808/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3066 - acc: 0.9800 - val_loss: 0.6761 - val_acc: 0.7339\n",
      "Epoch 2809/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3065 - acc: 0.9806 - val_loss: 0.6765 - val_acc: 0.7336\n",
      "Epoch 2810/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3064 - acc: 0.9808 - val_loss: 0.6747 - val_acc: 0.7325\n",
      "Epoch 2811/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3063 - acc: 0.9815 - val_loss: 0.6752 - val_acc: 0.7346\n",
      "Epoch 2812/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3062 - acc: 0.9810 - val_loss: 0.6756 - val_acc: 0.7325\n",
      "Epoch 2813/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3072 - acc: 0.9790 - val_loss: 0.6690 - val_acc: 0.7303\n",
      "Epoch 2814/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3079 - acc: 0.9744 - val_loss: 0.6729 - val_acc: 0.7262\n",
      "Epoch 2815/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3068 - acc: 0.9773 - val_loss: 0.6736 - val_acc: 0.7314\n",
      "Epoch 2816/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3064 - acc: 0.9803 - val_loss: 0.6724 - val_acc: 0.7281\n",
      "Epoch 2817/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3063 - acc: 0.9814 - val_loss: 0.6731 - val_acc: 0.7288\n",
      "Epoch 2818/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6735 - val_acc: 0.7284\n",
      "Epoch 2819/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3062 - acc: 0.9824 - val_loss: 0.6731 - val_acc: 0.7288\n",
      "Epoch 2820/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6724 - val_acc: 0.7288\n",
      "Epoch 2821/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6719 - val_acc: 0.7288\n",
      "Epoch 2822/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6717 - val_acc: 0.7292\n",
      "Epoch 2823/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6716 - val_acc: 0.7292\n",
      "Epoch 2824/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6710 - val_acc: 0.7295\n",
      "Epoch 2825/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6713 - val_acc: 0.7281\n",
      "Epoch 2826/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6713 - val_acc: 0.7292\n",
      "Epoch 2827/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6714 - val_acc: 0.7295\n",
      "Epoch 2828/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6710 - val_acc: 0.7310\n",
      "Epoch 2829/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6711 - val_acc: 0.7306\n",
      "Epoch 2830/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6715 - val_acc: 0.7303\n",
      "Epoch 2831/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6713 - val_acc: 0.7314\n",
      "Epoch 2832/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6715 - val_acc: 0.7299\n",
      "Epoch 2833/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6713 - val_acc: 0.7317\n",
      "Epoch 2834/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3059 - acc: 0.9858 - val_loss: 0.6710 - val_acc: 0.7306\n",
      "Epoch 2835/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3059 - acc: 0.9853 - val_loss: 0.6717 - val_acc: 0.7317\n",
      "Epoch 2836/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3059 - acc: 0.9848 - val_loss: 0.6718 - val_acc: 0.7310\n",
      "Epoch 2837/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6721 - val_acc: 0.7303\n",
      "Epoch 2838/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6725 - val_acc: 0.7321\n",
      "Epoch 2839/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6704 - val_acc: 0.7299\n",
      "Epoch 2840/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3061 - acc: 0.9830 - val_loss: 0.6727 - val_acc: 0.7310\n",
      "Epoch 2841/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6724 - val_acc: 0.7295\n",
      "Epoch 2842/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6720 - val_acc: 0.7277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2843/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6721 - val_acc: 0.7325\n",
      "Epoch 2844/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3062 - acc: 0.9796 - val_loss: 0.6697 - val_acc: 0.7310\n",
      "Epoch 2845/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3075 - acc: 0.9739 - val_loss: 0.6783 - val_acc: 0.7281\n",
      "Epoch 2846/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3145 - acc: 0.9609 - val_loss: 0.6958 - val_acc: 0.7197\n",
      "Epoch 2847/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3126 - acc: 0.9634 - val_loss: 0.6936 - val_acc: 0.7226\n",
      "Epoch 2848/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3136 - acc: 0.9629 - val_loss: 0.6917 - val_acc: 0.7233\n",
      "Epoch 2849/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3106 - acc: 0.9671 - val_loss: 0.6905 - val_acc: 0.7230\n",
      "Epoch 2850/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3091 - acc: 0.9708 - val_loss: 0.6939 - val_acc: 0.7230\n",
      "Epoch 2851/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3076 - acc: 0.9748 - val_loss: 0.6906 - val_acc: 0.7248\n",
      "Epoch 2852/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3071 - acc: 0.9770 - val_loss: 0.6909 - val_acc: 0.7197\n",
      "Epoch 2853/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3068 - acc: 0.9772 - val_loss: 0.6894 - val_acc: 0.7237\n",
      "Epoch 2854/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3066 - acc: 0.9781 - val_loss: 0.6893 - val_acc: 0.7226\n",
      "Epoch 2855/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3065 - acc: 0.9790 - val_loss: 0.6891 - val_acc: 0.7233\n",
      "Epoch 2856/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3064 - acc: 0.9786 - val_loss: 0.6889 - val_acc: 0.7237\n",
      "Epoch 2857/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3063 - acc: 0.9805 - val_loss: 0.6880 - val_acc: 0.7208\n",
      "Epoch 2858/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6877 - val_acc: 0.7222\n",
      "Epoch 2859/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3062 - acc: 0.9818 - val_loss: 0.6872 - val_acc: 0.7240\n",
      "Epoch 2860/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6880 - val_acc: 0.7230\n",
      "Epoch 2861/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6874 - val_acc: 0.7240\n",
      "Epoch 2862/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6876 - val_acc: 0.7266\n",
      "Epoch 2863/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6872 - val_acc: 0.7240\n",
      "Epoch 2864/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3060 - acc: 0.9834 - val_loss: 0.6869 - val_acc: 0.7244\n",
      "Epoch 2865/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6868 - val_acc: 0.7259\n",
      "Epoch 2866/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6870 - val_acc: 0.7273\n",
      "Epoch 2867/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6866 - val_acc: 0.7262\n",
      "Epoch 2868/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6865 - val_acc: 0.7259\n",
      "Epoch 2869/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6865 - val_acc: 0.7248\n",
      "Epoch 2870/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6862 - val_acc: 0.7273\n",
      "Epoch 2871/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6863 - val_acc: 0.7262\n",
      "Epoch 2872/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6861 - val_acc: 0.7251\n",
      "Epoch 2873/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6858 - val_acc: 0.7248\n",
      "Epoch 2874/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6862 - val_acc: 0.7255\n",
      "Epoch 2875/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6860 - val_acc: 0.7281\n",
      "Epoch 2876/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6862 - val_acc: 0.7259\n",
      "Epoch 2877/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6854 - val_acc: 0.7273\n",
      "Epoch 2878/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6866 - val_acc: 0.7266\n",
      "Epoch 2879/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6850 - val_acc: 0.7266\n",
      "Epoch 2880/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6863 - val_acc: 0.7262\n",
      "Epoch 2881/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6843 - val_acc: 0.7270\n",
      "Epoch 2882/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6851 - val_acc: 0.7255\n",
      "Epoch 2883/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6837 - val_acc: 0.7262\n",
      "Epoch 2884/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9824 - val_loss: 0.6844 - val_acc: 0.7277\n",
      "Epoch 2885/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6843 - val_acc: 0.7219\n",
      "Epoch 2886/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3062 - acc: 0.9813 - val_loss: 0.6839 - val_acc: 0.7255\n",
      "Epoch 2887/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6816 - val_acc: 0.7288\n",
      "Epoch 2888/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6821 - val_acc: 0.7266\n",
      "Epoch 2889/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6813 - val_acc: 0.7255\n",
      "Epoch 2890/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3061 - acc: 0.9817 - val_loss: 0.6818 - val_acc: 0.7255\n",
      "Epoch 2891/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6823 - val_acc: 0.7266\n",
      "Epoch 2892/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3101 - acc: 0.9703 - val_loss: 0.6827 - val_acc: 0.7208\n",
      "Epoch 2893/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3109 - acc: 0.9674 - val_loss: 0.6893 - val_acc: 0.7343\n",
      "Epoch 2894/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3092 - acc: 0.9734 - val_loss: 0.6815 - val_acc: 0.7303\n",
      "Epoch 2895/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3077 - acc: 0.9764 - val_loss: 0.6810 - val_acc: 0.7288\n",
      "Epoch 2896/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3075 - acc: 0.9790 - val_loss: 0.6795 - val_acc: 0.7299\n",
      "Epoch 2897/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3078 - acc: 0.9790 - val_loss: 0.6857 - val_acc: 0.7281\n",
      "Epoch 2898/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3106 - acc: 0.9743 - val_loss: 0.6813 - val_acc: 0.7215\n",
      "Epoch 2899/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3108 - acc: 0.9735 - val_loss: 0.6811 - val_acc: 0.7193\n",
      "Epoch 2900/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3101 - acc: 0.9715 - val_loss: 0.6841 - val_acc: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2901/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3086 - acc: 0.9758 - val_loss: 0.6864 - val_acc: 0.7233\n",
      "Epoch 2902/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3080 - acc: 0.9786 - val_loss: 0.6866 - val_acc: 0.7233\n",
      "Epoch 2903/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3078 - acc: 0.9803 - val_loss: 0.6855 - val_acc: 0.7288\n",
      "Epoch 2904/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3076 - acc: 0.9810 - val_loss: 0.6849 - val_acc: 0.7270\n",
      "Epoch 2905/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3075 - acc: 0.9822 - val_loss: 0.6850 - val_acc: 0.7266\n",
      "Epoch 2906/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3075 - acc: 0.9822 - val_loss: 0.6844 - val_acc: 0.7288\n",
      "Epoch 2907/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3074 - acc: 0.9827 - val_loss: 0.6843 - val_acc: 0.7277\n",
      "Epoch 2908/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3074 - acc: 0.9827 - val_loss: 0.6834 - val_acc: 0.7277\n",
      "Epoch 2909/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3073 - acc: 0.9825 - val_loss: 0.6832 - val_acc: 0.7281\n",
      "Epoch 2910/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3073 - acc: 0.9835 - val_loss: 0.6829 - val_acc: 0.7281\n",
      "Epoch 2911/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3073 - acc: 0.9837 - val_loss: 0.6828 - val_acc: 0.7292\n",
      "Epoch 2912/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3073 - acc: 0.9835 - val_loss: 0.6813 - val_acc: 0.7281\n",
      "Epoch 2913/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3072 - acc: 0.9831 - val_loss: 0.6816 - val_acc: 0.7295\n",
      "Epoch 2914/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3072 - acc: 0.9833 - val_loss: 0.6815 - val_acc: 0.7277\n",
      "Epoch 2915/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3072 - acc: 0.9840 - val_loss: 0.6814 - val_acc: 0.7270\n",
      "Epoch 2916/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3072 - acc: 0.9838 - val_loss: 0.6812 - val_acc: 0.7288\n",
      "Epoch 2917/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3072 - acc: 0.9840 - val_loss: 0.6814 - val_acc: 0.7281\n",
      "Epoch 2918/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3072 - acc: 0.9843 - val_loss: 0.6809 - val_acc: 0.7284\n",
      "Epoch 2919/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3072 - acc: 0.9846 - val_loss: 0.6807 - val_acc: 0.7299\n",
      "Epoch 2920/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3072 - acc: 0.9848 - val_loss: 0.6807 - val_acc: 0.7303\n",
      "Epoch 2921/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3072 - acc: 0.9839 - val_loss: 0.6801 - val_acc: 0.7306\n",
      "Epoch 2922/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3072 - acc: 0.9843 - val_loss: 0.6810 - val_acc: 0.7277\n",
      "Epoch 2923/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3072 - acc: 0.9838 - val_loss: 0.6806 - val_acc: 0.7292\n",
      "Epoch 2924/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3072 - acc: 0.9840 - val_loss: 0.6802 - val_acc: 0.7321\n",
      "Epoch 2925/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3072 - acc: 0.9837 - val_loss: 0.6816 - val_acc: 0.7277\n",
      "Epoch 2926/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3072 - acc: 0.9839 - val_loss: 0.6823 - val_acc: 0.7292\n",
      "Epoch 2927/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3073 - acc: 0.9824 - val_loss: 0.6809 - val_acc: 0.7299\n",
      "Epoch 2928/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3073 - acc: 0.9824 - val_loss: 0.6822 - val_acc: 0.7292\n",
      "Epoch 2929/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3074 - acc: 0.9823 - val_loss: 0.6794 - val_acc: 0.7284\n",
      "Epoch 2930/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3074 - acc: 0.9806 - val_loss: 0.6795 - val_acc: 0.7310\n",
      "Epoch 2931/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3074 - acc: 0.9804 - val_loss: 0.6796 - val_acc: 0.7328\n",
      "Epoch 2932/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3074 - acc: 0.9811 - val_loss: 0.6797 - val_acc: 0.7295\n",
      "Epoch 2933/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3074 - acc: 0.9809 - val_loss: 0.6781 - val_acc: 0.7299\n",
      "Epoch 2934/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3074 - acc: 0.9813 - val_loss: 0.6788 - val_acc: 0.7321\n",
      "Epoch 2935/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3075 - acc: 0.9797 - val_loss: 0.6786 - val_acc: 0.7321\n",
      "Epoch 2936/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3077 - acc: 0.9792 - val_loss: 0.6761 - val_acc: 0.7266\n",
      "Epoch 2937/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3083 - acc: 0.9763 - val_loss: 0.6794 - val_acc: 0.7255\n",
      "Epoch 2938/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3084 - acc: 0.9775 - val_loss: 0.6784 - val_acc: 0.7299\n",
      "Epoch 2939/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3079 - acc: 0.9778 - val_loss: 0.6786 - val_acc: 0.7310\n",
      "Epoch 2940/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3076 - acc: 0.9818 - val_loss: 0.6762 - val_acc: 0.7284\n",
      "Epoch 2941/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3074 - acc: 0.9832 - val_loss: 0.6765 - val_acc: 0.7310\n",
      "Epoch 2942/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3074 - acc: 0.9841 - val_loss: 0.6768 - val_acc: 0.7310\n",
      "Epoch 2943/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3074 - acc: 0.9828 - val_loss: 0.6756 - val_acc: 0.7303\n",
      "Epoch 2944/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3074 - acc: 0.9846 - val_loss: 0.6766 - val_acc: 0.7310\n",
      "Epoch 2945/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3074 - acc: 0.9838 - val_loss: 0.6755 - val_acc: 0.7299\n",
      "Epoch 2946/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3074 - acc: 0.9836 - val_loss: 0.6754 - val_acc: 0.7325\n",
      "Epoch 2947/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3075 - acc: 0.9825 - val_loss: 0.6757 - val_acc: 0.7281\n",
      "Epoch 2948/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3077 - acc: 0.9817 - val_loss: 0.6754 - val_acc: 0.7306\n",
      "Epoch 2949/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3077 - acc: 0.9800 - val_loss: 0.6752 - val_acc: 0.7284\n",
      "Epoch 2950/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3078 - acc: 0.9793 - val_loss: 0.6763 - val_acc: 0.7277\n",
      "Epoch 2951/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3077 - acc: 0.9804 - val_loss: 0.6768 - val_acc: 0.7295\n",
      "Epoch 2952/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3077 - acc: 0.9798 - val_loss: 0.6748 - val_acc: 0.7321\n",
      "Epoch 2953/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3076 - acc: 0.9811 - val_loss: 0.6754 - val_acc: 0.7336\n",
      "Epoch 2954/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3076 - acc: 0.9804 - val_loss: 0.6745 - val_acc: 0.7288\n",
      "Epoch 2955/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3078 - acc: 0.9802 - val_loss: 0.6740 - val_acc: 0.7281\n",
      "Epoch 2956/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3078 - acc: 0.9789 - val_loss: 0.6750 - val_acc: 0.7295\n",
      "Epoch 2957/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3079 - acc: 0.9788 - val_loss: 0.6729 - val_acc: 0.7328\n",
      "Epoch 2958/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3079 - acc: 0.9782 - val_loss: 0.6724 - val_acc: 0.7303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2959/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3078 - acc: 0.9794 - val_loss: 0.6722 - val_acc: 0.7303\n",
      "Epoch 2960/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3075 - acc: 0.9806 - val_loss: 0.6729 - val_acc: 0.7314\n",
      "Epoch 2961/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3075 - acc: 0.9789 - val_loss: 0.6735 - val_acc: 0.7321\n",
      "Epoch 2962/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3076 - acc: 0.9792 - val_loss: 0.6740 - val_acc: 0.7303\n",
      "Epoch 2963/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3077 - acc: 0.9799 - val_loss: 0.6765 - val_acc: 0.7332\n",
      "Epoch 2964/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3075 - acc: 0.9805 - val_loss: 0.6702 - val_acc: 0.7332\n",
      "Epoch 2965/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3074 - acc: 0.9797 - val_loss: 0.6711 - val_acc: 0.7328\n",
      "Epoch 2966/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3074 - acc: 0.9820 - val_loss: 0.6773 - val_acc: 0.7299\n",
      "Epoch 2967/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3075 - acc: 0.9799 - val_loss: 0.6751 - val_acc: 0.7325\n",
      "Epoch 2968/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3074 - acc: 0.9807 - val_loss: 0.6740 - val_acc: 0.7310\n",
      "Epoch 2969/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3079 - acc: 0.9801 - val_loss: 0.6745 - val_acc: 0.7277\n",
      "Epoch 2970/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3088 - acc: 0.9750 - val_loss: 0.6722 - val_acc: 0.7270\n",
      "Epoch 2971/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3112 - acc: 0.9721 - val_loss: 0.6778 - val_acc: 0.7299\n",
      "Epoch 2972/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3099 - acc: 0.9721 - val_loss: 0.6705 - val_acc: 0.7336\n",
      "Epoch 2973/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3092 - acc: 0.9743 - val_loss: 0.6681 - val_acc: 0.7339\n",
      "Epoch 2974/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3078 - acc: 0.9760 - val_loss: 0.6662 - val_acc: 0.7321\n",
      "Epoch 2975/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3070 - acc: 0.9775 - val_loss: 0.6692 - val_acc: 0.7354\n",
      "Epoch 2976/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3067 - acc: 0.9800 - val_loss: 0.6677 - val_acc: 0.7354\n",
      "Epoch 2977/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3066 - acc: 0.9808 - val_loss: 0.6705 - val_acc: 0.7321\n",
      "Epoch 2978/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9813 - val_loss: 0.6693 - val_acc: 0.7325\n",
      "Epoch 2979/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9817 - val_loss: 0.6688 - val_acc: 0.7321\n",
      "Epoch 2980/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3064 - acc: 0.9820 - val_loss: 0.6690 - val_acc: 0.7303\n",
      "Epoch 2981/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9818 - val_loss: 0.6683 - val_acc: 0.7306\n",
      "Epoch 2982/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3063 - acc: 0.9825 - val_loss: 0.6688 - val_acc: 0.7328\n",
      "Epoch 2983/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9834 - val_loss: 0.6686 - val_acc: 0.7325\n",
      "Epoch 2984/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9835 - val_loss: 0.6685 - val_acc: 0.7303\n",
      "Epoch 2985/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9837 - val_loss: 0.6687 - val_acc: 0.7328\n",
      "Epoch 2986/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3063 - acc: 0.9846 - val_loss: 0.6687 - val_acc: 0.7303\n",
      "Epoch 2987/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9844 - val_loss: 0.6676 - val_acc: 0.7281\n",
      "Epoch 2988/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9826 - val_loss: 0.6703 - val_acc: 0.7310\n",
      "Epoch 2989/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9820 - val_loss: 0.6696 - val_acc: 0.7284\n",
      "Epoch 2990/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6699 - val_acc: 0.7321\n",
      "Epoch 2991/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9832 - val_loss: 0.6692 - val_acc: 0.7295\n",
      "Epoch 2992/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9839 - val_loss: 0.6691 - val_acc: 0.7325\n",
      "Epoch 2993/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9837 - val_loss: 0.6688 - val_acc: 0.7299\n",
      "Epoch 2994/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6691 - val_acc: 0.7310\n",
      "Epoch 2995/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9835 - val_loss: 0.6688 - val_acc: 0.7303\n",
      "Epoch 2996/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9835 - val_loss: 0.6684 - val_acc: 0.7328\n",
      "Epoch 2997/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6697 - val_acc: 0.7314\n",
      "Epoch 2998/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6702 - val_acc: 0.7299\n",
      "Epoch 2999/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9816 - val_loss: 0.6689 - val_acc: 0.7306\n",
      "Epoch 3000/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9813 - val_loss: 0.6682 - val_acc: 0.7314\n",
      "Epoch 3001/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9799 - val_loss: 0.6683 - val_acc: 0.7339\n",
      "Epoch 3002/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3065 - acc: 0.9799 - val_loss: 0.6675 - val_acc: 0.7306\n",
      "Epoch 3003/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9793 - val_loss: 0.6663 - val_acc: 0.7303\n",
      "Epoch 3004/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9793 - val_loss: 0.6681 - val_acc: 0.7303\n",
      "Epoch 3005/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9792 - val_loss: 0.6676 - val_acc: 0.7339\n",
      "Epoch 3006/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9807 - val_loss: 0.6682 - val_acc: 0.7292\n",
      "Epoch 3007/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9805 - val_loss: 0.6688 - val_acc: 0.7277\n",
      "Epoch 3008/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9817 - val_loss: 0.6669 - val_acc: 0.7321\n",
      "Epoch 3009/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9806 - val_loss: 0.6665 - val_acc: 0.7292\n",
      "Epoch 3010/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9824 - val_loss: 0.6664 - val_acc: 0.7299\n",
      "Epoch 3011/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9803 - val_loss: 0.6686 - val_acc: 0.7303\n",
      "Epoch 3012/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9819 - val_loss: 0.6670 - val_acc: 0.7284\n",
      "Epoch 3013/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9817 - val_loss: 0.6648 - val_acc: 0.7317\n",
      "Epoch 3014/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9798 - val_loss: 0.6695 - val_acc: 0.7255\n",
      "Epoch 3015/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3074 - acc: 0.9808 - val_loss: 0.6683 - val_acc: 0.7314\n",
      "Epoch 3016/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3156 - acc: 0.9660 - val_loss: 0.6855 - val_acc: 0.7273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3017/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3162 - acc: 0.9627 - val_loss: 0.6775 - val_acc: 0.7233\n",
      "Epoch 3018/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3120 - acc: 0.9696 - val_loss: 0.6770 - val_acc: 0.7240\n",
      "Epoch 3019/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3101 - acc: 0.9736 - val_loss: 0.6773 - val_acc: 0.7273\n",
      "Epoch 3020/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3092 - acc: 0.9763 - val_loss: 0.6773 - val_acc: 0.7237\n",
      "Epoch 3021/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3087 - acc: 0.9771 - val_loss: 0.6756 - val_acc: 0.7251\n",
      "Epoch 3022/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3085 - acc: 0.9785 - val_loss: 0.6757 - val_acc: 0.7244\n",
      "Epoch 3023/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3083 - acc: 0.9793 - val_loss: 0.6755 - val_acc: 0.7251\n",
      "Epoch 3024/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3082 - acc: 0.9800 - val_loss: 0.6747 - val_acc: 0.7237\n",
      "Epoch 3025/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3081 - acc: 0.9807 - val_loss: 0.6744 - val_acc: 0.7262\n",
      "Epoch 3026/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3064 - acc: 0.9813 - val_loss: 0.6756 - val_acc: 0.7266\n",
      "Epoch 3027/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9813 - val_loss: 0.6747 - val_acc: 0.7251\n",
      "Epoch 3028/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6748 - val_acc: 0.7230\n",
      "Epoch 3029/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6743 - val_acc: 0.7240\n",
      "Epoch 3030/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9837 - val_loss: 0.6748 - val_acc: 0.7240\n",
      "Epoch 3031/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6745 - val_acc: 0.7248\n",
      "Epoch 3032/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3060 - acc: 0.9851 - val_loss: 0.6747 - val_acc: 0.7237\n",
      "Epoch 3033/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6749 - val_acc: 0.7240\n",
      "Epoch 3034/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6746 - val_acc: 0.7233\n",
      "Epoch 3035/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9848 - val_loss: 0.6748 - val_acc: 0.7233\n",
      "Epoch 3036/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6747 - val_acc: 0.7230\n",
      "Epoch 3037/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6748 - val_acc: 0.7240\n",
      "Epoch 3038/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9856 - val_loss: 0.6741 - val_acc: 0.7237\n",
      "Epoch 3039/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6743 - val_acc: 0.7237\n",
      "Epoch 3040/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6748 - val_acc: 0.7244\n",
      "Epoch 3041/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6744 - val_acc: 0.7251\n",
      "Epoch 3042/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6746 - val_acc: 0.7244\n",
      "Epoch 3043/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9855 - val_loss: 0.6743 - val_acc: 0.7244\n",
      "Epoch 3044/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6743 - val_acc: 0.7244\n",
      "Epoch 3045/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9858 - val_loss: 0.6747 - val_acc: 0.7259\n",
      "Epoch 3046/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6743 - val_acc: 0.7251\n",
      "Epoch 3047/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6745 - val_acc: 0.7273\n",
      "Epoch 3048/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6741 - val_acc: 0.7251\n",
      "Epoch 3049/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9814 - val_loss: 0.6740 - val_acc: 0.7233\n",
      "Epoch 3050/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9806 - val_loss: 0.6729 - val_acc: 0.7277\n",
      "Epoch 3051/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3062 - acc: 0.9814 - val_loss: 0.6718 - val_acc: 0.7244\n",
      "Epoch 3052/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3062 - acc: 0.9810 - val_loss: 0.6714 - val_acc: 0.7288\n",
      "Epoch 3053/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3063 - acc: 0.9804 - val_loss: 0.6699 - val_acc: 0.7270\n",
      "Epoch 3054/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3063 - acc: 0.9790 - val_loss: 0.6711 - val_acc: 0.7284\n",
      "Epoch 3055/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6687 - val_acc: 0.7259\n",
      "Epoch 3056/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6708 - val_acc: 0.7237\n",
      "Epoch 3057/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9819 - val_loss: 0.6698 - val_acc: 0.7259\n",
      "Epoch 3058/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6686 - val_acc: 0.7284\n",
      "Epoch 3059/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6695 - val_acc: 0.7270\n",
      "Epoch 3060/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6685 - val_acc: 0.7295\n",
      "Epoch 3061/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6706 - val_acc: 0.7281\n",
      "Epoch 3062/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6684 - val_acc: 0.7288\n",
      "Epoch 3063/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9802 - val_loss: 0.6686 - val_acc: 0.7310\n",
      "Epoch 3064/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9802 - val_loss: 0.6684 - val_acc: 0.7266\n",
      "Epoch 3065/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9803 - val_loss: 0.6677 - val_acc: 0.7317\n",
      "Epoch 3066/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9802 - val_loss: 0.6681 - val_acc: 0.7321\n",
      "Epoch 3067/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6671 - val_acc: 0.7266\n",
      "Epoch 3068/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9794 - val_loss: 0.6675 - val_acc: 0.7306\n",
      "Epoch 3069/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6673 - val_acc: 0.7295\n",
      "Epoch 3070/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9799 - val_loss: 0.6688 - val_acc: 0.7281\n",
      "Epoch 3071/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6639 - val_acc: 0.7262\n",
      "Epoch 3072/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9802 - val_loss: 0.6656 - val_acc: 0.7306\n",
      "Epoch 3073/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9801 - val_loss: 0.6645 - val_acc: 0.7284\n",
      "Epoch 3074/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9799 - val_loss: 0.6655 - val_acc: 0.7343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3075/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6646 - val_acc: 0.7299\n",
      "Epoch 3076/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3061 - acc: 0.9802 - val_loss: 0.6674 - val_acc: 0.7314\n",
      "Epoch 3077/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9795 - val_loss: 0.6654 - val_acc: 0.7295\n",
      "Epoch 3078/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6636 - val_acc: 0.7281\n",
      "Epoch 3079/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3062 - acc: 0.9794 - val_loss: 0.6621 - val_acc: 0.7343\n",
      "Epoch 3080/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6637 - val_acc: 0.7314\n",
      "Epoch 3081/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6647 - val_acc: 0.7317\n",
      "Epoch 3082/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9799 - val_loss: 0.6644 - val_acc: 0.7303\n",
      "Epoch 3083/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3061 - acc: 0.9814 - val_loss: 0.6637 - val_acc: 0.7325\n",
      "Epoch 3084/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9805 - val_loss: 0.6635 - val_acc: 0.7299\n",
      "Epoch 3085/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6631 - val_acc: 0.7314\n",
      "Epoch 3086/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6621 - val_acc: 0.7306\n",
      "Epoch 3087/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9796 - val_loss: 0.6640 - val_acc: 0.7321\n",
      "Epoch 3088/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9810 - val_loss: 0.6661 - val_acc: 0.7346\n",
      "Epoch 3089/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3062 - acc: 0.9801 - val_loss: 0.6635 - val_acc: 0.7332\n",
      "Epoch 3090/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9796 - val_loss: 0.6614 - val_acc: 0.7314\n",
      "Epoch 3091/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9800 - val_loss: 0.6609 - val_acc: 0.7336\n",
      "Epoch 3092/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3063 - acc: 0.9789 - val_loss: 0.6657 - val_acc: 0.7299\n",
      "Epoch 3093/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9789 - val_loss: 0.6608 - val_acc: 0.7295\n",
      "Epoch 3094/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9804 - val_loss: 0.6636 - val_acc: 0.7368\n",
      "Epoch 3095/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6635 - val_acc: 0.7368\n",
      "Epoch 3096/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9799 - val_loss: 0.6664 - val_acc: 0.7346\n",
      "Epoch 3097/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9797 - val_loss: 0.6620 - val_acc: 0.7354\n",
      "Epoch 3098/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6654 - val_acc: 0.7292\n",
      "Epoch 3099/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9804 - val_loss: 0.6636 - val_acc: 0.7328\n",
      "Epoch 3100/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6652 - val_acc: 0.7372\n",
      "Epoch 3101/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9791 - val_loss: 0.6735 - val_acc: 0.7332\n",
      "Epoch 3102/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3071 - acc: 0.9768 - val_loss: 0.6736 - val_acc: 0.7310\n",
      "Epoch 3103/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3113 - acc: 0.9656 - val_loss: 0.6763 - val_acc: 0.7303\n",
      "Epoch 3104/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3128 - acc: 0.9646 - val_loss: 0.6738 - val_acc: 0.7343\n",
      "Epoch 3105/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3099 - acc: 0.9686 - val_loss: 0.6748 - val_acc: 0.7339\n",
      "Epoch 3106/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3079 - acc: 0.9746 - val_loss: 0.6700 - val_acc: 0.7365\n",
      "Epoch 3107/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3071 - acc: 0.9774 - val_loss: 0.6732 - val_acc: 0.7379\n",
      "Epoch 3108/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3067 - acc: 0.9792 - val_loss: 0.6712 - val_acc: 0.7416\n",
      "Epoch 3109/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3065 - acc: 0.9798 - val_loss: 0.6710 - val_acc: 0.7405\n",
      "Epoch 3110/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9810 - val_loss: 0.6709 - val_acc: 0.7409\n",
      "Epoch 3111/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9818 - val_loss: 0.6708 - val_acc: 0.7420\n",
      "Epoch 3112/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9812 - val_loss: 0.6703 - val_acc: 0.7420\n",
      "Epoch 3113/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6696 - val_acc: 0.7423\n",
      "Epoch 3114/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9830 - val_loss: 0.6692 - val_acc: 0.7409\n",
      "Epoch 3115/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9835 - val_loss: 0.6692 - val_acc: 0.7423\n",
      "Epoch 3116/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6689 - val_acc: 0.7416\n",
      "Epoch 3117/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6688 - val_acc: 0.7420\n",
      "Epoch 3118/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6687 - val_acc: 0.7412\n",
      "Epoch 3119/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6686 - val_acc: 0.7416\n",
      "Epoch 3120/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6683 - val_acc: 0.7420\n",
      "Epoch 3121/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9845 - val_loss: 0.6683 - val_acc: 0.7398\n",
      "Epoch 3122/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6679 - val_acc: 0.7405\n",
      "Epoch 3123/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6680 - val_acc: 0.7420\n",
      "Epoch 3124/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6679 - val_acc: 0.7401\n",
      "Epoch 3125/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6681 - val_acc: 0.7409\n",
      "Epoch 3126/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6675 - val_acc: 0.7412\n",
      "Epoch 3127/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6675 - val_acc: 0.7420\n",
      "Epoch 3128/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6677 - val_acc: 0.7423\n",
      "Epoch 3129/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6669 - val_acc: 0.7405\n",
      "Epoch 3130/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6674 - val_acc: 0.7420\n",
      "Epoch 3131/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6670 - val_acc: 0.7409\n",
      "Epoch 3132/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9845 - val_loss: 0.6666 - val_acc: 0.7405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3133/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9832 - val_loss: 0.6665 - val_acc: 0.7394\n",
      "Epoch 3134/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6657 - val_acc: 0.7383\n",
      "Epoch 3135/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6656 - val_acc: 0.7398\n",
      "Epoch 3136/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9810 - val_loss: 0.6658 - val_acc: 0.7449\n",
      "Epoch 3137/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9796 - val_loss: 0.6694 - val_acc: 0.7379\n",
      "Epoch 3138/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9799 - val_loss: 0.6670 - val_acc: 0.7372\n",
      "Epoch 3139/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6661 - val_acc: 0.7409\n",
      "Epoch 3140/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3062 - acc: 0.9822 - val_loss: 0.6669 - val_acc: 0.7405\n",
      "Epoch 3141/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6654 - val_acc: 0.7387\n",
      "Epoch 3142/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6670 - val_acc: 0.7383\n",
      "Epoch 3143/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9823 - val_loss: 0.6654 - val_acc: 0.7434\n",
      "Epoch 3144/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6661 - val_acc: 0.7398\n",
      "Epoch 3145/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6649 - val_acc: 0.7401\n",
      "Epoch 3146/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6657 - val_acc: 0.7401\n",
      "Epoch 3147/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3112 - acc: 0.9681 - val_loss: 0.6806 - val_acc: 0.7270\n",
      "Epoch 3148/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3156 - acc: 0.9559 - val_loss: 0.6775 - val_acc: 0.7325\n",
      "Epoch 3149/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3093 - acc: 0.9677 - val_loss: 0.6706 - val_acc: 0.7346\n",
      "Epoch 3150/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3078 - acc: 0.9722 - val_loss: 0.6670 - val_acc: 0.7361\n",
      "Epoch 3151/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3070 - acc: 0.9751 - val_loss: 0.6696 - val_acc: 0.7357\n",
      "Epoch 3152/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3067 - acc: 0.9773 - val_loss: 0.6682 - val_acc: 0.7383\n",
      "Epoch 3153/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3065 - acc: 0.9793 - val_loss: 0.6688 - val_acc: 0.7376\n",
      "Epoch 3154/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3064 - acc: 0.9797 - val_loss: 0.6687 - val_acc: 0.7379\n",
      "Epoch 3155/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6695 - val_acc: 0.7357\n",
      "Epoch 3156/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9818 - val_loss: 0.6706 - val_acc: 0.7379\n",
      "Epoch 3157/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9820 - val_loss: 0.6704 - val_acc: 0.7368\n",
      "Epoch 3158/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3063 - acc: 0.9810 - val_loss: 0.6730 - val_acc: 0.7394\n",
      "Epoch 3159/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9815 - val_loss: 0.6709 - val_acc: 0.7434\n",
      "Epoch 3160/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6730 - val_acc: 0.7445\n",
      "Epoch 3161/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6717 - val_acc: 0.7452\n",
      "Epoch 3162/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6719 - val_acc: 0.7463\n",
      "Epoch 3163/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6719 - val_acc: 0.7431\n",
      "Epoch 3164/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6716 - val_acc: 0.7423\n",
      "Epoch 3165/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6717 - val_acc: 0.7427\n",
      "Epoch 3166/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6718 - val_acc: 0.7434\n",
      "Epoch 3167/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9853 - val_loss: 0.6715 - val_acc: 0.7442\n",
      "Epoch 3168/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9857 - val_loss: 0.6714 - val_acc: 0.7423\n",
      "Epoch 3169/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9855 - val_loss: 0.6713 - val_acc: 0.7416\n",
      "Epoch 3170/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6713 - val_acc: 0.7434\n",
      "Epoch 3171/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6706 - val_acc: 0.7431\n",
      "Epoch 3172/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6704 - val_acc: 0.7420\n",
      "Epoch 3173/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6705 - val_acc: 0.7409\n",
      "Epoch 3174/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9848 - val_loss: 0.6707 - val_acc: 0.7438\n",
      "Epoch 3175/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6699 - val_acc: 0.7401\n",
      "Epoch 3176/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9840 - val_loss: 0.6710 - val_acc: 0.7427\n",
      "Epoch 3177/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6695 - val_acc: 0.7412\n",
      "Epoch 3178/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6696 - val_acc: 0.7420\n",
      "Epoch 3179/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6689 - val_acc: 0.7460\n",
      "Epoch 3180/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9812 - val_loss: 0.6700 - val_acc: 0.7409\n",
      "Epoch 3181/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6688 - val_acc: 0.7434\n",
      "Epoch 3182/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9789 - val_loss: 0.6696 - val_acc: 0.7398\n",
      "Epoch 3183/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9793 - val_loss: 0.6679 - val_acc: 0.7412\n",
      "Epoch 3184/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9806 - val_loss: 0.6697 - val_acc: 0.7398\n",
      "Epoch 3185/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9800 - val_loss: 0.6672 - val_acc: 0.7427\n",
      "Epoch 3186/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9814 - val_loss: 0.6697 - val_acc: 0.7394\n",
      "Epoch 3187/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3067 - acc: 0.9787 - val_loss: 0.6648 - val_acc: 0.7339\n",
      "Epoch 3188/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3114 - acc: 0.9697 - val_loss: 0.6732 - val_acc: 0.7332\n",
      "Epoch 3189/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3126 - acc: 0.9642 - val_loss: 0.6743 - val_acc: 0.7303\n",
      "Epoch 3190/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3120 - acc: 0.9680 - val_loss: 0.6658 - val_acc: 0.7288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3191/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3088 - acc: 0.9731 - val_loss: 0.6650 - val_acc: 0.7237\n",
      "Epoch 3192/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3075 - acc: 0.9765 - val_loss: 0.6622 - val_acc: 0.7277\n",
      "Epoch 3193/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3070 - acc: 0.9787 - val_loss: 0.6620 - val_acc: 0.7277\n",
      "Epoch 3194/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3067 - acc: 0.9789 - val_loss: 0.6610 - val_acc: 0.7295\n",
      "Epoch 3195/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3065 - acc: 0.9814 - val_loss: 0.6602 - val_acc: 0.7292\n",
      "Epoch 3196/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9811 - val_loss: 0.6611 - val_acc: 0.7306\n",
      "Epoch 3197/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3063 - acc: 0.9819 - val_loss: 0.6602 - val_acc: 0.7292\n",
      "Epoch 3198/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6597 - val_acc: 0.7310\n",
      "Epoch 3199/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9829 - val_loss: 0.6603 - val_acc: 0.7310\n",
      "Epoch 3200/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9842 - val_loss: 0.6602 - val_acc: 0.7332\n",
      "Epoch 3201/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9846 - val_loss: 0.6605 - val_acc: 0.7328\n",
      "Epoch 3202/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6601 - val_acc: 0.7288\n",
      "Epoch 3203/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9852 - val_loss: 0.6601 - val_acc: 0.7266\n",
      "Epoch 3204/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9848 - val_loss: 0.6605 - val_acc: 0.7310\n",
      "Epoch 3205/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9856 - val_loss: 0.6608 - val_acc: 0.7306\n",
      "Epoch 3206/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9859 - val_loss: 0.6606 - val_acc: 0.7310\n",
      "Epoch 3207/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6604 - val_acc: 0.7303\n",
      "Epoch 3208/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9858 - val_loss: 0.6610 - val_acc: 0.7310\n",
      "Epoch 3209/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9856 - val_loss: 0.6606 - val_acc: 0.7306\n",
      "Epoch 3210/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9862 - val_loss: 0.6607 - val_acc: 0.7310\n",
      "Epoch 3211/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9859 - val_loss: 0.6606 - val_acc: 0.7328\n",
      "Epoch 3212/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9863 - val_loss: 0.6613 - val_acc: 0.7299\n",
      "Epoch 3213/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9861 - val_loss: 0.6613 - val_acc: 0.7317\n",
      "Epoch 3214/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9859 - val_loss: 0.6616 - val_acc: 0.7321\n",
      "Epoch 3215/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9861 - val_loss: 0.6615 - val_acc: 0.7317\n",
      "Epoch 3216/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9861 - val_loss: 0.6614 - val_acc: 0.7317\n",
      "Epoch 3217/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9853 - val_loss: 0.6619 - val_acc: 0.7325\n",
      "Epoch 3218/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9861 - val_loss: 0.6623 - val_acc: 0.7314\n",
      "Epoch 3219/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6635 - val_acc: 0.7332\n",
      "Epoch 3220/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6621 - val_acc: 0.7332\n",
      "Epoch 3221/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6635 - val_acc: 0.7321\n",
      "Epoch 3222/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6639 - val_acc: 0.7336\n",
      "Epoch 3223/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9837 - val_loss: 0.6646 - val_acc: 0.7332\n",
      "Epoch 3224/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6645 - val_acc: 0.7321\n",
      "Epoch 3225/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9824 - val_loss: 0.6640 - val_acc: 0.7350\n",
      "Epoch 3226/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9834 - val_loss: 0.6647 - val_acc: 0.7325\n",
      "Epoch 3227/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9814 - val_loss: 0.6627 - val_acc: 0.7387\n",
      "Epoch 3228/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6636 - val_acc: 0.7346\n",
      "Epoch 3229/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6629 - val_acc: 0.7357\n",
      "Epoch 3230/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9817 - val_loss: 0.6633 - val_acc: 0.7354\n",
      "Epoch 3231/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6631 - val_acc: 0.7346\n",
      "Epoch 3232/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6641 - val_acc: 0.7339\n",
      "Epoch 3233/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6622 - val_acc: 0.7325\n",
      "Epoch 3234/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6617 - val_acc: 0.7336\n",
      "Epoch 3235/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6599 - val_acc: 0.7361\n",
      "Epoch 3236/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9826 - val_loss: 0.6616 - val_acc: 0.7336\n",
      "Epoch 3237/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6605 - val_acc: 0.7357\n",
      "Epoch 3238/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6580 - val_acc: 0.7325\n",
      "Epoch 3239/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9812 - val_loss: 0.6626 - val_acc: 0.7346\n",
      "Epoch 3240/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6581 - val_acc: 0.7328\n",
      "Epoch 3241/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9815 - val_loss: 0.6594 - val_acc: 0.7387\n",
      "Epoch 3242/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9818 - val_loss: 0.6623 - val_acc: 0.7346\n",
      "Epoch 3243/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9813 - val_loss: 0.6614 - val_acc: 0.7372\n",
      "Epoch 3244/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9806 - val_loss: 0.6594 - val_acc: 0.7343\n",
      "Epoch 3245/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3106 - acc: 0.9691 - val_loss: 0.6639 - val_acc: 0.7281\n",
      "Epoch 3246/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3136 - acc: 0.9634 - val_loss: 0.6697 - val_acc: 0.7350\n",
      "Epoch 3247/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3098 - acc: 0.9698 - val_loss: 0.6638 - val_acc: 0.7292\n",
      "Epoch 3248/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3080 - acc: 0.9744 - val_loss: 0.6645 - val_acc: 0.7328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3249/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3070 - acc: 0.9772 - val_loss: 0.6637 - val_acc: 0.7346\n",
      "Epoch 3250/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9795 - val_loss: 0.6629 - val_acc: 0.7368\n",
      "Epoch 3251/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3064 - acc: 0.9804 - val_loss: 0.6634 - val_acc: 0.7368\n",
      "Epoch 3252/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6633 - val_acc: 0.7368\n",
      "Epoch 3253/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9814 - val_loss: 0.6632 - val_acc: 0.7383\n",
      "Epoch 3254/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6628 - val_acc: 0.7357\n",
      "Epoch 3255/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9814 - val_loss: 0.6633 - val_acc: 0.7361\n",
      "Epoch 3256/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6629 - val_acc: 0.7376\n",
      "Epoch 3257/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6631 - val_acc: 0.7357\n",
      "Epoch 3258/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6636 - val_acc: 0.7379\n",
      "Epoch 3259/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6631 - val_acc: 0.7376\n",
      "Epoch 3260/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6632 - val_acc: 0.7372\n",
      "Epoch 3261/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6632 - val_acc: 0.7387\n",
      "Epoch 3262/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6630 - val_acc: 0.7357\n",
      "Epoch 3263/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6629 - val_acc: 0.7387\n",
      "Epoch 3264/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6634 - val_acc: 0.7365\n",
      "Epoch 3265/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6631 - val_acc: 0.7361\n",
      "Epoch 3266/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6632 - val_acc: 0.7379\n",
      "Epoch 3267/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9855 - val_loss: 0.6623 - val_acc: 0.7376\n",
      "Epoch 3268/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6630 - val_acc: 0.7387\n",
      "Epoch 3269/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6625 - val_acc: 0.7372\n",
      "Epoch 3270/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6625 - val_acc: 0.7379\n",
      "Epoch 3271/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9856 - val_loss: 0.6624 - val_acc: 0.7383\n",
      "Epoch 3272/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9855 - val_loss: 0.6627 - val_acc: 0.7390\n",
      "Epoch 3273/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9849 - val_loss: 0.6625 - val_acc: 0.7368\n",
      "Epoch 3274/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9846 - val_loss: 0.6626 - val_acc: 0.7376\n",
      "Epoch 3275/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6618 - val_acc: 0.7401\n",
      "Epoch 3276/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6630 - val_acc: 0.7372\n",
      "Epoch 3277/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6609 - val_acc: 0.7394\n",
      "Epoch 3278/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6625 - val_acc: 0.7372\n",
      "Epoch 3279/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6596 - val_acc: 0.7390\n",
      "Epoch 3280/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9805 - val_loss: 0.6605 - val_acc: 0.7405\n",
      "Epoch 3281/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9822 - val_loss: 0.6597 - val_acc: 0.7416\n",
      "Epoch 3282/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6595 - val_acc: 0.7398\n",
      "Epoch 3283/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6581 - val_acc: 0.7398\n",
      "Epoch 3284/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6610 - val_acc: 0.7394\n",
      "Epoch 3285/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6611 - val_acc: 0.7387\n",
      "Epoch 3286/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6591 - val_acc: 0.7416\n",
      "Epoch 3287/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6607 - val_acc: 0.7412\n",
      "Epoch 3288/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6583 - val_acc: 0.7379\n",
      "Epoch 3289/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6562 - val_acc: 0.7420\n",
      "Epoch 3290/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6567 - val_acc: 0.7427\n",
      "Epoch 3291/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6557 - val_acc: 0.7394\n",
      "Epoch 3292/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6557 - val_acc: 0.7409\n",
      "Epoch 3293/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9814 - val_loss: 0.6583 - val_acc: 0.7416\n",
      "Epoch 3294/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9806 - val_loss: 0.6606 - val_acc: 0.7431\n",
      "Epoch 3295/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6542 - val_acc: 0.7405\n",
      "Epoch 3296/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6559 - val_acc: 0.7438\n",
      "Epoch 3297/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6556 - val_acc: 0.7379\n",
      "Epoch 3298/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9794 - val_loss: 0.6564 - val_acc: 0.7387\n",
      "Epoch 3299/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6543 - val_acc: 0.7427\n",
      "Epoch 3300/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6555 - val_acc: 0.7420\n",
      "Epoch 3301/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6561 - val_acc: 0.7431\n",
      "Epoch 3302/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6571 - val_acc: 0.7445\n",
      "Epoch 3303/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6555 - val_acc: 0.7445\n",
      "Epoch 3304/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9808 - val_loss: 0.6581 - val_acc: 0.7482\n",
      "Epoch 3305/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6545 - val_acc: 0.7463\n",
      "Epoch 3306/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9804 - val_loss: 0.6571 - val_acc: 0.7427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3307/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6548 - val_acc: 0.7438\n",
      "Epoch 3308/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6559 - val_acc: 0.7452\n",
      "Epoch 3309/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9809 - val_loss: 0.6532 - val_acc: 0.7445\n",
      "Epoch 3310/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6568 - val_acc: 0.7431\n",
      "Epoch 3311/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9817 - val_loss: 0.6580 - val_acc: 0.7427\n",
      "Epoch 3312/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6576 - val_acc: 0.7431\n",
      "Epoch 3313/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9809 - val_loss: 0.6561 - val_acc: 0.7405\n",
      "Epoch 3314/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6548 - val_acc: 0.7474\n",
      "Epoch 3315/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9800 - val_loss: 0.6589 - val_acc: 0.7420\n",
      "Epoch 3316/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9800 - val_loss: 0.6564 - val_acc: 0.7442\n",
      "Epoch 3317/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6595 - val_acc: 0.7442\n",
      "Epoch 3318/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9819 - val_loss: 0.6571 - val_acc: 0.7438\n",
      "Epoch 3319/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6583 - val_acc: 0.7445\n",
      "Epoch 3320/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6582 - val_acc: 0.7412\n",
      "Epoch 3321/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9812 - val_loss: 0.6611 - val_acc: 0.7427\n",
      "Epoch 3322/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9813 - val_loss: 0.6632 - val_acc: 0.7420\n",
      "Epoch 3323/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9783 - val_loss: 0.6642 - val_acc: 0.7390\n",
      "Epoch 3324/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3071 - acc: 0.9764 - val_loss: 0.6725 - val_acc: 0.7306\n",
      "Epoch 3325/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3081 - acc: 0.9721 - val_loss: 0.6571 - val_acc: 0.7328\n",
      "Epoch 3326/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3147 - acc: 0.9616 - val_loss: 0.6765 - val_acc: 0.7277\n",
      "Epoch 3327/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3131 - acc: 0.9652 - val_loss: 0.6636 - val_acc: 0.7299\n",
      "Epoch 3328/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3084 - acc: 0.9722 - val_loss: 0.6609 - val_acc: 0.7357\n",
      "Epoch 3329/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3085 - acc: 0.9744 - val_loss: 0.6642 - val_acc: 0.7346\n",
      "Epoch 3330/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3073 - acc: 0.9776 - val_loss: 0.6613 - val_acc: 0.7354\n",
      "Epoch 3331/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3069 - acc: 0.9778 - val_loss: 0.6602 - val_acc: 0.7354\n",
      "Epoch 3332/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3066 - acc: 0.9779 - val_loss: 0.6601 - val_acc: 0.7372\n",
      "Epoch 3333/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3064 - acc: 0.9801 - val_loss: 0.6604 - val_acc: 0.7383\n",
      "Epoch 3334/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6605 - val_acc: 0.7379\n",
      "Epoch 3335/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6599 - val_acc: 0.7368\n",
      "Epoch 3336/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9815 - val_loss: 0.6598 - val_acc: 0.7387\n",
      "Epoch 3337/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9817 - val_loss: 0.6597 - val_acc: 0.7376\n",
      "Epoch 3338/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6592 - val_acc: 0.7368\n",
      "Epoch 3339/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6593 - val_acc: 0.7390\n",
      "Epoch 3340/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9835 - val_loss: 0.6594 - val_acc: 0.7383\n",
      "Epoch 3341/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6593 - val_acc: 0.7368\n",
      "Epoch 3342/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6593 - val_acc: 0.7368\n",
      "Epoch 3343/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6592 - val_acc: 0.7376\n",
      "Epoch 3344/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6590 - val_acc: 0.7368\n",
      "Epoch 3345/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6589 - val_acc: 0.7379\n",
      "Epoch 3346/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6594 - val_acc: 0.7365\n",
      "Epoch 3347/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6593 - val_acc: 0.7379\n",
      "Epoch 3348/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6590 - val_acc: 0.7354\n",
      "Epoch 3349/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6588 - val_acc: 0.7379\n",
      "Epoch 3350/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6591 - val_acc: 0.7390\n",
      "Epoch 3351/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6590 - val_acc: 0.7379\n",
      "Epoch 3352/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6590 - val_acc: 0.7354\n",
      "Epoch 3353/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3059 - acc: 0.9848 - val_loss: 0.6590 - val_acc: 0.7376\n",
      "Epoch 3354/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6585 - val_acc: 0.7376\n",
      "Epoch 3355/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6593 - val_acc: 0.7365\n",
      "Epoch 3356/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6588 - val_acc: 0.7372\n",
      "Epoch 3357/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9855 - val_loss: 0.6605 - val_acc: 0.7383\n",
      "Epoch 3358/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9812 - val_loss: 0.6615 - val_acc: 0.7379\n",
      "Epoch 3359/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6603 - val_acc: 0.7372\n",
      "Epoch 3360/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6594 - val_acc: 0.7398\n",
      "Epoch 3361/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6610 - val_acc: 0.7368\n",
      "Epoch 3362/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9834 - val_loss: 0.6613 - val_acc: 0.7383\n",
      "Epoch 3363/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6606 - val_acc: 0.7394\n",
      "Epoch 3364/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6599 - val_acc: 0.7420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3365/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6609 - val_acc: 0.7361\n",
      "Epoch 3366/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6593 - val_acc: 0.7383\n",
      "Epoch 3367/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6595 - val_acc: 0.7379\n",
      "Epoch 3368/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6578 - val_acc: 0.7398\n",
      "Epoch 3369/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6591 - val_acc: 0.7383\n",
      "Epoch 3370/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6599 - val_acc: 0.7383\n",
      "Epoch 3371/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6587 - val_acc: 0.7383\n",
      "Epoch 3372/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9814 - val_loss: 0.6578 - val_acc: 0.7372\n",
      "Epoch 3373/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6583 - val_acc: 0.7390\n",
      "Epoch 3374/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6570 - val_acc: 0.7420\n",
      "Epoch 3375/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9818 - val_loss: 0.6568 - val_acc: 0.7390\n",
      "Epoch 3376/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9808 - val_loss: 0.6552 - val_acc: 0.7376\n",
      "Epoch 3377/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9806 - val_loss: 0.6548 - val_acc: 0.7379\n",
      "Epoch 3378/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9815 - val_loss: 0.6552 - val_acc: 0.7368\n",
      "Epoch 3379/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6552 - val_acc: 0.7354\n",
      "Epoch 3380/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9834 - val_loss: 0.6555 - val_acc: 0.7387\n",
      "Epoch 3381/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6538 - val_acc: 0.7357\n",
      "Epoch 3382/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9817 - val_loss: 0.6538 - val_acc: 0.7401\n",
      "Epoch 3383/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6543 - val_acc: 0.7354\n",
      "Epoch 3384/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9805 - val_loss: 0.6547 - val_acc: 0.7368\n",
      "Epoch 3385/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9804 - val_loss: 0.6555 - val_acc: 0.7365\n",
      "Epoch 3386/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6544 - val_acc: 0.7398\n",
      "Epoch 3387/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6542 - val_acc: 0.7365\n",
      "Epoch 3388/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6539 - val_acc: 0.7365\n",
      "Epoch 3389/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9795 - val_loss: 0.6556 - val_acc: 0.7325\n",
      "Epoch 3390/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3068 - acc: 0.9775 - val_loss: 0.6584 - val_acc: 0.7361\n",
      "Epoch 3391/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3072 - acc: 0.9759 - val_loss: 0.6618 - val_acc: 0.7317\n",
      "Epoch 3392/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3070 - acc: 0.9752 - val_loss: 0.6601 - val_acc: 0.7379\n",
      "Epoch 3393/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3075 - acc: 0.9759 - val_loss: 0.6720 - val_acc: 0.7259\n",
      "Epoch 3394/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3079 - acc: 0.9740 - val_loss: 0.6630 - val_acc: 0.7321\n",
      "Epoch 3395/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3067 - acc: 0.9785 - val_loss: 0.6644 - val_acc: 0.7354\n",
      "Epoch 3396/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3063 - acc: 0.9818 - val_loss: 0.6641 - val_acc: 0.7354\n",
      "Epoch 3397/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6653 - val_acc: 0.7350\n",
      "Epoch 3398/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6654 - val_acc: 0.7379\n",
      "Epoch 3399/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6649 - val_acc: 0.7379\n",
      "Epoch 3400/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6650 - val_acc: 0.7372\n",
      "Epoch 3401/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9845 - val_loss: 0.6644 - val_acc: 0.7390\n",
      "Epoch 3402/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9844 - val_loss: 0.6645 - val_acc: 0.7390\n",
      "Epoch 3403/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9849 - val_loss: 0.6639 - val_acc: 0.7372\n",
      "Epoch 3404/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6646 - val_acc: 0.7390\n",
      "Epoch 3405/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9845 - val_loss: 0.6641 - val_acc: 0.7394\n",
      "Epoch 3406/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3058 - acc: 0.9849 - val_loss: 0.6646 - val_acc: 0.7379\n",
      "Epoch 3407/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9848 - val_loss: 0.6641 - val_acc: 0.7365\n",
      "Epoch 3408/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6650 - val_acc: 0.7383\n",
      "Epoch 3409/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6648 - val_acc: 0.7390\n",
      "Epoch 3410/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6646 - val_acc: 0.7387\n",
      "Epoch 3411/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9832 - val_loss: 0.6642 - val_acc: 0.7387\n",
      "Epoch 3412/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6643 - val_acc: 0.7383\n",
      "Epoch 3413/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9817 - val_loss: 0.6645 - val_acc: 0.7387\n",
      "Epoch 3414/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6656 - val_acc: 0.7383\n",
      "Epoch 3415/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9802 - val_loss: 0.6624 - val_acc: 0.7376\n",
      "Epoch 3416/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9784 - val_loss: 0.6626 - val_acc: 0.7390\n",
      "Epoch 3417/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9786 - val_loss: 0.6600 - val_acc: 0.7376\n",
      "Epoch 3418/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9817 - val_loss: 0.6615 - val_acc: 0.7379\n",
      "Epoch 3419/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6635 - val_acc: 0.7379\n",
      "Epoch 3420/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6621 - val_acc: 0.7361\n",
      "Epoch 3421/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6614 - val_acc: 0.7365\n",
      "Epoch 3422/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6665 - val_acc: 0.7336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3423/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9802 - val_loss: 0.6650 - val_acc: 0.7346\n",
      "Epoch 3424/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9806 - val_loss: 0.6651 - val_acc: 0.7350\n",
      "Epoch 3425/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9799 - val_loss: 0.6668 - val_acc: 0.7372\n",
      "Epoch 3426/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9815 - val_loss: 0.6636 - val_acc: 0.7379\n",
      "Epoch 3427/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9805 - val_loss: 0.6656 - val_acc: 0.7372\n",
      "Epoch 3428/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9815 - val_loss: 0.6670 - val_acc: 0.7372\n",
      "Epoch 3429/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6636 - val_acc: 0.7332\n",
      "Epoch 3430/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6637 - val_acc: 0.7383\n",
      "Epoch 3431/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6660 - val_acc: 0.7336\n",
      "Epoch 3432/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6625 - val_acc: 0.7361\n",
      "Epoch 3433/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6635 - val_acc: 0.7361\n",
      "Epoch 3434/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9817 - val_loss: 0.6649 - val_acc: 0.7361\n",
      "Epoch 3435/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3060 - acc: 0.9817 - val_loss: 0.6635 - val_acc: 0.7350\n",
      "Epoch 3436/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6636 - val_acc: 0.7387\n",
      "Epoch 3437/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9789 - val_loss: 0.6642 - val_acc: 0.7354\n",
      "Epoch 3438/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6633 - val_acc: 0.7401\n",
      "Epoch 3439/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9812 - val_loss: 0.6644 - val_acc: 0.7354\n",
      "Epoch 3440/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6628 - val_acc: 0.7394\n",
      "Epoch 3441/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9796 - val_loss: 0.6630 - val_acc: 0.7383\n",
      "Epoch 3442/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9808 - val_loss: 0.6642 - val_acc: 0.7394\n",
      "Epoch 3443/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9808 - val_loss: 0.6635 - val_acc: 0.7357\n",
      "Epoch 3444/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6631 - val_acc: 0.7390\n",
      "Epoch 3445/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6624 - val_acc: 0.7372\n",
      "Epoch 3446/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6636 - val_acc: 0.7368\n",
      "Epoch 3447/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9811 - val_loss: 0.6623 - val_acc: 0.7361\n",
      "Epoch 3448/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9800 - val_loss: 0.6623 - val_acc: 0.7354\n",
      "Epoch 3449/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9811 - val_loss: 0.6618 - val_acc: 0.7383\n",
      "Epoch 3450/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9805 - val_loss: 0.6619 - val_acc: 0.7387\n",
      "Epoch 3451/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9808 - val_loss: 0.6657 - val_acc: 0.7343\n",
      "Epoch 3452/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6629 - val_acc: 0.7350\n",
      "Epoch 3453/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9803 - val_loss: 0.6622 - val_acc: 0.7372\n",
      "Epoch 3454/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9789 - val_loss: 0.6629 - val_acc: 0.7336\n",
      "Epoch 3455/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3062 - acc: 0.9788 - val_loss: 0.6614 - val_acc: 0.7387\n",
      "Epoch 3456/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9813 - val_loss: 0.6635 - val_acc: 0.7321\n",
      "Epoch 3457/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9800 - val_loss: 0.6603 - val_acc: 0.7346\n",
      "Epoch 3458/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9826 - val_loss: 0.6618 - val_acc: 0.7328\n",
      "Epoch 3459/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9812 - val_loss: 0.6603 - val_acc: 0.7383\n",
      "Epoch 3460/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6614 - val_acc: 0.7383\n",
      "Epoch 3461/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6604 - val_acc: 0.7372\n",
      "Epoch 3462/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6618 - val_acc: 0.7372\n",
      "Epoch 3463/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9811 - val_loss: 0.6602 - val_acc: 0.7339\n",
      "Epoch 3464/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6631 - val_acc: 0.7401\n",
      "Epoch 3465/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6621 - val_acc: 0.7376\n",
      "Epoch 3466/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9802 - val_loss: 0.6617 - val_acc: 0.7343\n",
      "Epoch 3467/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3063 - acc: 0.9786 - val_loss: 0.6613 - val_acc: 0.7394\n",
      "Epoch 3468/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9789 - val_loss: 0.6608 - val_acc: 0.7372\n",
      "Epoch 3469/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3063 - acc: 0.9795 - val_loss: 0.6631 - val_acc: 0.7365\n",
      "Epoch 3470/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9801 - val_loss: 0.6610 - val_acc: 0.7383\n",
      "Epoch 3471/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6636 - val_acc: 0.7339\n",
      "Epoch 3472/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9815 - val_loss: 0.6631 - val_acc: 0.7376\n",
      "Epoch 3473/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9818 - val_loss: 0.6616 - val_acc: 0.7354\n",
      "Epoch 3474/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6613 - val_acc: 0.7346\n",
      "Epoch 3475/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6618 - val_acc: 0.7361\n",
      "Epoch 3476/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6613 - val_acc: 0.7350\n",
      "Epoch 3477/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9819 - val_loss: 0.6608 - val_acc: 0.7379\n",
      "Epoch 3478/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6621 - val_acc: 0.7343\n",
      "Epoch 3479/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6607 - val_acc: 0.7365\n",
      "Epoch 3480/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9812 - val_loss: 0.6611 - val_acc: 0.7379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3481/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9817 - val_loss: 0.6631 - val_acc: 0.7361\n",
      "Epoch 3482/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9800 - val_loss: 0.6607 - val_acc: 0.7383\n",
      "Epoch 3483/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6620 - val_acc: 0.7332\n",
      "Epoch 3484/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6637 - val_acc: 0.7372\n",
      "Epoch 3485/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9815 - val_loss: 0.6607 - val_acc: 0.7372\n",
      "Epoch 3486/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9809 - val_loss: 0.6607 - val_acc: 0.7379\n",
      "Epoch 3487/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6601 - val_acc: 0.7394\n",
      "Epoch 3488/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6601 - val_acc: 0.7361\n",
      "Epoch 3489/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9805 - val_loss: 0.6595 - val_acc: 0.7379\n",
      "Epoch 3490/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9814 - val_loss: 0.6625 - val_acc: 0.7387\n",
      "Epoch 3491/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9799 - val_loss: 0.6606 - val_acc: 0.7332\n",
      "Epoch 3492/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9772 - val_loss: 0.6591 - val_acc: 0.7346\n",
      "Epoch 3493/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9804 - val_loss: 0.6621 - val_acc: 0.7346\n",
      "Epoch 3494/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6615 - val_acc: 0.7368\n",
      "Epoch 3495/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3073 - acc: 0.9768 - val_loss: 0.6639 - val_acc: 0.7288\n",
      "Epoch 3496/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3098 - acc: 0.9703 - val_loss: 0.6693 - val_acc: 0.7317\n",
      "Epoch 3497/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3109 - acc: 0.9670 - val_loss: 0.6631 - val_acc: 0.7336\n",
      "Epoch 3498/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3077 - acc: 0.9743 - val_loss: 0.6562 - val_acc: 0.7361\n",
      "Epoch 3499/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3066 - acc: 0.9771 - val_loss: 0.6553 - val_acc: 0.7376\n",
      "Epoch 3500/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9797 - val_loss: 0.6551 - val_acc: 0.7383\n",
      "Epoch 3501/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6549 - val_acc: 0.7372\n",
      "Epoch 3502/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9822 - val_loss: 0.6555 - val_acc: 0.7357\n",
      "Epoch 3503/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9822 - val_loss: 0.6550 - val_acc: 0.7354\n",
      "Epoch 3504/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9831 - val_loss: 0.6552 - val_acc: 0.7357\n",
      "Epoch 3505/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9831 - val_loss: 0.6549 - val_acc: 0.7361\n",
      "Epoch 3506/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6550 - val_acc: 0.7361\n",
      "Epoch 3507/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9837 - val_loss: 0.6551 - val_acc: 0.7354\n",
      "Epoch 3508/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9844 - val_loss: 0.6549 - val_acc: 0.7365\n",
      "Epoch 3509/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9843 - val_loss: 0.6550 - val_acc: 0.7350\n",
      "Epoch 3510/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9842 - val_loss: 0.6552 - val_acc: 0.7354\n",
      "Epoch 3511/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9844 - val_loss: 0.6547 - val_acc: 0.7346\n",
      "Epoch 3512/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9840 - val_loss: 0.6550 - val_acc: 0.7354\n",
      "Epoch 3513/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9843 - val_loss: 0.6546 - val_acc: 0.7354\n",
      "Epoch 3514/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6553 - val_acc: 0.7357\n",
      "Epoch 3515/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6548 - val_acc: 0.7354\n",
      "Epoch 3516/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6552 - val_acc: 0.7372\n",
      "Epoch 3517/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6550 - val_acc: 0.7357\n",
      "Epoch 3518/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6556 - val_acc: 0.7365\n",
      "Epoch 3519/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6554 - val_acc: 0.7346\n",
      "Epoch 3520/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9846 - val_loss: 0.6558 - val_acc: 0.7357\n",
      "Epoch 3521/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9843 - val_loss: 0.6550 - val_acc: 0.7361\n",
      "Epoch 3522/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9833 - val_loss: 0.6561 - val_acc: 0.7354\n",
      "Epoch 3523/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9822 - val_loss: 0.6557 - val_acc: 0.7350\n",
      "Epoch 3524/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6570 - val_acc: 0.7321\n",
      "Epoch 3525/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6549 - val_acc: 0.7368\n",
      "Epoch 3526/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6571 - val_acc: 0.7394\n",
      "Epoch 3527/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6565 - val_acc: 0.7346\n",
      "Epoch 3528/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9800 - val_loss: 0.6560 - val_acc: 0.7372\n",
      "Epoch 3529/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3060 - acc: 0.9807 - val_loss: 0.6544 - val_acc: 0.7379\n",
      "Epoch 3530/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9816 - val_loss: 0.6559 - val_acc: 0.7354\n",
      "Epoch 3531/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9820 - val_loss: 0.6549 - val_acc: 0.7365\n",
      "Epoch 3532/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6568 - val_acc: 0.7376\n",
      "Epoch 3533/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9816 - val_loss: 0.6544 - val_acc: 0.7376\n",
      "Epoch 3534/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6561 - val_acc: 0.7343\n",
      "Epoch 3535/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9788 - val_loss: 0.6683 - val_acc: 0.7354\n",
      "Epoch 3536/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3180 - acc: 0.9591 - val_loss: 0.6819 - val_acc: 0.7284\n",
      "Epoch 3537/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3150 - acc: 0.9605 - val_loss: 0.6687 - val_acc: 0.7401\n",
      "Epoch 3538/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3093 - acc: 0.9702 - val_loss: 0.6664 - val_acc: 0.7398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3539/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3080 - acc: 0.9738 - val_loss: 0.6629 - val_acc: 0.7416\n",
      "Epoch 3540/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3077 - acc: 0.9757 - val_loss: 0.6620 - val_acc: 0.7398\n",
      "Epoch 3541/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3074 - acc: 0.9780 - val_loss: 0.6639 - val_acc: 0.7394\n",
      "Epoch 3542/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3071 - acc: 0.9784 - val_loss: 0.6620 - val_acc: 0.7409\n",
      "Epoch 3543/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3070 - acc: 0.9793 - val_loss: 0.6625 - val_acc: 0.7398\n",
      "Epoch 3544/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3068 - acc: 0.9804 - val_loss: 0.6637 - val_acc: 0.7401\n",
      "Epoch 3545/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3066 - acc: 0.9807 - val_loss: 0.6617 - val_acc: 0.7398\n",
      "Epoch 3546/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3065 - acc: 0.9814 - val_loss: 0.6620 - val_acc: 0.7379\n",
      "Epoch 3547/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9822 - val_loss: 0.6613 - val_acc: 0.7398\n",
      "Epoch 3548/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9819 - val_loss: 0.6613 - val_acc: 0.7390\n",
      "Epoch 3549/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9825 - val_loss: 0.6606 - val_acc: 0.7379\n",
      "Epoch 3550/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9815 - val_loss: 0.6618 - val_acc: 0.7405\n",
      "Epoch 3551/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9811 - val_loss: 0.6624 - val_acc: 0.7361\n",
      "Epoch 3552/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9818 - val_loss: 0.6607 - val_acc: 0.7379\n",
      "Epoch 3553/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9812 - val_loss: 0.6625 - val_acc: 0.7394\n",
      "Epoch 3554/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9823 - val_loss: 0.6619 - val_acc: 0.7398\n",
      "Epoch 3555/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9831 - val_loss: 0.6618 - val_acc: 0.7376\n",
      "Epoch 3556/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6623 - val_acc: 0.7379\n",
      "Epoch 3557/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6623 - val_acc: 0.7387\n",
      "Epoch 3558/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6618 - val_acc: 0.7372\n",
      "Epoch 3559/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6620 - val_acc: 0.7376\n",
      "Epoch 3560/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6619 - val_acc: 0.7376\n",
      "Epoch 3561/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6618 - val_acc: 0.7361\n",
      "Epoch 3562/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6619 - val_acc: 0.7376\n",
      "Epoch 3563/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6623 - val_acc: 0.7368\n",
      "Epoch 3564/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6619 - val_acc: 0.7368\n",
      "Epoch 3565/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3059 - acc: 0.9848 - val_loss: 0.6612 - val_acc: 0.7379\n",
      "Epoch 3566/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6615 - val_acc: 0.7354\n",
      "Epoch 3567/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9855 - val_loss: 0.6614 - val_acc: 0.7379\n",
      "Epoch 3568/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9853 - val_loss: 0.6614 - val_acc: 0.7365\n",
      "Epoch 3569/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6618 - val_acc: 0.7379\n",
      "Epoch 3570/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9855 - val_loss: 0.6612 - val_acc: 0.7372\n",
      "Epoch 3571/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9856 - val_loss: 0.6617 - val_acc: 0.7387\n",
      "Epoch 3572/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9855 - val_loss: 0.6615 - val_acc: 0.7383\n",
      "Epoch 3573/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9857 - val_loss: 0.6608 - val_acc: 0.7372\n",
      "Epoch 3574/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9857 - val_loss: 0.6613 - val_acc: 0.7368\n",
      "Epoch 3575/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6607 - val_acc: 0.7365\n",
      "Epoch 3576/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6609 - val_acc: 0.7368\n",
      "Epoch 3577/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6612 - val_acc: 0.7405\n",
      "Epoch 3578/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6601 - val_acc: 0.7361\n",
      "Epoch 3579/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6598 - val_acc: 0.7405\n",
      "Epoch 3580/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6608 - val_acc: 0.7401\n",
      "Epoch 3581/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9797 - val_loss: 0.6597 - val_acc: 0.7379\n",
      "Epoch 3582/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6601 - val_acc: 0.7376\n",
      "Epoch 3583/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6607 - val_acc: 0.7405\n",
      "Epoch 3584/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6594 - val_acc: 0.7405\n",
      "Epoch 3585/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9813 - val_loss: 0.6581 - val_acc: 0.7390\n",
      "Epoch 3586/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6586 - val_acc: 0.7387\n",
      "Epoch 3587/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6587 - val_acc: 0.7394\n",
      "Epoch 3588/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6583 - val_acc: 0.7390\n",
      "Epoch 3589/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6605 - val_acc: 0.7379\n",
      "Epoch 3590/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6600 - val_acc: 0.7379\n",
      "Epoch 3591/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6579 - val_acc: 0.7376\n",
      "Epoch 3592/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9805 - val_loss: 0.6584 - val_acc: 0.7398\n",
      "Epoch 3593/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6574 - val_acc: 0.7398\n",
      "Epoch 3594/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6574 - val_acc: 0.7372\n",
      "Epoch 3595/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6587 - val_acc: 0.7398\n",
      "Epoch 3596/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9823 - val_loss: 0.6559 - val_acc: 0.7376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3597/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9816 - val_loss: 0.6573 - val_acc: 0.7361\n",
      "Epoch 3598/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9779 - val_loss: 0.6554 - val_acc: 0.7383\n",
      "Epoch 3599/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3109 - acc: 0.9660 - val_loss: 0.6724 - val_acc: 0.7230\n",
      "Epoch 3600/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3111 - acc: 0.9650 - val_loss: 0.6654 - val_acc: 0.7365\n",
      "Epoch 3601/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3088 - acc: 0.9705 - val_loss: 0.6632 - val_acc: 0.7284\n",
      "Epoch 3602/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3075 - acc: 0.9750 - val_loss: 0.6623 - val_acc: 0.7357\n",
      "Epoch 3603/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3068 - acc: 0.9775 - val_loss: 0.6646 - val_acc: 0.7372\n",
      "Epoch 3604/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3064 - acc: 0.9802 - val_loss: 0.6633 - val_acc: 0.7354\n",
      "Epoch 3605/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9814 - val_loss: 0.6627 - val_acc: 0.7357\n",
      "Epoch 3606/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6625 - val_acc: 0.7354\n",
      "Epoch 3607/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6620 - val_acc: 0.7343\n",
      "Epoch 3608/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6614 - val_acc: 0.7361\n",
      "Epoch 3609/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6615 - val_acc: 0.7357\n",
      "Epoch 3610/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6610 - val_acc: 0.7357\n",
      "Epoch 3611/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6614 - val_acc: 0.7357\n",
      "Epoch 3612/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6609 - val_acc: 0.7365\n",
      "Epoch 3613/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6610 - val_acc: 0.7361\n",
      "Epoch 3614/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9861 - val_loss: 0.6612 - val_acc: 0.7339\n",
      "Epoch 3615/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6612 - val_acc: 0.7365\n",
      "Epoch 3616/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6614 - val_acc: 0.7346\n",
      "Epoch 3617/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9864 - val_loss: 0.6613 - val_acc: 0.7361\n",
      "Epoch 3618/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9863 - val_loss: 0.6610 - val_acc: 0.7343\n",
      "Epoch 3619/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9859 - val_loss: 0.6612 - val_acc: 0.7346\n",
      "Epoch 3620/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9863 - val_loss: 0.6612 - val_acc: 0.7365\n",
      "Epoch 3621/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9863 - val_loss: 0.6610 - val_acc: 0.7336\n",
      "Epoch 3622/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9857 - val_loss: 0.6613 - val_acc: 0.7354\n",
      "Epoch 3623/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9866 - val_loss: 0.6616 - val_acc: 0.7354\n",
      "Epoch 3624/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9859 - val_loss: 0.6602 - val_acc: 0.7343\n",
      "Epoch 3625/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3058 - acc: 0.9861 - val_loss: 0.6615 - val_acc: 0.7339\n",
      "Epoch 3626/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3058 - acc: 0.9863 - val_loss: 0.6606 - val_acc: 0.7350\n",
      "Epoch 3627/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9857 - val_loss: 0.6614 - val_acc: 0.7361\n",
      "Epoch 3628/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9856 - val_loss: 0.6604 - val_acc: 0.7339\n",
      "Epoch 3629/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6612 - val_acc: 0.7361\n",
      "Epoch 3630/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9842 - val_loss: 0.6615 - val_acc: 0.7365\n",
      "Epoch 3631/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6596 - val_acc: 0.7365\n",
      "Epoch 3632/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9830 - val_loss: 0.6604 - val_acc: 0.7317\n",
      "Epoch 3633/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3067 - acc: 0.9782 - val_loss: 0.6606 - val_acc: 0.7379\n",
      "Epoch 3634/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3110 - acc: 0.9723 - val_loss: 0.6670 - val_acc: 0.7248\n",
      "Epoch 3635/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3121 - acc: 0.9697 - val_loss: 0.6831 - val_acc: 0.7292\n",
      "Epoch 3636/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3110 - acc: 0.9674 - val_loss: 0.6759 - val_acc: 0.7314\n",
      "Epoch 3637/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3099 - acc: 0.9715 - val_loss: 0.6762 - val_acc: 0.7248\n",
      "Epoch 3638/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3084 - acc: 0.9743 - val_loss: 0.6732 - val_acc: 0.7273\n",
      "Epoch 3639/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3072 - acc: 0.9779 - val_loss: 0.6718 - val_acc: 0.7288\n",
      "Epoch 3640/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3068 - acc: 0.9777 - val_loss: 0.6718 - val_acc: 0.7292\n",
      "Epoch 3641/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3067 - acc: 0.9795 - val_loss: 0.6710 - val_acc: 0.7284\n",
      "Epoch 3642/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9800 - val_loss: 0.6708 - val_acc: 0.7299\n",
      "Epoch 3643/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9797 - val_loss: 0.6703 - val_acc: 0.7281\n",
      "Epoch 3644/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9806 - val_loss: 0.6703 - val_acc: 0.7284\n",
      "Epoch 3645/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9815 - val_loss: 0.6710 - val_acc: 0.7299\n",
      "Epoch 3646/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9820 - val_loss: 0.6702 - val_acc: 0.7306\n",
      "Epoch 3647/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6703 - val_acc: 0.7306\n",
      "Epoch 3648/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6701 - val_acc: 0.7299\n",
      "Epoch 3649/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9823 - val_loss: 0.6693 - val_acc: 0.7288\n",
      "Epoch 3650/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9828 - val_loss: 0.6700 - val_acc: 0.7325\n",
      "Epoch 3651/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6693 - val_acc: 0.7314\n",
      "Epoch 3652/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6692 - val_acc: 0.7321\n",
      "Epoch 3653/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6694 - val_acc: 0.7310\n",
      "Epoch 3654/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6690 - val_acc: 0.7317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3655/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6689 - val_acc: 0.7288\n",
      "Epoch 3656/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6691 - val_acc: 0.7292\n",
      "Epoch 3657/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6691 - val_acc: 0.7295\n",
      "Epoch 3658/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3060 - acc: 0.9846 - val_loss: 0.6693 - val_acc: 0.7295\n",
      "Epoch 3659/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9850 - val_loss: 0.6689 - val_acc: 0.7310\n",
      "Epoch 3660/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6691 - val_acc: 0.7288\n",
      "Epoch 3661/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6690 - val_acc: 0.7284\n",
      "Epoch 3662/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9847 - val_loss: 0.6687 - val_acc: 0.7292\n",
      "Epoch 3663/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9842 - val_loss: 0.6688 - val_acc: 0.7299\n",
      "Epoch 3664/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9835 - val_loss: 0.6685 - val_acc: 0.7295\n",
      "Epoch 3665/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3059 - acc: 0.9829 - val_loss: 0.6680 - val_acc: 0.7295\n",
      "Epoch 3666/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6689 - val_acc: 0.7310\n",
      "Epoch 3667/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6685 - val_acc: 0.7317\n",
      "Epoch 3668/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6679 - val_acc: 0.7281\n",
      "Epoch 3669/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6695 - val_acc: 0.7314\n",
      "Epoch 3670/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6672 - val_acc: 0.7299\n",
      "Epoch 3671/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9838 - val_loss: 0.6687 - val_acc: 0.7303\n",
      "Epoch 3672/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9820 - val_loss: 0.6680 - val_acc: 0.7303\n",
      "Epoch 3673/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6691 - val_acc: 0.7321\n",
      "Epoch 3674/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9812 - val_loss: 0.6683 - val_acc: 0.7295\n",
      "Epoch 3675/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9808 - val_loss: 0.6667 - val_acc: 0.7303\n",
      "Epoch 3676/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6688 - val_acc: 0.7255\n",
      "Epoch 3677/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6668 - val_acc: 0.7284\n",
      "Epoch 3678/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9806 - val_loss: 0.6683 - val_acc: 0.7277\n",
      "Epoch 3679/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3067 - acc: 0.9786 - val_loss: 0.6728 - val_acc: 0.7270\n",
      "Epoch 3680/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3087 - acc: 0.9737 - val_loss: 0.6717 - val_acc: 0.7317\n",
      "Epoch 3681/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3138 - acc: 0.9652 - val_loss: 0.6703 - val_acc: 0.7259\n",
      "Epoch 3682/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3103 - acc: 0.9720 - val_loss: 0.6778 - val_acc: 0.7281\n",
      "Epoch 3683/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3092 - acc: 0.9695 - val_loss: 0.6814 - val_acc: 0.7339\n",
      "Epoch 3684/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3074 - acc: 0.9734 - val_loss: 0.6802 - val_acc: 0.7332\n",
      "Epoch 3685/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3068 - acc: 0.9772 - val_loss: 0.6798 - val_acc: 0.7336\n",
      "Epoch 3686/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9786 - val_loss: 0.6791 - val_acc: 0.7339\n",
      "Epoch 3687/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9807 - val_loss: 0.6786 - val_acc: 0.7343\n",
      "Epoch 3688/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9810 - val_loss: 0.6777 - val_acc: 0.7361\n",
      "Epoch 3689/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9816 - val_loss: 0.6773 - val_acc: 0.7343\n",
      "Epoch 3690/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9815 - val_loss: 0.6771 - val_acc: 0.7354\n",
      "Epoch 3691/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9822 - val_loss: 0.6770 - val_acc: 0.7332\n",
      "Epoch 3692/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9828 - val_loss: 0.6764 - val_acc: 0.7325\n",
      "Epoch 3693/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6765 - val_acc: 0.7346\n",
      "Epoch 3694/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9830 - val_loss: 0.6763 - val_acc: 0.7339\n",
      "Epoch 3695/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9835 - val_loss: 0.6762 - val_acc: 0.7339\n",
      "Epoch 3696/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9834 - val_loss: 0.6758 - val_acc: 0.7328\n",
      "Epoch 3697/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6759 - val_acc: 0.7332\n",
      "Epoch 3698/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9838 - val_loss: 0.6753 - val_acc: 0.7317\n",
      "Epoch 3699/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9839 - val_loss: 0.6756 - val_acc: 0.7332\n",
      "Epoch 3700/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6752 - val_acc: 0.7317\n",
      "Epoch 3701/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3060 - acc: 0.9846 - val_loss: 0.6752 - val_acc: 0.7339\n",
      "Epoch 3702/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6752 - val_acc: 0.7321\n",
      "Epoch 3703/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6752 - val_acc: 0.7314\n",
      "Epoch 3704/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6753 - val_acc: 0.7339\n",
      "Epoch 3705/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6753 - val_acc: 0.7332\n",
      "Epoch 3706/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6743 - val_acc: 0.7332\n",
      "Epoch 3707/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6727 - val_acc: 0.7328\n",
      "Epoch 3708/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9826 - val_loss: 0.6735 - val_acc: 0.7292\n",
      "Epoch 3709/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6728 - val_acc: 0.7325\n",
      "Epoch 3710/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6711 - val_acc: 0.7310\n",
      "Epoch 3711/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6721 - val_acc: 0.7314\n",
      "Epoch 3712/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6721 - val_acc: 0.7288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3713/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9846 - val_loss: 0.6712 - val_acc: 0.7339\n",
      "Epoch 3714/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6709 - val_acc: 0.7325\n",
      "Epoch 3715/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9834 - val_loss: 0.6714 - val_acc: 0.7332\n",
      "Epoch 3716/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6727 - val_acc: 0.7325\n",
      "Epoch 3717/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6724 - val_acc: 0.7317\n",
      "Epoch 3718/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9829 - val_loss: 0.6735 - val_acc: 0.7350\n",
      "Epoch 3719/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9824 - val_loss: 0.6715 - val_acc: 0.7361\n",
      "Epoch 3720/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6711 - val_acc: 0.7365\n",
      "Epoch 3721/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9822 - val_loss: 0.6709 - val_acc: 0.7354\n",
      "Epoch 3722/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9828 - val_loss: 0.6695 - val_acc: 0.7343\n",
      "Epoch 3723/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6701 - val_acc: 0.7339\n",
      "Epoch 3724/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6686 - val_acc: 0.7336\n",
      "Epoch 3725/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9828 - val_loss: 0.6701 - val_acc: 0.7336\n",
      "Epoch 3726/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6696 - val_acc: 0.7346\n",
      "Epoch 3727/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6734 - val_acc: 0.7346\n",
      "Epoch 3728/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3062 - acc: 0.9801 - val_loss: 0.6691 - val_acc: 0.7354\n",
      "Epoch 3729/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9810 - val_loss: 0.6682 - val_acc: 0.7332\n",
      "Epoch 3730/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9809 - val_loss: 0.6695 - val_acc: 0.7343\n",
      "Epoch 3731/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6699 - val_acc: 0.7365\n",
      "Epoch 3732/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6678 - val_acc: 0.7350\n",
      "Epoch 3733/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6667 - val_acc: 0.7383\n",
      "Epoch 3734/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9808 - val_loss: 0.6682 - val_acc: 0.7336\n",
      "Epoch 3735/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6665 - val_acc: 0.7350\n",
      "Epoch 3736/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9806 - val_loss: 0.6687 - val_acc: 0.7368\n",
      "Epoch 3737/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6681 - val_acc: 0.7314\n",
      "Epoch 3738/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6696 - val_acc: 0.7368\n",
      "Epoch 3739/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3062 - acc: 0.9816 - val_loss: 0.6659 - val_acc: 0.7379\n",
      "Epoch 3740/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9797 - val_loss: 0.6702 - val_acc: 0.7350\n",
      "Epoch 3741/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9809 - val_loss: 0.6664 - val_acc: 0.7346\n",
      "Epoch 3742/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6673 - val_acc: 0.7336\n",
      "Epoch 3743/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6636 - val_acc: 0.7354\n",
      "Epoch 3744/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6663 - val_acc: 0.7336\n",
      "Epoch 3745/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6665 - val_acc: 0.7354\n",
      "Epoch 3746/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9804 - val_loss: 0.6674 - val_acc: 0.7339\n",
      "Epoch 3747/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6653 - val_acc: 0.7336\n",
      "Epoch 3748/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9801 - val_loss: 0.6662 - val_acc: 0.7376\n",
      "Epoch 3749/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9798 - val_loss: 0.6653 - val_acc: 0.7332\n",
      "Epoch 3750/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9800 - val_loss: 0.6650 - val_acc: 0.7361\n",
      "Epoch 3751/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9799 - val_loss: 0.6655 - val_acc: 0.7357\n",
      "Epoch 3752/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6626 - val_acc: 0.7412\n",
      "Epoch 3753/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6660 - val_acc: 0.7339\n",
      "Epoch 3754/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3074 - acc: 0.9772 - val_loss: 0.6705 - val_acc: 0.7328\n",
      "Epoch 3755/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3169 - acc: 0.9590 - val_loss: 0.6801 - val_acc: 0.7255\n",
      "Epoch 3756/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3122 - acc: 0.9660 - val_loss: 0.6813 - val_acc: 0.7303\n",
      "Epoch 3757/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3094 - acc: 0.9687 - val_loss: 0.6726 - val_acc: 0.7350\n",
      "Epoch 3758/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3079 - acc: 0.9736 - val_loss: 0.6703 - val_acc: 0.7325\n",
      "Epoch 3759/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3074 - acc: 0.9750 - val_loss: 0.6671 - val_acc: 0.7332\n",
      "Epoch 3760/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3070 - acc: 0.9771 - val_loss: 0.6654 - val_acc: 0.7350\n",
      "Epoch 3761/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3068 - acc: 0.9782 - val_loss: 0.6647 - val_acc: 0.7332\n",
      "Epoch 3762/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3067 - acc: 0.9780 - val_loss: 0.6641 - val_acc: 0.7350\n",
      "Epoch 3763/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3066 - acc: 0.9799 - val_loss: 0.6635 - val_acc: 0.7339\n",
      "Epoch 3764/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3065 - acc: 0.9799 - val_loss: 0.6643 - val_acc: 0.7321\n",
      "Epoch 3765/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3064 - acc: 0.9807 - val_loss: 0.6660 - val_acc: 0.7328\n",
      "Epoch 3766/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9821 - val_loss: 0.6660 - val_acc: 0.7325\n",
      "Epoch 3767/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9822 - val_loss: 0.6661 - val_acc: 0.7350\n",
      "Epoch 3768/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9820 - val_loss: 0.6631 - val_acc: 0.7346\n",
      "Epoch 3769/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9825 - val_loss: 0.6706 - val_acc: 0.7365\n",
      "Epoch 3770/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3064 - acc: 0.9820 - val_loss: 0.6671 - val_acc: 0.7383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3771/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9826 - val_loss: 0.6681 - val_acc: 0.7376\n",
      "Epoch 3772/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3065 - acc: 0.9834 - val_loss: 0.6674 - val_acc: 0.7372\n",
      "Epoch 3773/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3064 - acc: 0.9843 - val_loss: 0.6671 - val_acc: 0.7390\n",
      "Epoch 3774/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9846 - val_loss: 0.6671 - val_acc: 0.7383\n",
      "Epoch 3775/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9843 - val_loss: 0.6667 - val_acc: 0.7387\n",
      "Epoch 3776/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3065 - acc: 0.9840 - val_loss: 0.6694 - val_acc: 0.7387\n",
      "Epoch 3777/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3071 - acc: 0.9786 - val_loss: 0.6705 - val_acc: 0.7361\n",
      "Epoch 3778/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3083 - acc: 0.9773 - val_loss: 0.6669 - val_acc: 0.7292\n",
      "Epoch 3779/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3080 - acc: 0.9737 - val_loss: 0.6637 - val_acc: 0.7284\n",
      "Epoch 3780/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3071 - acc: 0.9771 - val_loss: 0.6635 - val_acc: 0.7295\n",
      "Epoch 3781/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9807 - val_loss: 0.6623 - val_acc: 0.7281\n",
      "Epoch 3782/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9821 - val_loss: 0.6622 - val_acc: 0.7284\n",
      "Epoch 3783/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9833 - val_loss: 0.6618 - val_acc: 0.7288\n",
      "Epoch 3784/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9834 - val_loss: 0.6616 - val_acc: 0.7281\n",
      "Epoch 3785/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6619 - val_acc: 0.7295\n",
      "Epoch 3786/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6621 - val_acc: 0.7303\n",
      "Epoch 3787/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9847 - val_loss: 0.6622 - val_acc: 0.7292\n",
      "Epoch 3788/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9851 - val_loss: 0.6621 - val_acc: 0.7295\n",
      "Epoch 3789/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9851 - val_loss: 0.6621 - val_acc: 0.7303\n",
      "Epoch 3790/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9854 - val_loss: 0.6620 - val_acc: 0.7314\n",
      "Epoch 3791/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9849 - val_loss: 0.6618 - val_acc: 0.7295\n",
      "Epoch 3792/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6622 - val_acc: 0.7306\n",
      "Epoch 3793/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6618 - val_acc: 0.7314\n",
      "Epoch 3794/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6636 - val_acc: 0.7317\n",
      "Epoch 3795/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6638 - val_acc: 0.7314\n",
      "Epoch 3796/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9856 - val_loss: 0.6623 - val_acc: 0.7336\n",
      "Epoch 3797/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9860 - val_loss: 0.6637 - val_acc: 0.7306\n",
      "Epoch 3798/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6622 - val_acc: 0.7314\n",
      "Epoch 3799/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6628 - val_acc: 0.7328\n",
      "Epoch 3800/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6618 - val_acc: 0.7321\n",
      "Epoch 3801/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6642 - val_acc: 0.7303\n",
      "Epoch 3802/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6646 - val_acc: 0.7288\n",
      "Epoch 3803/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9835 - val_loss: 0.6634 - val_acc: 0.7314\n",
      "Epoch 3804/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6640 - val_acc: 0.7299\n",
      "Epoch 3805/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6616 - val_acc: 0.7343\n",
      "Epoch 3806/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6654 - val_acc: 0.7303\n",
      "Epoch 3807/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6605 - val_acc: 0.7328\n",
      "Epoch 3808/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9804 - val_loss: 0.6617 - val_acc: 0.7339\n",
      "Epoch 3809/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6626 - val_acc: 0.7346\n",
      "Epoch 3810/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6643 - val_acc: 0.7343\n",
      "Epoch 3811/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6612 - val_acc: 0.7332\n",
      "Epoch 3812/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9831 - val_loss: 0.6597 - val_acc: 0.7336\n",
      "Epoch 3813/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9834 - val_loss: 0.6614 - val_acc: 0.7317\n",
      "Epoch 3814/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6591 - val_acc: 0.7317\n",
      "Epoch 3815/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6646 - val_acc: 0.7310\n",
      "Epoch 3816/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9808 - val_loss: 0.6603 - val_acc: 0.7314\n",
      "Epoch 3817/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6611 - val_acc: 0.7303\n",
      "Epoch 3818/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9805 - val_loss: 0.6588 - val_acc: 0.7321\n",
      "Epoch 3819/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6612 - val_acc: 0.7328\n",
      "Epoch 3820/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6597 - val_acc: 0.7339\n",
      "Epoch 3821/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6610 - val_acc: 0.7310\n",
      "Epoch 3822/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9809 - val_loss: 0.6587 - val_acc: 0.7314\n",
      "Epoch 3823/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6607 - val_acc: 0.7295\n",
      "Epoch 3824/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9823 - val_loss: 0.6593 - val_acc: 0.7295\n",
      "Epoch 3825/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6638 - val_acc: 0.7321\n",
      "Epoch 3826/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9804 - val_loss: 0.6612 - val_acc: 0.7321\n",
      "Epoch 3827/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9812 - val_loss: 0.6614 - val_acc: 0.7259\n",
      "Epoch 3828/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9809 - val_loss: 0.6597 - val_acc: 0.7317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3829/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9806 - val_loss: 0.6621 - val_acc: 0.7314\n",
      "Epoch 3830/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9814 - val_loss: 0.6591 - val_acc: 0.7306\n",
      "Epoch 3831/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6586 - val_acc: 0.7306\n",
      "Epoch 3832/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6615 - val_acc: 0.7328\n",
      "Epoch 3833/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6608 - val_acc: 0.7310\n",
      "Epoch 3834/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6611 - val_acc: 0.7310\n",
      "Epoch 3835/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6576 - val_acc: 0.7336\n",
      "Epoch 3836/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6607 - val_acc: 0.7288\n",
      "Epoch 3837/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9816 - val_loss: 0.6618 - val_acc: 0.7317\n",
      "Epoch 3838/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6598 - val_acc: 0.7303\n",
      "Epoch 3839/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9811 - val_loss: 0.6622 - val_acc: 0.7317\n",
      "Epoch 3840/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9826 - val_loss: 0.6601 - val_acc: 0.7339\n",
      "Epoch 3841/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6595 - val_acc: 0.7325\n",
      "Epoch 3842/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6600 - val_acc: 0.7314\n",
      "Epoch 3843/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9830 - val_loss: 0.6581 - val_acc: 0.7325\n",
      "Epoch 3844/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9816 - val_loss: 0.6577 - val_acc: 0.7321\n",
      "Epoch 3845/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3062 - acc: 0.9801 - val_loss: 0.6556 - val_acc: 0.7350\n",
      "Epoch 3846/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6584 - val_acc: 0.7336\n",
      "Epoch 3847/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6621 - val_acc: 0.7346\n",
      "Epoch 3848/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6606 - val_acc: 0.7339\n",
      "Epoch 3849/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3060 - acc: 0.9809 - val_loss: 0.6587 - val_acc: 0.7346\n",
      "Epoch 3850/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6570 - val_acc: 0.7350\n",
      "Epoch 3851/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9808 - val_loss: 0.6587 - val_acc: 0.7314\n",
      "Epoch 3852/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6554 - val_acc: 0.7357\n",
      "Epoch 3853/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3063 - acc: 0.9794 - val_loss: 0.6582 - val_acc: 0.7306\n",
      "Epoch 3854/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3079 - acc: 0.9747 - val_loss: 0.6685 - val_acc: 0.7405\n",
      "Epoch 3855/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3171 - acc: 0.9604 - val_loss: 0.6820 - val_acc: 0.7288\n",
      "Epoch 3856/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3099 - acc: 0.9688 - val_loss: 0.6773 - val_acc: 0.7303\n",
      "Epoch 3857/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3093 - acc: 0.9725 - val_loss: 0.6657 - val_acc: 0.7339\n",
      "Epoch 3858/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3078 - acc: 0.9743 - val_loss: 0.6670 - val_acc: 0.7328\n",
      "Epoch 3859/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3070 - acc: 0.9766 - val_loss: 0.6653 - val_acc: 0.7339\n",
      "Epoch 3860/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3067 - acc: 0.9772 - val_loss: 0.6661 - val_acc: 0.7321\n",
      "Epoch 3861/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9798 - val_loss: 0.6656 - val_acc: 0.7328\n",
      "Epoch 3862/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9800 - val_loss: 0.6654 - val_acc: 0.7332\n",
      "Epoch 3863/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9813 - val_loss: 0.6654 - val_acc: 0.7325\n",
      "Epoch 3864/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9808 - val_loss: 0.6655 - val_acc: 0.7339\n",
      "Epoch 3865/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6653 - val_acc: 0.7336\n",
      "Epoch 3866/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6659 - val_acc: 0.7343\n",
      "Epoch 3867/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6657 - val_acc: 0.7343\n",
      "Epoch 3868/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6659 - val_acc: 0.7350\n",
      "Epoch 3869/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6654 - val_acc: 0.7343\n",
      "Epoch 3870/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6656 - val_acc: 0.7332\n",
      "Epoch 3871/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6658 - val_acc: 0.7343\n",
      "Epoch 3872/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6657 - val_acc: 0.7339\n",
      "Epoch 3873/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6659 - val_acc: 0.7332\n",
      "Epoch 3874/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6657 - val_acc: 0.7343\n",
      "Epoch 3875/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6657 - val_acc: 0.7336\n",
      "Epoch 3876/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9853 - val_loss: 0.6658 - val_acc: 0.7332\n",
      "Epoch 3877/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9858 - val_loss: 0.6660 - val_acc: 0.7325\n",
      "Epoch 3878/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6657 - val_acc: 0.7317\n",
      "Epoch 3879/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6660 - val_acc: 0.7317\n",
      "Epoch 3880/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6652 - val_acc: 0.7317\n",
      "Epoch 3881/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6657 - val_acc: 0.7321\n",
      "Epoch 3882/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9856 - val_loss: 0.6653 - val_acc: 0.7310\n",
      "Epoch 3883/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6653 - val_acc: 0.7314\n",
      "Epoch 3884/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6653 - val_acc: 0.7314\n",
      "Epoch 3885/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9853 - val_loss: 0.6649 - val_acc: 0.7317\n",
      "Epoch 3886/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6649 - val_acc: 0.7310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3887/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6648 - val_acc: 0.7314\n",
      "Epoch 3888/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6659 - val_acc: 0.7292\n",
      "Epoch 3889/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6651 - val_acc: 0.7303\n",
      "Epoch 3890/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6658 - val_acc: 0.7325\n",
      "Epoch 3891/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6671 - val_acc: 0.7284\n",
      "Epoch 3892/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6654 - val_acc: 0.7325\n",
      "Epoch 3893/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6635 - val_acc: 0.7336\n",
      "Epoch 3894/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9798 - val_loss: 0.6648 - val_acc: 0.7339\n",
      "Epoch 3895/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6640 - val_acc: 0.7339\n",
      "Epoch 3896/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6644 - val_acc: 0.7328\n",
      "Epoch 3897/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6639 - val_acc: 0.7328\n",
      "Epoch 3898/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9824 - val_loss: 0.6642 - val_acc: 0.7299\n",
      "Epoch 3899/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9832 - val_loss: 0.6631 - val_acc: 0.7306\n",
      "Epoch 3900/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6639 - val_acc: 0.7284\n",
      "Epoch 3901/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6639 - val_acc: 0.7310\n",
      "Epoch 3902/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9828 - val_loss: 0.6644 - val_acc: 0.7321\n",
      "Epoch 3903/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6629 - val_acc: 0.7321\n",
      "Epoch 3904/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6639 - val_acc: 0.7336\n",
      "Epoch 3905/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9812 - val_loss: 0.6623 - val_acc: 0.7368\n",
      "Epoch 3906/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9828 - val_loss: 0.6654 - val_acc: 0.7328\n",
      "Epoch 3907/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9797 - val_loss: 0.6642 - val_acc: 0.7325\n",
      "Epoch 3908/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6637 - val_acc: 0.7343\n",
      "Epoch 3909/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9814 - val_loss: 0.6642 - val_acc: 0.7310\n",
      "Epoch 3910/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6635 - val_acc: 0.7321\n",
      "Epoch 3911/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9823 - val_loss: 0.6616 - val_acc: 0.7306\n",
      "Epoch 3912/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6640 - val_acc: 0.7317\n",
      "Epoch 3913/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6633 - val_acc: 0.7339\n",
      "Epoch 3914/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6625 - val_acc: 0.7332\n",
      "Epoch 3915/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9812 - val_loss: 0.6646 - val_acc: 0.7328\n",
      "Epoch 3916/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3081 - acc: 0.9753 - val_loss: 0.6617 - val_acc: 0.7368\n",
      "Epoch 3917/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3079 - acc: 0.9729 - val_loss: 0.6566 - val_acc: 0.7303\n",
      "Epoch 3918/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3072 - acc: 0.9748 - val_loss: 0.6584 - val_acc: 0.7310\n",
      "Epoch 3919/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3064 - acc: 0.9797 - val_loss: 0.6582 - val_acc: 0.7346\n",
      "Epoch 3920/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6584 - val_acc: 0.7336\n",
      "Epoch 3921/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6578 - val_acc: 0.7310\n",
      "Epoch 3922/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6582 - val_acc: 0.7336\n",
      "Epoch 3923/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6584 - val_acc: 0.7357\n",
      "Epoch 3924/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6579 - val_acc: 0.7339\n",
      "Epoch 3925/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6592 - val_acc: 0.7343\n",
      "Epoch 3926/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9844 - val_loss: 0.6584 - val_acc: 0.7339\n",
      "Epoch 3927/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6584 - val_acc: 0.7321\n",
      "Epoch 3928/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9856 - val_loss: 0.6586 - val_acc: 0.7336\n",
      "Epoch 3929/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9857 - val_loss: 0.6587 - val_acc: 0.7336\n",
      "Epoch 3930/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6590 - val_acc: 0.7332\n",
      "Epoch 3931/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6592 - val_acc: 0.7332\n",
      "Epoch 3932/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6584 - val_acc: 0.7321\n",
      "Epoch 3933/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6588 - val_acc: 0.7321\n",
      "Epoch 3934/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6585 - val_acc: 0.7343\n",
      "Epoch 3935/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6590 - val_acc: 0.7321\n",
      "Epoch 3936/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6584 - val_acc: 0.7292\n",
      "Epoch 3937/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9822 - val_loss: 0.6564 - val_acc: 0.7365\n",
      "Epoch 3938/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6586 - val_acc: 0.7317\n",
      "Epoch 3939/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9797 - val_loss: 0.6568 - val_acc: 0.7328\n",
      "Epoch 3940/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9781 - val_loss: 0.6597 - val_acc: 0.7346\n",
      "Epoch 3941/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9795 - val_loss: 0.6590 - val_acc: 0.7310\n",
      "Epoch 3942/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9800 - val_loss: 0.6570 - val_acc: 0.7350\n",
      "Epoch 3943/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6586 - val_acc: 0.7306\n",
      "Epoch 3944/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6567 - val_acc: 0.7357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3945/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9832 - val_loss: 0.6579 - val_acc: 0.7346\n",
      "Epoch 3946/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6575 - val_acc: 0.7346\n",
      "Epoch 3947/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6582 - val_acc: 0.7343\n",
      "Epoch 3948/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6569 - val_acc: 0.7332\n",
      "Epoch 3949/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6575 - val_acc: 0.7357\n",
      "Epoch 3950/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6581 - val_acc: 0.7336\n",
      "Epoch 3951/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6579 - val_acc: 0.7361\n",
      "Epoch 3952/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9812 - val_loss: 0.6580 - val_acc: 0.7343\n",
      "Epoch 3953/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9796 - val_loss: 0.6573 - val_acc: 0.7368\n",
      "Epoch 3954/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6585 - val_acc: 0.7314\n",
      "Epoch 3955/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9805 - val_loss: 0.6573 - val_acc: 0.7354\n",
      "Epoch 3956/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9799 - val_loss: 0.6573 - val_acc: 0.7354\n",
      "Epoch 3957/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3063 - acc: 0.9805 - val_loss: 0.6664 - val_acc: 0.7368\n",
      "Epoch 3958/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3090 - acc: 0.9710 - val_loss: 0.6735 - val_acc: 0.7332\n",
      "Epoch 3959/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3097 - acc: 0.9682 - val_loss: 0.6589 - val_acc: 0.7292\n",
      "Epoch 3960/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3081 - acc: 0.9732 - val_loss: 0.6711 - val_acc: 0.7273\n",
      "Epoch 3961/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3083 - acc: 0.9724 - val_loss: 0.6617 - val_acc: 0.7303\n",
      "Epoch 3962/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3069 - acc: 0.9771 - val_loss: 0.6625 - val_acc: 0.7336\n",
      "Epoch 3963/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9807 - val_loss: 0.6623 - val_acc: 0.7325\n",
      "Epoch 3964/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9815 - val_loss: 0.6626 - val_acc: 0.7336\n",
      "Epoch 3965/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9824 - val_loss: 0.6621 - val_acc: 0.7343\n",
      "Epoch 3966/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9835 - val_loss: 0.6622 - val_acc: 0.7336\n",
      "Epoch 3967/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6620 - val_acc: 0.7336\n",
      "Epoch 3968/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6618 - val_acc: 0.7325\n",
      "Epoch 3969/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6619 - val_acc: 0.7339\n",
      "Epoch 3970/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6615 - val_acc: 0.7336\n",
      "Epoch 3971/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6617 - val_acc: 0.7336\n",
      "Epoch 3972/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6615 - val_acc: 0.7332\n",
      "Epoch 3973/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9848 - val_loss: 0.6617 - val_acc: 0.7343\n",
      "Epoch 3974/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9856 - val_loss: 0.6616 - val_acc: 0.7343\n",
      "Epoch 3975/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9857 - val_loss: 0.6615 - val_acc: 0.7332\n",
      "Epoch 3976/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6613 - val_acc: 0.7346\n",
      "Epoch 3977/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9862 - val_loss: 0.6611 - val_acc: 0.7332\n",
      "Epoch 3978/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9849 - val_loss: 0.6614 - val_acc: 0.7336\n",
      "Epoch 3979/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9857 - val_loss: 0.6615 - val_acc: 0.7339\n",
      "Epoch 3980/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9861 - val_loss: 0.6612 - val_acc: 0.7325\n",
      "Epoch 3981/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3058 - acc: 0.9862 - val_loss: 0.6609 - val_acc: 0.7328\n",
      "Epoch 3982/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9859 - val_loss: 0.6610 - val_acc: 0.7346\n",
      "Epoch 3983/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9869 - val_loss: 0.6608 - val_acc: 0.7346\n",
      "Epoch 3984/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6607 - val_acc: 0.7343\n",
      "Epoch 3985/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6613 - val_acc: 0.7346\n",
      "Epoch 3986/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9861 - val_loss: 0.6608 - val_acc: 0.7354\n",
      "Epoch 3987/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6607 - val_acc: 0.7328\n",
      "Epoch 3988/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9834 - val_loss: 0.6611 - val_acc: 0.7336\n",
      "Epoch 3989/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6600 - val_acc: 0.7336\n",
      "Epoch 3990/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6607 - val_acc: 0.7314\n",
      "Epoch 3991/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6601 - val_acc: 0.7321\n",
      "Epoch 3992/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9817 - val_loss: 0.6587 - val_acc: 0.7336\n",
      "Epoch 3993/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9790 - val_loss: 0.6600 - val_acc: 0.7354\n",
      "Epoch 3994/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9794 - val_loss: 0.6596 - val_acc: 0.7321\n",
      "Epoch 3995/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3067 - acc: 0.9795 - val_loss: 0.6663 - val_acc: 0.7314\n",
      "Epoch 3996/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3124 - acc: 0.9652 - val_loss: 0.6693 - val_acc: 0.7281\n",
      "Epoch 3997/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3125 - acc: 0.9630 - val_loss: 0.6757 - val_acc: 0.7292\n",
      "Epoch 3998/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3101 - acc: 0.9678 - val_loss: 0.6716 - val_acc: 0.7248\n",
      "Epoch 3999/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3084 - acc: 0.9715 - val_loss: 0.6648 - val_acc: 0.7339\n",
      "Epoch 4000/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3076 - acc: 0.9731 - val_loss: 0.6702 - val_acc: 0.7346\n",
      "Epoch 4001/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3069 - acc: 0.9753 - val_loss: 0.6687 - val_acc: 0.7314\n",
      "Epoch 4002/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3067 - acc: 0.9779 - val_loss: 0.6684 - val_acc: 0.7325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4003/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3066 - acc: 0.9798 - val_loss: 0.6681 - val_acc: 0.7332\n",
      "Epoch 4004/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9796 - val_loss: 0.6679 - val_acc: 0.7303\n",
      "Epoch 4005/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9803 - val_loss: 0.6673 - val_acc: 0.7310\n",
      "Epoch 4006/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9810 - val_loss: 0.6667 - val_acc: 0.7295\n",
      "Epoch 4007/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9820 - val_loss: 0.6662 - val_acc: 0.7310\n",
      "Epoch 4008/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9822 - val_loss: 0.6662 - val_acc: 0.7303\n",
      "Epoch 4009/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6665 - val_acc: 0.7292\n",
      "Epoch 4010/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6662 - val_acc: 0.7292\n",
      "Epoch 4011/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9836 - val_loss: 0.6660 - val_acc: 0.7292\n",
      "Epoch 4012/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9834 - val_loss: 0.6663 - val_acc: 0.7284\n",
      "Epoch 4013/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9836 - val_loss: 0.6660 - val_acc: 0.7292\n",
      "Epoch 4014/10000\n",
      "4259/4259 [==============================] - 2s 464us/step - loss: 0.3061 - acc: 0.9842 - val_loss: 0.6660 - val_acc: 0.7284\n",
      "Epoch 4015/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9844 - val_loss: 0.6658 - val_acc: 0.7281\n",
      "Epoch 4016/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9846 - val_loss: 0.6657 - val_acc: 0.7292\n",
      "Epoch 4017/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9846 - val_loss: 0.6652 - val_acc: 0.7281\n",
      "Epoch 4018/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9846 - val_loss: 0.6653 - val_acc: 0.7281\n",
      "Epoch 4019/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9847 - val_loss: 0.6586 - val_acc: 0.7310\n",
      "Epoch 4020/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3068 - acc: 0.9801 - val_loss: 0.6615 - val_acc: 0.7288\n",
      "Epoch 4021/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9832 - val_loss: 0.6617 - val_acc: 0.7317\n",
      "Epoch 4022/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9835 - val_loss: 0.6634 - val_acc: 0.7303\n",
      "Epoch 4023/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6628 - val_acc: 0.7306\n",
      "Epoch 4024/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6628 - val_acc: 0.7299\n",
      "Epoch 4025/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6631 - val_acc: 0.7325\n",
      "Epoch 4026/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6631 - val_acc: 0.7310\n",
      "Epoch 4027/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6627 - val_acc: 0.7306\n",
      "Epoch 4028/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6627 - val_acc: 0.7299\n",
      "Epoch 4029/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6629 - val_acc: 0.7303\n",
      "Epoch 4030/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6627 - val_acc: 0.7299\n",
      "Epoch 4031/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6625 - val_acc: 0.7310\n",
      "Epoch 4032/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6635 - val_acc: 0.7317\n",
      "Epoch 4033/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6621 - val_acc: 0.7336\n",
      "Epoch 4034/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9831 - val_loss: 0.6613 - val_acc: 0.7325\n",
      "Epoch 4035/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6640 - val_acc: 0.7306\n",
      "Epoch 4036/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9826 - val_loss: 0.6605 - val_acc: 0.7295\n",
      "Epoch 4037/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6624 - val_acc: 0.7244\n",
      "Epoch 4038/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9820 - val_loss: 0.6591 - val_acc: 0.7299\n",
      "Epoch 4039/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9826 - val_loss: 0.6602 - val_acc: 0.7325\n",
      "Epoch 4040/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6595 - val_acc: 0.7306\n",
      "Epoch 4041/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6596 - val_acc: 0.7295\n",
      "Epoch 4042/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6594 - val_acc: 0.7299\n",
      "Epoch 4043/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9832 - val_loss: 0.6595 - val_acc: 0.7292\n",
      "Epoch 4044/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6602 - val_acc: 0.7346\n",
      "Epoch 4045/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6597 - val_acc: 0.7299\n",
      "Epoch 4046/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6586 - val_acc: 0.7332\n",
      "Epoch 4047/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6596 - val_acc: 0.7325\n",
      "Epoch 4048/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6586 - val_acc: 0.7325\n",
      "Epoch 4049/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9808 - val_loss: 0.6600 - val_acc: 0.7314\n",
      "Epoch 4050/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9788 - val_loss: 0.6575 - val_acc: 0.7328\n",
      "Epoch 4051/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9814 - val_loss: 0.6588 - val_acc: 0.7321\n",
      "Epoch 4052/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9806 - val_loss: 0.6590 - val_acc: 0.7310\n",
      "Epoch 4053/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9814 - val_loss: 0.6589 - val_acc: 0.7310\n",
      "Epoch 4054/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3068 - acc: 0.9780 - val_loss: 0.6607 - val_acc: 0.7259\n",
      "Epoch 4055/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3091 - acc: 0.9717 - val_loss: 0.6752 - val_acc: 0.7251\n",
      "Epoch 4056/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3154 - acc: 0.9614 - val_loss: 0.6771 - val_acc: 0.7292\n",
      "Epoch 4057/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3129 - acc: 0.9680 - val_loss: 0.6781 - val_acc: 0.7325\n",
      "Epoch 4058/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3123 - acc: 0.9657 - val_loss: 0.6666 - val_acc: 0.7328\n",
      "Epoch 4059/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3098 - acc: 0.9710 - val_loss: 0.6679 - val_acc: 0.7361\n",
      "Epoch 4060/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3080 - acc: 0.9744 - val_loss: 0.6633 - val_acc: 0.7357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4061/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3074 - acc: 0.9773 - val_loss: 0.6637 - val_acc: 0.7354\n",
      "Epoch 4062/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3072 - acc: 0.9776 - val_loss: 0.6634 - val_acc: 0.7343\n",
      "Epoch 4063/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3070 - acc: 0.9786 - val_loss: 0.6633 - val_acc: 0.7346\n",
      "Epoch 4064/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3069 - acc: 0.9796 - val_loss: 0.6632 - val_acc: 0.7336\n",
      "Epoch 4065/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3068 - acc: 0.9800 - val_loss: 0.6634 - val_acc: 0.7376\n",
      "Epoch 4066/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3068 - acc: 0.9798 - val_loss: 0.6634 - val_acc: 0.7368\n",
      "Epoch 4067/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3126 - acc: 0.9663 - val_loss: 0.6734 - val_acc: 0.7306\n",
      "Epoch 4068/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3084 - acc: 0.9756 - val_loss: 0.6701 - val_acc: 0.7346\n",
      "Epoch 4069/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3075 - acc: 0.9756 - val_loss: 0.6723 - val_acc: 0.7346\n",
      "Epoch 4070/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3070 - acc: 0.9777 - val_loss: 0.6683 - val_acc: 0.7339\n",
      "Epoch 4071/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3067 - acc: 0.9797 - val_loss: 0.6684 - val_acc: 0.7317\n",
      "Epoch 4072/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3065 - acc: 0.9800 - val_loss: 0.6676 - val_acc: 0.7328\n",
      "Epoch 4073/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3064 - acc: 0.9803 - val_loss: 0.6670 - val_acc: 0.7310\n",
      "Epoch 4074/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3063 - acc: 0.9816 - val_loss: 0.6674 - val_acc: 0.7310\n",
      "Epoch 4075/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9813 - val_loss: 0.6671 - val_acc: 0.7321\n",
      "Epoch 4076/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9815 - val_loss: 0.6667 - val_acc: 0.7321\n",
      "Epoch 4077/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9822 - val_loss: 0.6667 - val_acc: 0.7328\n",
      "Epoch 4078/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9820 - val_loss: 0.6666 - val_acc: 0.7303\n",
      "Epoch 4079/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9831 - val_loss: 0.6664 - val_acc: 0.7306\n",
      "Epoch 4080/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9828 - val_loss: 0.6665 - val_acc: 0.7314\n",
      "Epoch 4081/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6663 - val_acc: 0.7295\n",
      "Epoch 4082/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9832 - val_loss: 0.6662 - val_acc: 0.7306\n",
      "Epoch 4083/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6661 - val_acc: 0.7328\n",
      "Epoch 4084/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6660 - val_acc: 0.7306\n",
      "Epoch 4085/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6656 - val_acc: 0.7310\n",
      "Epoch 4086/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6661 - val_acc: 0.7303\n",
      "Epoch 4087/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9839 - val_loss: 0.6658 - val_acc: 0.7314\n",
      "Epoch 4088/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9835 - val_loss: 0.6661 - val_acc: 0.7317\n",
      "Epoch 4089/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9846 - val_loss: 0.6657 - val_acc: 0.7303\n",
      "Epoch 4090/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9851 - val_loss: 0.6657 - val_acc: 0.7325\n",
      "Epoch 4091/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9842 - val_loss: 0.6662 - val_acc: 0.7321\n",
      "Epoch 4092/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6657 - val_acc: 0.7328\n",
      "Epoch 4093/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6659 - val_acc: 0.7332\n",
      "Epoch 4094/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9848 - val_loss: 0.6651 - val_acc: 0.7317\n",
      "Epoch 4095/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6657 - val_acc: 0.7354\n",
      "Epoch 4096/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6652 - val_acc: 0.7314\n",
      "Epoch 4097/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6657 - val_acc: 0.7332\n",
      "Epoch 4098/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6652 - val_acc: 0.7325\n",
      "Epoch 4099/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6652 - val_acc: 0.7314\n",
      "Epoch 4100/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6653 - val_acc: 0.7325\n",
      "Epoch 4101/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6648 - val_acc: 0.7299\n",
      "Epoch 4102/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6645 - val_acc: 0.7314\n",
      "Epoch 4103/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6651 - val_acc: 0.7328\n",
      "Epoch 4104/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6645 - val_acc: 0.7336\n",
      "Epoch 4105/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6652 - val_acc: 0.7336\n",
      "Epoch 4106/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6634 - val_acc: 0.7325\n",
      "Epoch 4107/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9834 - val_loss: 0.6643 - val_acc: 0.7339\n",
      "Epoch 4108/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6641 - val_acc: 0.7317\n",
      "Epoch 4109/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9837 - val_loss: 0.6636 - val_acc: 0.7325\n",
      "Epoch 4110/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9823 - val_loss: 0.6632 - val_acc: 0.7357\n",
      "Epoch 4111/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6626 - val_acc: 0.7336\n",
      "Epoch 4112/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6600 - val_acc: 0.7357\n",
      "Epoch 4113/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9795 - val_loss: 0.6613 - val_acc: 0.7321\n",
      "Epoch 4114/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6621 - val_acc: 0.7314\n",
      "Epoch 4115/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9817 - val_loss: 0.6641 - val_acc: 0.7332\n",
      "Epoch 4116/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6608 - val_acc: 0.7332\n",
      "Epoch 4117/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6619 - val_acc: 0.7361\n",
      "Epoch 4118/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6605 - val_acc: 0.7361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4119/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6597 - val_acc: 0.7361\n",
      "Epoch 4120/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9837 - val_loss: 0.6608 - val_acc: 0.7350\n",
      "Epoch 4121/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6588 - val_acc: 0.7339\n",
      "Epoch 4122/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9832 - val_loss: 0.6596 - val_acc: 0.7328\n",
      "Epoch 4123/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6615 - val_acc: 0.7339\n",
      "Epoch 4124/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6596 - val_acc: 0.7365\n",
      "Epoch 4125/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6613 - val_acc: 0.7376\n",
      "Epoch 4126/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6612 - val_acc: 0.7325\n",
      "Epoch 4127/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9806 - val_loss: 0.6602 - val_acc: 0.7346\n",
      "Epoch 4128/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3065 - acc: 0.9782 - val_loss: 0.6601 - val_acc: 0.7310\n",
      "Epoch 4129/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3064 - acc: 0.9794 - val_loss: 0.6580 - val_acc: 0.7343\n",
      "Epoch 4130/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3070 - acc: 0.9775 - val_loss: 0.6632 - val_acc: 0.7357\n",
      "Epoch 4131/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3105 - acc: 0.9677 - val_loss: 0.6634 - val_acc: 0.7284\n",
      "Epoch 4132/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3087 - acc: 0.9681 - val_loss: 0.6651 - val_acc: 0.7368\n",
      "Epoch 4133/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3070 - acc: 0.9759 - val_loss: 0.6648 - val_acc: 0.7350\n",
      "Epoch 4134/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3074 - acc: 0.9751 - val_loss: 0.6657 - val_acc: 0.7332\n",
      "Epoch 4135/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3080 - acc: 0.9760 - val_loss: 0.6706 - val_acc: 0.7299\n",
      "Epoch 4136/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3070 - acc: 0.9767 - val_loss: 0.6677 - val_acc: 0.7339\n",
      "Epoch 4137/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9779 - val_loss: 0.6682 - val_acc: 0.7357\n",
      "Epoch 4138/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9799 - val_loss: 0.6674 - val_acc: 0.7383\n",
      "Epoch 4139/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6672 - val_acc: 0.7372\n",
      "Epoch 4140/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6672 - val_acc: 0.7379\n",
      "Epoch 4141/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9820 - val_loss: 0.6670 - val_acc: 0.7372\n",
      "Epoch 4142/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6670 - val_acc: 0.7372\n",
      "Epoch 4143/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9830 - val_loss: 0.6671 - val_acc: 0.7387\n",
      "Epoch 4144/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6662 - val_acc: 0.7372\n",
      "Epoch 4145/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9832 - val_loss: 0.6671 - val_acc: 0.7376\n",
      "Epoch 4146/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6673 - val_acc: 0.7387\n",
      "Epoch 4147/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6673 - val_acc: 0.7383\n",
      "Epoch 4148/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6670 - val_acc: 0.7394\n",
      "Epoch 4149/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6666 - val_acc: 0.7372\n",
      "Epoch 4150/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9846 - val_loss: 0.6666 - val_acc: 0.7368\n",
      "Epoch 4151/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6663 - val_acc: 0.7390\n",
      "Epoch 4152/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9857 - val_loss: 0.6669 - val_acc: 0.7376\n",
      "Epoch 4153/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6658 - val_acc: 0.7379\n",
      "Epoch 4154/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3058 - acc: 0.9849 - val_loss: 0.6665 - val_acc: 0.7376\n",
      "Epoch 4155/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6658 - val_acc: 0.7394\n",
      "Epoch 4156/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6656 - val_acc: 0.7387\n",
      "Epoch 4157/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3058 - acc: 0.9855 - val_loss: 0.6658 - val_acc: 0.7379\n",
      "Epoch 4158/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9846 - val_loss: 0.6654 - val_acc: 0.7372\n",
      "Epoch 4159/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3058 - acc: 0.9849 - val_loss: 0.6652 - val_acc: 0.7390\n",
      "Epoch 4160/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6654 - val_acc: 0.7394\n",
      "Epoch 4161/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3058 - acc: 0.9836 - val_loss: 0.6654 - val_acc: 0.7372\n",
      "Epoch 4162/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6654 - val_acc: 0.7394\n",
      "Epoch 4163/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9827 - val_loss: 0.6647 - val_acc: 0.7361\n",
      "Epoch 4164/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6643 - val_acc: 0.7379\n",
      "Epoch 4165/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9817 - val_loss: 0.6656 - val_acc: 0.7361\n",
      "Epoch 4166/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6654 - val_acc: 0.7383\n",
      "Epoch 4167/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9806 - val_loss: 0.6660 - val_acc: 0.7383\n",
      "Epoch 4168/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6651 - val_acc: 0.7398\n",
      "Epoch 4169/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9800 - val_loss: 0.6650 - val_acc: 0.7390\n",
      "Epoch 4170/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9819 - val_loss: 0.6645 - val_acc: 0.7401\n",
      "Epoch 4171/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6660 - val_acc: 0.7357\n",
      "Epoch 4172/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9824 - val_loss: 0.6644 - val_acc: 0.7387\n",
      "Epoch 4173/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6633 - val_acc: 0.7398\n",
      "Epoch 4174/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9822 - val_loss: 0.6635 - val_acc: 0.7383\n",
      "Epoch 4175/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9828 - val_loss: 0.6633 - val_acc: 0.7365\n",
      "Epoch 4176/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6622 - val_acc: 0.7387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4177/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9812 - val_loss: 0.6635 - val_acc: 0.7412\n",
      "Epoch 4178/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9791 - val_loss: 0.6627 - val_acc: 0.7383\n",
      "Epoch 4179/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3063 - acc: 0.9796 - val_loss: 0.6634 - val_acc: 0.7390\n",
      "Epoch 4180/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9809 - val_loss: 0.6612 - val_acc: 0.7372\n",
      "Epoch 4181/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9810 - val_loss: 0.6629 - val_acc: 0.7372\n",
      "Epoch 4182/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9814 - val_loss: 0.6612 - val_acc: 0.7357\n",
      "Epoch 4183/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6602 - val_acc: 0.7354\n",
      "Epoch 4184/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9819 - val_loss: 0.6612 - val_acc: 0.7390\n",
      "Epoch 4185/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6597 - val_acc: 0.7343\n",
      "Epoch 4186/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9830 - val_loss: 0.6601 - val_acc: 0.7394\n",
      "Epoch 4187/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6590 - val_acc: 0.7383\n",
      "Epoch 4188/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6612 - val_acc: 0.7368\n",
      "Epoch 4189/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6611 - val_acc: 0.7379\n",
      "Epoch 4190/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6624 - val_acc: 0.7350\n",
      "Epoch 4191/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9804 - val_loss: 0.6609 - val_acc: 0.7387\n",
      "Epoch 4192/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6586 - val_acc: 0.7350\n",
      "Epoch 4193/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9802 - val_loss: 0.6590 - val_acc: 0.7357\n",
      "Epoch 4194/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6589 - val_acc: 0.7387\n",
      "Epoch 4195/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6577 - val_acc: 0.7376\n",
      "Epoch 4196/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9813 - val_loss: 0.6607 - val_acc: 0.7365\n",
      "Epoch 4197/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6582 - val_acc: 0.7361\n",
      "Epoch 4198/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9831 - val_loss: 0.6580 - val_acc: 0.7401\n",
      "Epoch 4199/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9811 - val_loss: 0.6590 - val_acc: 0.7376\n",
      "Epoch 4200/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6592 - val_acc: 0.7376\n",
      "Epoch 4201/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9817 - val_loss: 0.6583 - val_acc: 0.7365\n",
      "Epoch 4202/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9805 - val_loss: 0.6597 - val_acc: 0.7346\n",
      "Epoch 4203/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6572 - val_acc: 0.7354\n",
      "Epoch 4204/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9806 - val_loss: 0.6567 - val_acc: 0.7379\n",
      "Epoch 4205/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9804 - val_loss: 0.6569 - val_acc: 0.7372\n",
      "Epoch 4206/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6569 - val_acc: 0.7361\n",
      "Epoch 4207/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9813 - val_loss: 0.6571 - val_acc: 0.7379\n",
      "Epoch 4208/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6561 - val_acc: 0.7346\n",
      "Epoch 4209/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9822 - val_loss: 0.6569 - val_acc: 0.7390\n",
      "Epoch 4210/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6580 - val_acc: 0.7390\n",
      "Epoch 4211/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6570 - val_acc: 0.7346\n",
      "Epoch 4212/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6558 - val_acc: 0.7361\n",
      "Epoch 4213/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6581 - val_acc: 0.7321\n",
      "Epoch 4214/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3065 - acc: 0.9785 - val_loss: 0.6586 - val_acc: 0.7343\n",
      "Epoch 4215/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3074 - acc: 0.9762 - val_loss: 0.6622 - val_acc: 0.7325\n",
      "Epoch 4216/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3112 - acc: 0.9653 - val_loss: 0.6686 - val_acc: 0.7346\n",
      "Epoch 4217/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3103 - acc: 0.9685 - val_loss: 0.6740 - val_acc: 0.7339\n",
      "Epoch 4218/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3083 - acc: 0.9717 - val_loss: 0.6673 - val_acc: 0.7346\n",
      "Epoch 4219/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3068 - acc: 0.9776 - val_loss: 0.6647 - val_acc: 0.7339\n",
      "Epoch 4220/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3065 - acc: 0.9789 - val_loss: 0.6638 - val_acc: 0.7365\n",
      "Epoch 4221/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6637 - val_acc: 0.7372\n",
      "Epoch 4222/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9817 - val_loss: 0.6633 - val_acc: 0.7368\n",
      "Epoch 4223/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6623 - val_acc: 0.7368\n",
      "Epoch 4224/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6628 - val_acc: 0.7372\n",
      "Epoch 4225/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6626 - val_acc: 0.7379\n",
      "Epoch 4226/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6621 - val_acc: 0.7383\n",
      "Epoch 4227/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6621 - val_acc: 0.7379\n",
      "Epoch 4228/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6618 - val_acc: 0.7376\n",
      "Epoch 4229/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6618 - val_acc: 0.7361\n",
      "Epoch 4230/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9855 - val_loss: 0.6618 - val_acc: 0.7368\n",
      "Epoch 4231/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6618 - val_acc: 0.7368\n",
      "Epoch 4232/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9856 - val_loss: 0.6618 - val_acc: 0.7357\n",
      "Epoch 4233/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9860 - val_loss: 0.6613 - val_acc: 0.7376\n",
      "Epoch 4234/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6621 - val_acc: 0.7354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4235/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9864 - val_loss: 0.6616 - val_acc: 0.7346\n",
      "Epoch 4236/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6617 - val_acc: 0.7361\n",
      "Epoch 4237/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9855 - val_loss: 0.6618 - val_acc: 0.7354\n",
      "Epoch 4238/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9860 - val_loss: 0.6622 - val_acc: 0.7357\n",
      "Epoch 4239/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9859 - val_loss: 0.6614 - val_acc: 0.7357\n",
      "Epoch 4240/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3058 - acc: 0.9856 - val_loss: 0.6620 - val_acc: 0.7361\n",
      "Epoch 4241/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3058 - acc: 0.9859 - val_loss: 0.6613 - val_acc: 0.7350\n",
      "Epoch 4242/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6624 - val_acc: 0.7361\n",
      "Epoch 4243/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9853 - val_loss: 0.6609 - val_acc: 0.7346\n",
      "Epoch 4244/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9856 - val_loss: 0.6621 - val_acc: 0.7372\n",
      "Epoch 4245/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6604 - val_acc: 0.7354\n",
      "Epoch 4246/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6617 - val_acc: 0.7368\n",
      "Epoch 4247/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6607 - val_acc: 0.7357\n",
      "Epoch 4248/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9817 - val_loss: 0.6593 - val_acc: 0.7394\n",
      "Epoch 4249/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9795 - val_loss: 0.6687 - val_acc: 0.7314\n",
      "Epoch 4250/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3102 - acc: 0.9714 - val_loss: 0.6706 - val_acc: 0.7357\n",
      "Epoch 4251/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3117 - acc: 0.9674 - val_loss: 0.6750 - val_acc: 0.7237\n",
      "Epoch 4252/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3099 - acc: 0.9734 - val_loss: 0.6716 - val_acc: 0.7292\n",
      "Epoch 4253/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3082 - acc: 0.9762 - val_loss: 0.6697 - val_acc: 0.7328\n",
      "Epoch 4254/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3069 - acc: 0.9769 - val_loss: 0.6674 - val_acc: 0.7325\n",
      "Epoch 4255/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9781 - val_loss: 0.6673 - val_acc: 0.7292\n",
      "Epoch 4256/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9789 - val_loss: 0.6665 - val_acc: 0.7306\n",
      "Epoch 4257/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9802 - val_loss: 0.6668 - val_acc: 0.7288\n",
      "Epoch 4258/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9806 - val_loss: 0.6674 - val_acc: 0.7281\n",
      "Epoch 4259/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9813 - val_loss: 0.6667 - val_acc: 0.7295\n",
      "Epoch 4260/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6665 - val_acc: 0.7299\n",
      "Epoch 4261/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6646 - val_acc: 0.7295\n",
      "Epoch 4262/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6634 - val_acc: 0.7299\n",
      "Epoch 4263/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6633 - val_acc: 0.7284\n",
      "Epoch 4264/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6631 - val_acc: 0.7288\n",
      "Epoch 4265/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9834 - val_loss: 0.6632 - val_acc: 0.7292\n",
      "Epoch 4266/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6632 - val_acc: 0.7310\n",
      "Epoch 4267/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9834 - val_loss: 0.6639 - val_acc: 0.7310\n",
      "Epoch 4268/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6638 - val_acc: 0.7325\n",
      "Epoch 4269/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6640 - val_acc: 0.7303\n",
      "Epoch 4270/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6639 - val_acc: 0.7292\n",
      "Epoch 4271/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6637 - val_acc: 0.7317\n",
      "Epoch 4272/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6636 - val_acc: 0.7310\n",
      "Epoch 4273/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6632 - val_acc: 0.7295\n",
      "Epoch 4274/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6635 - val_acc: 0.7306\n",
      "Epoch 4275/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6635 - val_acc: 0.7281\n",
      "Epoch 4276/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6633 - val_acc: 0.7303\n",
      "Epoch 4277/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9848 - val_loss: 0.6639 - val_acc: 0.7310\n",
      "Epoch 4278/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6635 - val_acc: 0.7295\n",
      "Epoch 4279/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6635 - val_acc: 0.7306\n",
      "Epoch 4280/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3058 - acc: 0.9844 - val_loss: 0.6639 - val_acc: 0.7295\n",
      "Epoch 4281/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6637 - val_acc: 0.7303\n",
      "Epoch 4282/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6632 - val_acc: 0.7306\n",
      "Epoch 4283/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6641 - val_acc: 0.7284\n",
      "Epoch 4284/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6643 - val_acc: 0.7288\n",
      "Epoch 4285/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6637 - val_acc: 0.7262\n",
      "Epoch 4286/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9824 - val_loss: 0.6624 - val_acc: 0.7314\n",
      "Epoch 4287/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6617 - val_acc: 0.7288\n",
      "Epoch 4288/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9819 - val_loss: 0.6631 - val_acc: 0.7328\n",
      "Epoch 4289/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6595 - val_acc: 0.7292\n",
      "Epoch 4290/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6611 - val_acc: 0.7288\n",
      "Epoch 4291/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9817 - val_loss: 0.6613 - val_acc: 0.7292\n",
      "Epoch 4292/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6625 - val_acc: 0.7306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4293/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9822 - val_loss: 0.6610 - val_acc: 0.7270\n",
      "Epoch 4294/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9846 - val_loss: 0.6589 - val_acc: 0.7259\n",
      "Epoch 4295/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6613 - val_acc: 0.7303\n",
      "Epoch 4296/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9819 - val_loss: 0.6603 - val_acc: 0.7284\n",
      "Epoch 4297/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6604 - val_acc: 0.7281\n",
      "Epoch 4298/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9819 - val_loss: 0.6606 - val_acc: 0.7277\n",
      "Epoch 4299/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9822 - val_loss: 0.6610 - val_acc: 0.7273\n",
      "Epoch 4300/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9832 - val_loss: 0.6606 - val_acc: 0.7332\n",
      "Epoch 4301/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6602 - val_acc: 0.7310\n",
      "Epoch 4302/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6591 - val_acc: 0.7332\n",
      "Epoch 4303/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9831 - val_loss: 0.6610 - val_acc: 0.7336\n",
      "Epoch 4304/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6595 - val_acc: 0.7314\n",
      "Epoch 4305/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6584 - val_acc: 0.7328\n",
      "Epoch 4306/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9800 - val_loss: 0.6590 - val_acc: 0.7325\n",
      "Epoch 4307/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9809 - val_loss: 0.6652 - val_acc: 0.7368\n",
      "Epoch 4308/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3106 - acc: 0.9671 - val_loss: 0.6867 - val_acc: 0.7226\n",
      "Epoch 4309/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3152 - acc: 0.9598 - val_loss: 0.6768 - val_acc: 0.7281\n",
      "Epoch 4310/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3104 - acc: 0.9709 - val_loss: 0.6691 - val_acc: 0.7248\n",
      "Epoch 4311/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3135 - acc: 0.9696 - val_loss: 0.6860 - val_acc: 0.7244\n",
      "Epoch 4312/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3097 - acc: 0.9715 - val_loss: 0.6815 - val_acc: 0.7288\n",
      "Epoch 4313/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3081 - acc: 0.9721 - val_loss: 0.6830 - val_acc: 0.7303\n",
      "Epoch 4314/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3074 - acc: 0.9746 - val_loss: 0.6810 - val_acc: 0.7259\n",
      "Epoch 4315/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3070 - acc: 0.9749 - val_loss: 0.6791 - val_acc: 0.7262\n",
      "Epoch 4316/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3068 - acc: 0.9769 - val_loss: 0.6787 - val_acc: 0.7259\n",
      "Epoch 4317/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3067 - acc: 0.9784 - val_loss: 0.6787 - val_acc: 0.7273\n",
      "Epoch 4318/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3066 - acc: 0.9786 - val_loss: 0.6780 - val_acc: 0.7277\n",
      "Epoch 4319/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9793 - val_loss: 0.6780 - val_acc: 0.7266\n",
      "Epoch 4320/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9799 - val_loss: 0.6772 - val_acc: 0.7266\n",
      "Epoch 4321/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9801 - val_loss: 0.6773 - val_acc: 0.7259\n",
      "Epoch 4322/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9803 - val_loss: 0.6765 - val_acc: 0.7262\n",
      "Epoch 4323/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9808 - val_loss: 0.6768 - val_acc: 0.7273\n",
      "Epoch 4324/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9812 - val_loss: 0.6764 - val_acc: 0.7266\n",
      "Epoch 4325/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9812 - val_loss: 0.6757 - val_acc: 0.7288\n",
      "Epoch 4326/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6760 - val_acc: 0.7259\n",
      "Epoch 4327/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9817 - val_loss: 0.6756 - val_acc: 0.7284\n",
      "Epoch 4328/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6752 - val_acc: 0.7273\n",
      "Epoch 4329/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6755 - val_acc: 0.7266\n",
      "Epoch 4330/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6751 - val_acc: 0.7266\n",
      "Epoch 4331/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6753 - val_acc: 0.7284\n",
      "Epoch 4332/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9822 - val_loss: 0.6754 - val_acc: 0.7273\n",
      "Epoch 4333/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6754 - val_acc: 0.7273\n",
      "Epoch 4334/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6748 - val_acc: 0.7266\n",
      "Epoch 4335/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6751 - val_acc: 0.7273\n",
      "Epoch 4336/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9832 - val_loss: 0.6748 - val_acc: 0.7266\n",
      "Epoch 4337/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6743 - val_acc: 0.7259\n",
      "Epoch 4338/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6735 - val_acc: 0.7273\n",
      "Epoch 4339/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6734 - val_acc: 0.7259\n",
      "Epoch 4340/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6737 - val_acc: 0.7284\n",
      "Epoch 4341/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6735 - val_acc: 0.7299\n",
      "Epoch 4342/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6730 - val_acc: 0.7288\n",
      "Epoch 4343/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6738 - val_acc: 0.7306\n",
      "Epoch 4344/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6739 - val_acc: 0.7277\n",
      "Epoch 4345/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6757 - val_acc: 0.7295\n",
      "Epoch 4346/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6750 - val_acc: 0.7273\n",
      "Epoch 4347/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6735 - val_acc: 0.7284\n",
      "Epoch 4348/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6741 - val_acc: 0.7306\n",
      "Epoch 4349/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6734 - val_acc: 0.7295\n",
      "Epoch 4350/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6756 - val_acc: 0.7270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4351/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6742 - val_acc: 0.7259\n",
      "Epoch 4352/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6737 - val_acc: 0.7299\n",
      "Epoch 4353/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6734 - val_acc: 0.7292\n",
      "Epoch 4354/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6741 - val_acc: 0.7273\n",
      "Epoch 4355/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6738 - val_acc: 0.7266\n",
      "Epoch 4356/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6749 - val_acc: 0.7273\n",
      "Epoch 4357/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6750 - val_acc: 0.7270\n",
      "Epoch 4358/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9848 - val_loss: 0.6731 - val_acc: 0.7262\n",
      "Epoch 4359/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6722 - val_acc: 0.7273\n",
      "Epoch 4360/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6739 - val_acc: 0.7255\n",
      "Epoch 4361/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9837 - val_loss: 0.6714 - val_acc: 0.7299\n",
      "Epoch 4362/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9831 - val_loss: 0.6727 - val_acc: 0.7277\n",
      "Epoch 4363/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6717 - val_acc: 0.7281\n",
      "Epoch 4364/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9822 - val_loss: 0.6743 - val_acc: 0.7262\n",
      "Epoch 4365/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9817 - val_loss: 0.6713 - val_acc: 0.7292\n",
      "Epoch 4366/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6731 - val_acc: 0.7303\n",
      "Epoch 4367/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9817 - val_loss: 0.6727 - val_acc: 0.7325\n",
      "Epoch 4368/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6726 - val_acc: 0.7262\n",
      "Epoch 4369/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6718 - val_acc: 0.7299\n",
      "Epoch 4370/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6730 - val_acc: 0.7281\n",
      "Epoch 4371/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6736 - val_acc: 0.7292\n",
      "Epoch 4372/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9822 - val_loss: 0.6731 - val_acc: 0.7292\n",
      "Epoch 4373/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9811 - val_loss: 0.6705 - val_acc: 0.7303\n",
      "Epoch 4374/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9815 - val_loss: 0.6736 - val_acc: 0.7321\n",
      "Epoch 4375/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6703 - val_acc: 0.7299\n",
      "Epoch 4376/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6718 - val_acc: 0.7325\n",
      "Epoch 4377/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9806 - val_loss: 0.6739 - val_acc: 0.7310\n",
      "Epoch 4378/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6708 - val_acc: 0.7332\n",
      "Epoch 4379/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9817 - val_loss: 0.6742 - val_acc: 0.7295\n",
      "Epoch 4380/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6703 - val_acc: 0.7288\n",
      "Epoch 4381/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6709 - val_acc: 0.7314\n",
      "Epoch 4382/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6702 - val_acc: 0.7295\n",
      "Epoch 4383/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9831 - val_loss: 0.6703 - val_acc: 0.7299\n",
      "Epoch 4384/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6711 - val_acc: 0.7310\n",
      "Epoch 4385/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6694 - val_acc: 0.7361\n",
      "Epoch 4386/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6688 - val_acc: 0.7332\n",
      "Epoch 4387/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3085 - acc: 0.9737 - val_loss: 0.6845 - val_acc: 0.7270\n",
      "Epoch 4388/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3099 - acc: 0.9672 - val_loss: 0.6912 - val_acc: 0.7262\n",
      "Epoch 4389/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3147 - acc: 0.9634 - val_loss: 0.6920 - val_acc: 0.7186\n",
      "Epoch 4390/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3113 - acc: 0.9649 - val_loss: 0.6892 - val_acc: 0.7233\n",
      "Epoch 4391/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3107 - acc: 0.9683 - val_loss: 0.6924 - val_acc: 0.7332\n",
      "Epoch 4392/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3087 - acc: 0.9710 - val_loss: 0.6879 - val_acc: 0.7317\n",
      "Epoch 4393/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3081 - acc: 0.9740 - val_loss: 0.6877 - val_acc: 0.7273\n",
      "Epoch 4394/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3077 - acc: 0.9748 - val_loss: 0.6872 - val_acc: 0.7288\n",
      "Epoch 4395/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3072 - acc: 0.9757 - val_loss: 0.6880 - val_acc: 0.7310\n",
      "Epoch 4396/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3071 - acc: 0.9776 - val_loss: 0.6886 - val_acc: 0.7310\n",
      "Epoch 4397/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3070 - acc: 0.9783 - val_loss: 0.6881 - val_acc: 0.7273\n",
      "Epoch 4398/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3069 - acc: 0.9797 - val_loss: 0.6877 - val_acc: 0.7273\n",
      "Epoch 4399/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3068 - acc: 0.9798 - val_loss: 0.6873 - val_acc: 0.7288\n",
      "Epoch 4400/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3067 - acc: 0.9807 - val_loss: 0.6866 - val_acc: 0.7270\n",
      "Epoch 4401/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3067 - acc: 0.9805 - val_loss: 0.6869 - val_acc: 0.7273\n",
      "Epoch 4402/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3066 - acc: 0.9807 - val_loss: 0.6866 - val_acc: 0.7281\n",
      "Epoch 4403/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3066 - acc: 0.9822 - val_loss: 0.6859 - val_acc: 0.7292\n",
      "Epoch 4404/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3066 - acc: 0.9828 - val_loss: 0.6866 - val_acc: 0.7299\n",
      "Epoch 4405/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3065 - acc: 0.9816 - val_loss: 0.6864 - val_acc: 0.7299\n",
      "Epoch 4406/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3065 - acc: 0.9832 - val_loss: 0.6854 - val_acc: 0.7281\n",
      "Epoch 4407/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3065 - acc: 0.9835 - val_loss: 0.6855 - val_acc: 0.7295\n",
      "Epoch 4408/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3067 - acc: 0.9827 - val_loss: 0.6861 - val_acc: 0.7277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4409/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3074 - acc: 0.9786 - val_loss: 0.6816 - val_acc: 0.7259\n",
      "Epoch 4410/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3069 - acc: 0.9782 - val_loss: 0.6813 - val_acc: 0.7295\n",
      "Epoch 4411/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3064 - acc: 0.9811 - val_loss: 0.6791 - val_acc: 0.7303\n",
      "Epoch 4412/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9823 - val_loss: 0.6800 - val_acc: 0.7306\n",
      "Epoch 4413/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9834 - val_loss: 0.6800 - val_acc: 0.7284\n",
      "Epoch 4414/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9831 - val_loss: 0.6796 - val_acc: 0.7303\n",
      "Epoch 4415/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9843 - val_loss: 0.6797 - val_acc: 0.7299\n",
      "Epoch 4416/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6792 - val_acc: 0.7288\n",
      "Epoch 4417/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9842 - val_loss: 0.6791 - val_acc: 0.7273\n",
      "Epoch 4418/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9839 - val_loss: 0.6792 - val_acc: 0.7284\n",
      "Epoch 4419/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6786 - val_acc: 0.7270\n",
      "Epoch 4420/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9847 - val_loss: 0.6786 - val_acc: 0.7299\n",
      "Epoch 4421/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9848 - val_loss: 0.6781 - val_acc: 0.7277\n",
      "Epoch 4422/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6783 - val_acc: 0.7266\n",
      "Epoch 4423/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6779 - val_acc: 0.7277\n",
      "Epoch 4424/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6781 - val_acc: 0.7284\n",
      "Epoch 4425/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6778 - val_acc: 0.7273\n",
      "Epoch 4426/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6787 - val_acc: 0.7288\n",
      "Epoch 4427/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3059 - acc: 0.9855 - val_loss: 0.6788 - val_acc: 0.7273\n",
      "Epoch 4428/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9857 - val_loss: 0.6779 - val_acc: 0.7310\n",
      "Epoch 4429/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6779 - val_acc: 0.7292\n",
      "Epoch 4430/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6777 - val_acc: 0.7292\n",
      "Epoch 4431/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6771 - val_acc: 0.7288\n",
      "Epoch 4432/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9849 - val_loss: 0.6771 - val_acc: 0.7295\n",
      "Epoch 4433/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9839 - val_loss: 0.6779 - val_acc: 0.7266\n",
      "Epoch 4434/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6771 - val_acc: 0.7314\n",
      "Epoch 4435/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6775 - val_acc: 0.7266\n",
      "Epoch 4436/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9835 - val_loss: 0.6769 - val_acc: 0.7262\n",
      "Epoch 4437/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9834 - val_loss: 0.6773 - val_acc: 0.7259\n",
      "Epoch 4438/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6762 - val_acc: 0.7314\n",
      "Epoch 4439/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9831 - val_loss: 0.6747 - val_acc: 0.7303\n",
      "Epoch 4440/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3091 - acc: 0.9717 - val_loss: 0.6836 - val_acc: 0.7219\n",
      "Epoch 4441/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3191 - acc: 0.9509 - val_loss: 0.6894 - val_acc: 0.7237\n",
      "Epoch 4442/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3127 - acc: 0.9638 - val_loss: 0.6807 - val_acc: 0.7328\n",
      "Epoch 4443/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3115 - acc: 0.9688 - val_loss: 0.6784 - val_acc: 0.7303\n",
      "Epoch 4444/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3088 - acc: 0.9707 - val_loss: 0.6790 - val_acc: 0.7292\n",
      "Epoch 4445/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3080 - acc: 0.9728 - val_loss: 0.6786 - val_acc: 0.7251\n",
      "Epoch 4446/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3076 - acc: 0.9739 - val_loss: 0.6761 - val_acc: 0.7273\n",
      "Epoch 4447/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3073 - acc: 0.9759 - val_loss: 0.6761 - val_acc: 0.7270\n",
      "Epoch 4448/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3071 - acc: 0.9770 - val_loss: 0.6773 - val_acc: 0.7277\n",
      "Epoch 4449/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3070 - acc: 0.9779 - val_loss: 0.6767 - val_acc: 0.7303\n",
      "Epoch 4450/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3069 - acc: 0.9787 - val_loss: 0.6767 - val_acc: 0.7292\n",
      "Epoch 4451/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3068 - acc: 0.9785 - val_loss: 0.6762 - val_acc: 0.7306\n",
      "Epoch 4452/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3067 - acc: 0.9796 - val_loss: 0.6764 - val_acc: 0.7303\n",
      "Epoch 4453/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3066 - acc: 0.9809 - val_loss: 0.6748 - val_acc: 0.7310\n",
      "Epoch 4454/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3065 - acc: 0.9806 - val_loss: 0.6752 - val_acc: 0.7321\n",
      "Epoch 4455/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3065 - acc: 0.9817 - val_loss: 0.6755 - val_acc: 0.7310\n",
      "Epoch 4456/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3064 - acc: 0.9814 - val_loss: 0.6758 - val_acc: 0.7321\n",
      "Epoch 4457/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3064 - acc: 0.9824 - val_loss: 0.6756 - val_acc: 0.7306\n",
      "Epoch 4458/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3064 - acc: 0.9823 - val_loss: 0.6752 - val_acc: 0.7292\n",
      "Epoch 4459/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3067 - acc: 0.9807 - val_loss: 0.6801 - val_acc: 0.7266\n",
      "Epoch 4460/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3071 - acc: 0.9769 - val_loss: 0.6749 - val_acc: 0.7281\n",
      "Epoch 4461/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6754 - val_acc: 0.7295\n",
      "Epoch 4462/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9824 - val_loss: 0.6725 - val_acc: 0.7266\n",
      "Epoch 4463/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9833 - val_loss: 0.6743 - val_acc: 0.7270\n",
      "Epoch 4464/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6746 - val_acc: 0.7273\n",
      "Epoch 4465/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9836 - val_loss: 0.6751 - val_acc: 0.7266\n",
      "Epoch 4466/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6760 - val_acc: 0.7266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4467/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6756 - val_acc: 0.7266\n",
      "Epoch 4468/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6760 - val_acc: 0.7270\n",
      "Epoch 4469/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6755 - val_acc: 0.7248\n",
      "Epoch 4470/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6759 - val_acc: 0.7259\n",
      "Epoch 4471/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6759 - val_acc: 0.7244\n",
      "Epoch 4472/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6751 - val_acc: 0.7270\n",
      "Epoch 4473/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6750 - val_acc: 0.7262\n",
      "Epoch 4474/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6752 - val_acc: 0.7266\n",
      "Epoch 4475/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6751 - val_acc: 0.7277\n",
      "Epoch 4476/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9855 - val_loss: 0.6751 - val_acc: 0.7273\n",
      "Epoch 4477/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6748 - val_acc: 0.7317\n",
      "Epoch 4478/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6739 - val_acc: 0.7288\n",
      "Epoch 4479/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3059 - acc: 0.9856 - val_loss: 0.6731 - val_acc: 0.7273\n",
      "Epoch 4480/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6745 - val_acc: 0.7266\n",
      "Epoch 4481/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6734 - val_acc: 0.7273\n",
      "Epoch 4482/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6741 - val_acc: 0.7288\n",
      "Epoch 4483/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9853 - val_loss: 0.6717 - val_acc: 0.7292\n",
      "Epoch 4484/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9847 - val_loss: 0.6720 - val_acc: 0.7321\n",
      "Epoch 4485/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6695 - val_acc: 0.7299\n",
      "Epoch 4486/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6728 - val_acc: 0.7295\n",
      "Epoch 4487/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9828 - val_loss: 0.6704 - val_acc: 0.7281\n",
      "Epoch 4488/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6708 - val_acc: 0.7310\n",
      "Epoch 4489/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9820 - val_loss: 0.6706 - val_acc: 0.7314\n",
      "Epoch 4490/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9818 - val_loss: 0.6750 - val_acc: 0.7295\n",
      "Epoch 4491/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6721 - val_acc: 0.7270\n",
      "Epoch 4492/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3068 - acc: 0.9784 - val_loss: 0.6744 - val_acc: 0.7299\n",
      "Epoch 4493/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3160 - acc: 0.9668 - val_loss: 0.6849 - val_acc: 0.7219\n",
      "Epoch 4494/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3173 - acc: 0.9605 - val_loss: 0.6845 - val_acc: 0.7266\n",
      "Epoch 4495/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3122 - acc: 0.9654 - val_loss: 0.6748 - val_acc: 0.7273\n",
      "Epoch 4496/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3097 - acc: 0.9714 - val_loss: 0.6689 - val_acc: 0.7336\n",
      "Epoch 4497/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3096 - acc: 0.9708 - val_loss: 0.6774 - val_acc: 0.7343\n",
      "Epoch 4498/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3085 - acc: 0.9716 - val_loss: 0.6745 - val_acc: 0.7292\n",
      "Epoch 4499/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3079 - acc: 0.9738 - val_loss: 0.6738 - val_acc: 0.7314\n",
      "Epoch 4500/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3075 - acc: 0.9750 - val_loss: 0.6745 - val_acc: 0.7317\n",
      "Epoch 4501/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3074 - acc: 0.9764 - val_loss: 0.6747 - val_acc: 0.7314\n",
      "Epoch 4502/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3072 - acc: 0.9772 - val_loss: 0.6744 - val_acc: 0.7299\n",
      "Epoch 4503/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3070 - acc: 0.9776 - val_loss: 0.6741 - val_acc: 0.7292\n",
      "Epoch 4504/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3069 - acc: 0.9782 - val_loss: 0.6729 - val_acc: 0.7288\n",
      "Epoch 4505/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3069 - acc: 0.9785 - val_loss: 0.6714 - val_acc: 0.7288\n",
      "Epoch 4506/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3068 - acc: 0.9786 - val_loss: 0.6715 - val_acc: 0.7292\n",
      "Epoch 4507/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3067 - acc: 0.9803 - val_loss: 0.6722 - val_acc: 0.7288\n",
      "Epoch 4508/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3064 - acc: 0.9792 - val_loss: 0.6713 - val_acc: 0.7317\n",
      "Epoch 4509/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9804 - val_loss: 0.6714 - val_acc: 0.7303\n",
      "Epoch 4510/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3063 - acc: 0.9808 - val_loss: 0.6719 - val_acc: 0.7284\n",
      "Epoch 4511/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3063 - acc: 0.9813 - val_loss: 0.6708 - val_acc: 0.7303\n",
      "Epoch 4512/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6707 - val_acc: 0.7277\n",
      "Epoch 4513/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9815 - val_loss: 0.6710 - val_acc: 0.7299\n",
      "Epoch 4514/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9817 - val_loss: 0.6705 - val_acc: 0.7299\n",
      "Epoch 4515/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6704 - val_acc: 0.7303\n",
      "Epoch 4516/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9830 - val_loss: 0.6711 - val_acc: 0.7299\n",
      "Epoch 4517/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6709 - val_acc: 0.7295\n",
      "Epoch 4518/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6716 - val_acc: 0.7295\n",
      "Epoch 4519/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6708 - val_acc: 0.7292\n",
      "Epoch 4520/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6714 - val_acc: 0.7288\n",
      "Epoch 4521/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6711 - val_acc: 0.7314\n",
      "Epoch 4522/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6713 - val_acc: 0.7299\n",
      "Epoch 4523/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6716 - val_acc: 0.7310\n",
      "Epoch 4524/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6702 - val_acc: 0.7281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4525/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9830 - val_loss: 0.6713 - val_acc: 0.7270\n",
      "Epoch 4526/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9832 - val_loss: 0.6713 - val_acc: 0.7292\n",
      "Epoch 4527/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6717 - val_acc: 0.7288\n",
      "Epoch 4528/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9837 - val_loss: 0.6710 - val_acc: 0.7288\n",
      "Epoch 4529/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9839 - val_loss: 0.6711 - val_acc: 0.7292\n",
      "Epoch 4530/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9847 - val_loss: 0.6712 - val_acc: 0.7281\n",
      "Epoch 4531/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9835 - val_loss: 0.6707 - val_acc: 0.7295\n",
      "Epoch 4532/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6710 - val_acc: 0.7277\n",
      "Epoch 4533/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9846 - val_loss: 0.6712 - val_acc: 0.7299\n",
      "Epoch 4534/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6703 - val_acc: 0.7284\n",
      "Epoch 4535/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9837 - val_loss: 0.6713 - val_acc: 0.7255\n",
      "Epoch 4536/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6706 - val_acc: 0.7277\n",
      "Epoch 4537/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6709 - val_acc: 0.7259\n",
      "Epoch 4538/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9836 - val_loss: 0.6695 - val_acc: 0.7244\n",
      "Epoch 4539/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9826 - val_loss: 0.6739 - val_acc: 0.7262\n",
      "Epoch 4540/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3078 - acc: 0.9772 - val_loss: 0.6724 - val_acc: 0.7240\n",
      "Epoch 4541/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3162 - acc: 0.9609 - val_loss: 0.6858 - val_acc: 0.7226\n",
      "Epoch 4542/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3149 - acc: 0.9598 - val_loss: 0.6776 - val_acc: 0.7248\n",
      "Epoch 4543/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3108 - acc: 0.9680 - val_loss: 0.6792 - val_acc: 0.7204\n",
      "Epoch 4544/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3098 - acc: 0.9686 - val_loss: 0.6754 - val_acc: 0.7262\n",
      "Epoch 4545/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3084 - acc: 0.9721 - val_loss: 0.6706 - val_acc: 0.7251\n",
      "Epoch 4546/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3078 - acc: 0.9745 - val_loss: 0.6702 - val_acc: 0.7273\n",
      "Epoch 4547/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3074 - acc: 0.9761 - val_loss: 0.6688 - val_acc: 0.7292\n",
      "Epoch 4548/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3071 - acc: 0.9763 - val_loss: 0.6669 - val_acc: 0.7303\n",
      "Epoch 4549/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3068 - acc: 0.9782 - val_loss: 0.6667 - val_acc: 0.7295\n",
      "Epoch 4550/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3067 - acc: 0.9786 - val_loss: 0.6661 - val_acc: 0.7281\n",
      "Epoch 4551/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3066 - acc: 0.9795 - val_loss: 0.6657 - val_acc: 0.7284\n",
      "Epoch 4552/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3065 - acc: 0.9802 - val_loss: 0.6657 - val_acc: 0.7270\n",
      "Epoch 4553/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3064 - acc: 0.9810 - val_loss: 0.6655 - val_acc: 0.7273\n",
      "Epoch 4554/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9811 - val_loss: 0.6653 - val_acc: 0.7288\n",
      "Epoch 4555/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3063 - acc: 0.9815 - val_loss: 0.6653 - val_acc: 0.7292\n",
      "Epoch 4556/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3063 - acc: 0.9817 - val_loss: 0.6652 - val_acc: 0.7262\n",
      "Epoch 4557/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3063 - acc: 0.9818 - val_loss: 0.6651 - val_acc: 0.7277\n",
      "Epoch 4558/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6650 - val_acc: 0.7281\n",
      "Epoch 4559/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3062 - acc: 0.9829 - val_loss: 0.6654 - val_acc: 0.7270\n",
      "Epoch 4560/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3062 - acc: 0.9829 - val_loss: 0.6650 - val_acc: 0.7281\n",
      "Epoch 4561/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3062 - acc: 0.9840 - val_loss: 0.6659 - val_acc: 0.7259\n",
      "Epoch 4562/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6652 - val_acc: 0.7277\n",
      "Epoch 4563/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9836 - val_loss: 0.6652 - val_acc: 0.7270\n",
      "Epoch 4564/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3061 - acc: 0.9837 - val_loss: 0.6654 - val_acc: 0.7277\n",
      "Epoch 4565/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9847 - val_loss: 0.6652 - val_acc: 0.7259\n",
      "Epoch 4566/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9843 - val_loss: 0.6646 - val_acc: 0.7266\n",
      "Epoch 4567/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9848 - val_loss: 0.6650 - val_acc: 0.7266\n",
      "Epoch 4568/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9848 - val_loss: 0.6654 - val_acc: 0.7255\n",
      "Epoch 4569/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9853 - val_loss: 0.6654 - val_acc: 0.7259\n",
      "Epoch 4570/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9843 - val_loss: 0.6659 - val_acc: 0.7248\n",
      "Epoch 4571/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3061 - acc: 0.9850 - val_loss: 0.6655 - val_acc: 0.7251\n",
      "Epoch 4572/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9850 - val_loss: 0.6666 - val_acc: 0.7270\n",
      "Epoch 4573/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9846 - val_loss: 0.6665 - val_acc: 0.7255\n",
      "Epoch 4574/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9852 - val_loss: 0.6662 - val_acc: 0.7244\n",
      "Epoch 4575/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6667 - val_acc: 0.7270\n",
      "Epoch 4576/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6665 - val_acc: 0.7240\n",
      "Epoch 4577/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9848 - val_loss: 0.6666 - val_acc: 0.7255\n",
      "Epoch 4578/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9852 - val_loss: 0.6669 - val_acc: 0.7251\n",
      "Epoch 4579/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3061 - acc: 0.9844 - val_loss: 0.6648 - val_acc: 0.7255\n",
      "Epoch 4580/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6666 - val_acc: 0.7266\n",
      "Epoch 4581/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3061 - acc: 0.9832 - val_loss: 0.6674 - val_acc: 0.7251\n",
      "Epoch 4582/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3061 - acc: 0.9823 - val_loss: 0.6664 - val_acc: 0.7248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4583/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3062 - acc: 0.9822 - val_loss: 0.6659 - val_acc: 0.7273\n",
      "Epoch 4584/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3063 - acc: 0.9818 - val_loss: 0.6659 - val_acc: 0.7266\n",
      "Epoch 4585/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3062 - acc: 0.9809 - val_loss: 0.6654 - val_acc: 0.7255\n",
      "Epoch 4586/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9817 - val_loss: 0.6654 - val_acc: 0.7251\n",
      "Epoch 4587/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9831 - val_loss: 0.6655 - val_acc: 0.7281\n",
      "Epoch 4588/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9833 - val_loss: 0.6658 - val_acc: 0.7255\n",
      "Epoch 4589/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3062 - acc: 0.9816 - val_loss: 0.6650 - val_acc: 0.7255\n",
      "Epoch 4590/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3082 - acc: 0.9748 - val_loss: 0.6561 - val_acc: 0.7346\n",
      "Epoch 4591/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3113 - acc: 0.9661 - val_loss: 0.6765 - val_acc: 0.7230\n",
      "Epoch 4592/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3153 - acc: 0.9650 - val_loss: 0.6739 - val_acc: 0.7262\n",
      "Epoch 4593/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3130 - acc: 0.9659 - val_loss: 0.6743 - val_acc: 0.7219\n",
      "Epoch 4594/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3092 - acc: 0.9719 - val_loss: 0.6706 - val_acc: 0.7248\n",
      "Epoch 4595/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3079 - acc: 0.9721 - val_loss: 0.6685 - val_acc: 0.7215\n",
      "Epoch 4596/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3073 - acc: 0.9745 - val_loss: 0.6688 - val_acc: 0.7244\n",
      "Epoch 4597/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3070 - acc: 0.9761 - val_loss: 0.6683 - val_acc: 0.7244\n",
      "Epoch 4598/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3068 - acc: 0.9772 - val_loss: 0.6680 - val_acc: 0.7244\n",
      "Epoch 4599/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3067 - acc: 0.9768 - val_loss: 0.6679 - val_acc: 0.7262\n",
      "Epoch 4600/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3066 - acc: 0.9794 - val_loss: 0.6681 - val_acc: 0.7262\n",
      "Epoch 4601/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3065 - acc: 0.9792 - val_loss: 0.6678 - val_acc: 0.7248\n",
      "Epoch 4602/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3064 - acc: 0.9798 - val_loss: 0.6682 - val_acc: 0.7244\n",
      "Epoch 4603/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3064 - acc: 0.9804 - val_loss: 0.6683 - val_acc: 0.7230\n",
      "Epoch 4604/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3063 - acc: 0.9809 - val_loss: 0.6678 - val_acc: 0.7244\n",
      "Epoch 4605/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3063 - acc: 0.9805 - val_loss: 0.6684 - val_acc: 0.7251\n",
      "Epoch 4606/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3062 - acc: 0.9815 - val_loss: 0.6680 - val_acc: 0.7240\n",
      "Epoch 4607/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3062 - acc: 0.9819 - val_loss: 0.6681 - val_acc: 0.7259\n",
      "Epoch 4608/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3062 - acc: 0.9822 - val_loss: 0.6685 - val_acc: 0.7270\n",
      "Epoch 4609/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6684 - val_acc: 0.7255\n",
      "Epoch 4610/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6688 - val_acc: 0.7266\n",
      "Epoch 4611/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3061 - acc: 0.9824 - val_loss: 0.6688 - val_acc: 0.7266\n",
      "Epoch 4612/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9832 - val_loss: 0.6687 - val_acc: 0.7270\n",
      "Epoch 4613/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9830 - val_loss: 0.6690 - val_acc: 0.7237\n",
      "Epoch 4614/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6686 - val_acc: 0.7277\n",
      "Epoch 4615/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6697 - val_acc: 0.7255\n",
      "Epoch 4616/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6694 - val_acc: 0.7259\n",
      "Epoch 4617/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9838 - val_loss: 0.6701 - val_acc: 0.7262\n",
      "Epoch 4618/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6687 - val_acc: 0.7270\n",
      "Epoch 4619/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9847 - val_loss: 0.6701 - val_acc: 0.7251\n",
      "Epoch 4620/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6702 - val_acc: 0.7255\n",
      "Epoch 4621/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6702 - val_acc: 0.7255\n",
      "Epoch 4622/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6702 - val_acc: 0.7266\n",
      "Epoch 4623/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9842 - val_loss: 0.6701 - val_acc: 0.7277\n",
      "Epoch 4624/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9842 - val_loss: 0.6699 - val_acc: 0.7255\n",
      "Epoch 4625/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9838 - val_loss: 0.6694 - val_acc: 0.7273\n",
      "Epoch 4626/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9847 - val_loss: 0.6683 - val_acc: 0.7259\n",
      "Epoch 4627/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6685 - val_acc: 0.7273\n",
      "Epoch 4628/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6691 - val_acc: 0.7237\n",
      "Epoch 4629/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9836 - val_loss: 0.6686 - val_acc: 0.7270\n",
      "Epoch 4630/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9819 - val_loss: 0.6685 - val_acc: 0.7226\n",
      "Epoch 4631/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6689 - val_acc: 0.7259\n",
      "Epoch 4632/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3061 - acc: 0.9823 - val_loss: 0.6695 - val_acc: 0.7240\n",
      "Epoch 4633/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6666 - val_acc: 0.7266\n",
      "Epoch 4634/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6669 - val_acc: 0.7262\n",
      "Epoch 4635/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9804 - val_loss: 0.6640 - val_acc: 0.7240\n",
      "Epoch 4636/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6671 - val_acc: 0.7281\n",
      "Epoch 4637/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9816 - val_loss: 0.6671 - val_acc: 0.7277\n",
      "Epoch 4638/10000\n",
      "4259/4259 [==============================] - 2s 482us/step - loss: 0.3060 - acc: 0.9815 - val_loss: 0.6651 - val_acc: 0.7251\n",
      "Epoch 4639/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3061 - acc: 0.9824 - val_loss: 0.6639 - val_acc: 0.7295\n",
      "Epoch 4640/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3062 - acc: 0.9802 - val_loss: 0.6649 - val_acc: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4641/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3062 - acc: 0.9809 - val_loss: 0.6657 - val_acc: 0.7248\n",
      "Epoch 4642/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3062 - acc: 0.9818 - val_loss: 0.6690 - val_acc: 0.7251\n",
      "Epoch 4643/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9815 - val_loss: 0.6662 - val_acc: 0.7240\n",
      "Epoch 4644/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3063 - acc: 0.9797 - val_loss: 0.6614 - val_acc: 0.7259\n",
      "Epoch 4645/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3066 - acc: 0.9797 - val_loss: 0.6638 - val_acc: 0.7306\n",
      "Epoch 4646/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3112 - acc: 0.9654 - val_loss: 0.6751 - val_acc: 0.7270\n",
      "Epoch 4647/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3084 - acc: 0.9730 - val_loss: 0.6700 - val_acc: 0.7255\n",
      "Epoch 4648/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3083 - acc: 0.9766 - val_loss: 0.6668 - val_acc: 0.7215\n",
      "Epoch 4649/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3077 - acc: 0.9773 - val_loss: 0.6679 - val_acc: 0.7244\n",
      "Epoch 4650/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3090 - acc: 0.9761 - val_loss: 0.6690 - val_acc: 0.7233\n",
      "Epoch 4651/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3142 - acc: 0.9653 - val_loss: 0.6702 - val_acc: 0.7314\n",
      "Epoch 4652/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3116 - acc: 0.9665 - val_loss: 0.6749 - val_acc: 0.7299\n",
      "Epoch 4653/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3093 - acc: 0.9706 - val_loss: 0.6779 - val_acc: 0.7295\n",
      "Epoch 4654/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3080 - acc: 0.9735 - val_loss: 0.6753 - val_acc: 0.7292\n",
      "Epoch 4655/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3074 - acc: 0.9753 - val_loss: 0.6745 - val_acc: 0.7306\n",
      "Epoch 4656/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3071 - acc: 0.9762 - val_loss: 0.6746 - val_acc: 0.7317\n",
      "Epoch 4657/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3070 - acc: 0.9771 - val_loss: 0.6735 - val_acc: 0.7328\n",
      "Epoch 4658/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3068 - acc: 0.9779 - val_loss: 0.6737 - val_acc: 0.7325\n",
      "Epoch 4659/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3067 - acc: 0.9781 - val_loss: 0.6733 - val_acc: 0.7336\n",
      "Epoch 4660/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3066 - acc: 0.9789 - val_loss: 0.6731 - val_acc: 0.7339\n",
      "Epoch 4661/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3065 - acc: 0.9793 - val_loss: 0.6724 - val_acc: 0.7328\n",
      "Epoch 4662/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3065 - acc: 0.9802 - val_loss: 0.6721 - val_acc: 0.7295\n",
      "Epoch 4663/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3064 - acc: 0.9811 - val_loss: 0.6720 - val_acc: 0.7339\n",
      "Epoch 4664/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3064 - acc: 0.9810 - val_loss: 0.6715 - val_acc: 0.7321\n",
      "Epoch 4665/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3063 - acc: 0.9818 - val_loss: 0.6715 - val_acc: 0.7328\n",
      "Epoch 4666/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3063 - acc: 0.9822 - val_loss: 0.6707 - val_acc: 0.7303\n",
      "Epoch 4667/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6708 - val_acc: 0.7317\n",
      "Epoch 4668/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3062 - acc: 0.9829 - val_loss: 0.6708 - val_acc: 0.7310\n",
      "Epoch 4669/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3062 - acc: 0.9823 - val_loss: 0.6707 - val_acc: 0.7317\n",
      "Epoch 4670/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6705 - val_acc: 0.7314\n",
      "Epoch 4671/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6703 - val_acc: 0.7299\n",
      "Epoch 4672/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6698 - val_acc: 0.7325\n",
      "Epoch 4673/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6700 - val_acc: 0.7303\n",
      "Epoch 4674/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9842 - val_loss: 0.6699 - val_acc: 0.7306\n",
      "Epoch 4675/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3071 - acc: 0.9795 - val_loss: 0.6669 - val_acc: 0.7321\n",
      "Epoch 4676/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3074 - acc: 0.9776 - val_loss: 0.6680 - val_acc: 0.7295\n",
      "Epoch 4677/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3070 - acc: 0.9787 - val_loss: 0.6653 - val_acc: 0.7354\n",
      "Epoch 4678/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3064 - acc: 0.9808 - val_loss: 0.6657 - val_acc: 0.7354\n",
      "Epoch 4679/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3062 - acc: 0.9822 - val_loss: 0.6659 - val_acc: 0.7357\n",
      "Epoch 4680/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3062 - acc: 0.9830 - val_loss: 0.6650 - val_acc: 0.7339\n",
      "Epoch 4681/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6656 - val_acc: 0.7350\n",
      "Epoch 4682/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9841 - val_loss: 0.6651 - val_acc: 0.7350\n",
      "Epoch 4683/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3061 - acc: 0.9841 - val_loss: 0.6651 - val_acc: 0.7350\n",
      "Epoch 4684/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9847 - val_loss: 0.6653 - val_acc: 0.7343\n",
      "Epoch 4685/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3060 - acc: 0.9848 - val_loss: 0.6651 - val_acc: 0.7357\n",
      "Epoch 4686/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3060 - acc: 0.9855 - val_loss: 0.6653 - val_acc: 0.7361\n",
      "Epoch 4687/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3060 - acc: 0.9851 - val_loss: 0.6650 - val_acc: 0.7357\n",
      "Epoch 4688/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9850 - val_loss: 0.6662 - val_acc: 0.7357\n",
      "Epoch 4689/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9854 - val_loss: 0.6652 - val_acc: 0.7365\n",
      "Epoch 4690/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3060 - acc: 0.9852 - val_loss: 0.6656 - val_acc: 0.7376\n",
      "Epoch 4691/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9853 - val_loss: 0.6657 - val_acc: 0.7357\n",
      "Epoch 4692/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9860 - val_loss: 0.6663 - val_acc: 0.7354\n",
      "Epoch 4693/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3060 - acc: 0.9853 - val_loss: 0.6658 - val_acc: 0.7346\n",
      "Epoch 4694/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3060 - acc: 0.9855 - val_loss: 0.6657 - val_acc: 0.7332\n",
      "Epoch 4695/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9857 - val_loss: 0.6655 - val_acc: 0.7350\n",
      "Epoch 4696/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9859 - val_loss: 0.6662 - val_acc: 0.7346\n",
      "Epoch 4697/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3060 - acc: 0.9858 - val_loss: 0.6657 - val_acc: 0.7343\n",
      "Epoch 4698/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3060 - acc: 0.9853 - val_loss: 0.6656 - val_acc: 0.7368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4699/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3061 - acc: 0.9846 - val_loss: 0.6667 - val_acc: 0.7325\n",
      "Epoch 4700/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9832 - val_loss: 0.6654 - val_acc: 0.7336\n",
      "Epoch 4701/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6662 - val_acc: 0.7321\n",
      "Epoch 4702/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6664 - val_acc: 0.7346\n",
      "Epoch 4703/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9843 - val_loss: 0.6669 - val_acc: 0.7350\n",
      "Epoch 4704/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6664 - val_acc: 0.7350\n",
      "Epoch 4705/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6669 - val_acc: 0.7317\n",
      "Epoch 4706/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9834 - val_loss: 0.6671 - val_acc: 0.7314\n",
      "Epoch 4707/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3064 - acc: 0.9811 - val_loss: 0.6648 - val_acc: 0.7292\n",
      "Epoch 4708/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3064 - acc: 0.9815 - val_loss: 0.6650 - val_acc: 0.7299\n",
      "Epoch 4709/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3064 - acc: 0.9796 - val_loss: 0.6606 - val_acc: 0.7376\n",
      "Epoch 4710/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3071 - acc: 0.9811 - val_loss: 0.6639 - val_acc: 0.7314\n",
      "Epoch 4711/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3078 - acc: 0.9744 - val_loss: 0.6569 - val_acc: 0.7299\n",
      "Epoch 4712/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3078 - acc: 0.9747 - val_loss: 0.6752 - val_acc: 0.7222\n",
      "Epoch 4713/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3088 - acc: 0.9722 - val_loss: 0.6594 - val_acc: 0.7277\n",
      "Epoch 4714/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3075 - acc: 0.9765 - val_loss: 0.6606 - val_acc: 0.7266\n",
      "Epoch 4715/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3066 - acc: 0.9780 - val_loss: 0.6584 - val_acc: 0.7295\n",
      "Epoch 4716/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3063 - acc: 0.9811 - val_loss: 0.6596 - val_acc: 0.7303\n",
      "Epoch 4717/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3062 - acc: 0.9815 - val_loss: 0.6580 - val_acc: 0.7288\n",
      "Epoch 4718/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9828 - val_loss: 0.6580 - val_acc: 0.7303\n",
      "Epoch 4719/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6580 - val_acc: 0.7310\n",
      "Epoch 4720/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3061 - acc: 0.9848 - val_loss: 0.6581 - val_acc: 0.7314\n",
      "Epoch 4721/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9847 - val_loss: 0.6576 - val_acc: 0.7332\n",
      "Epoch 4722/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9847 - val_loss: 0.6580 - val_acc: 0.7321\n",
      "Epoch 4723/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3061 - acc: 0.9855 - val_loss: 0.6575 - val_acc: 0.7339\n",
      "Epoch 4724/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9854 - val_loss: 0.6569 - val_acc: 0.7325\n",
      "Epoch 4725/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9847 - val_loss: 0.6570 - val_acc: 0.7328\n",
      "Epoch 4726/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9854 - val_loss: 0.6570 - val_acc: 0.7339\n",
      "Epoch 4727/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3063 - acc: 0.9822 - val_loss: 0.6592 - val_acc: 0.7332\n",
      "Epoch 4728/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6571 - val_acc: 0.7314\n",
      "Epoch 4729/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6585 - val_acc: 0.7281\n",
      "Epoch 4730/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9839 - val_loss: 0.6589 - val_acc: 0.7321\n",
      "Epoch 4731/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6572 - val_acc: 0.7328\n",
      "Epoch 4732/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6575 - val_acc: 0.7303\n",
      "Epoch 4733/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6578 - val_acc: 0.7314\n",
      "Epoch 4734/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6576 - val_acc: 0.7328\n",
      "Epoch 4735/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9846 - val_loss: 0.6576 - val_acc: 0.7310\n",
      "Epoch 4736/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6566 - val_acc: 0.7317\n",
      "Epoch 4737/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6584 - val_acc: 0.7339\n",
      "Epoch 4738/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3061 - acc: 0.9826 - val_loss: 0.6569 - val_acc: 0.7303\n",
      "Epoch 4739/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6563 - val_acc: 0.7321\n",
      "Epoch 4740/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3062 - acc: 0.9823 - val_loss: 0.6551 - val_acc: 0.7346\n",
      "Epoch 4741/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6577 - val_acc: 0.7281\n",
      "Epoch 4742/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3063 - acc: 0.9820 - val_loss: 0.6568 - val_acc: 0.7328\n",
      "Epoch 4743/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3063 - acc: 0.9811 - val_loss: 0.6578 - val_acc: 0.7343\n",
      "Epoch 4744/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3062 - acc: 0.9816 - val_loss: 0.6562 - val_acc: 0.7328\n",
      "Epoch 4745/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3062 - acc: 0.9827 - val_loss: 0.6553 - val_acc: 0.7303\n",
      "Epoch 4746/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6550 - val_acc: 0.7310\n",
      "Epoch 4747/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6541 - val_acc: 0.7317\n",
      "Epoch 4748/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9823 - val_loss: 0.6551 - val_acc: 0.7317\n",
      "Epoch 4749/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6534 - val_acc: 0.7346\n",
      "Epoch 4750/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6551 - val_acc: 0.7339\n",
      "Epoch 4751/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6565 - val_acc: 0.7295\n",
      "Epoch 4752/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3062 - acc: 0.9814 - val_loss: 0.6559 - val_acc: 0.7350\n",
      "Epoch 4753/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6539 - val_acc: 0.7332\n",
      "Epoch 4754/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3063 - acc: 0.9819 - val_loss: 0.6550 - val_acc: 0.7295\n",
      "Epoch 4755/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3062 - acc: 0.9806 - val_loss: 0.6532 - val_acc: 0.7321\n",
      "Epoch 4756/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6529 - val_acc: 0.7325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4757/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3062 - acc: 0.9817 - val_loss: 0.6641 - val_acc: 0.7339\n",
      "Epoch 4758/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3070 - acc: 0.9786 - val_loss: 0.6722 - val_acc: 0.7273\n",
      "Epoch 4759/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3081 - acc: 0.9748 - val_loss: 0.6655 - val_acc: 0.7299\n",
      "Epoch 4760/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3076 - acc: 0.9750 - val_loss: 0.6668 - val_acc: 0.7303\n",
      "Epoch 4761/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3068 - acc: 0.9764 - val_loss: 0.6613 - val_acc: 0.7339\n",
      "Epoch 4762/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3081 - acc: 0.9733 - val_loss: 0.6666 - val_acc: 0.7251\n",
      "Epoch 4763/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3071 - acc: 0.9772 - val_loss: 0.6635 - val_acc: 0.7259\n",
      "Epoch 4764/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3063 - acc: 0.9801 - val_loss: 0.6635 - val_acc: 0.7273\n",
      "Epoch 4765/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3063 - acc: 0.9814 - val_loss: 0.6656 - val_acc: 0.7259\n",
      "Epoch 4766/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6648 - val_acc: 0.7255\n",
      "Epoch 4767/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9836 - val_loss: 0.6639 - val_acc: 0.7270\n",
      "Epoch 4768/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6638 - val_acc: 0.7277\n",
      "Epoch 4769/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6633 - val_acc: 0.7262\n",
      "Epoch 4770/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6632 - val_acc: 0.7248\n",
      "Epoch 4771/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3060 - acc: 0.9839 - val_loss: 0.6626 - val_acc: 0.7292\n",
      "Epoch 4772/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6626 - val_acc: 0.7255\n",
      "Epoch 4773/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6628 - val_acc: 0.7273\n",
      "Epoch 4774/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6622 - val_acc: 0.7270\n",
      "Epoch 4775/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6620 - val_acc: 0.7270\n",
      "Epoch 4776/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6620 - val_acc: 0.7284\n",
      "Epoch 4777/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6621 - val_acc: 0.7273\n",
      "Epoch 4778/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6621 - val_acc: 0.7284\n",
      "Epoch 4779/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6618 - val_acc: 0.7288\n",
      "Epoch 4780/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6624 - val_acc: 0.7288\n",
      "Epoch 4781/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6612 - val_acc: 0.7299\n",
      "Epoch 4782/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6614 - val_acc: 0.7292\n",
      "Epoch 4783/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6614 - val_acc: 0.7262\n",
      "Epoch 4784/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6616 - val_acc: 0.7248\n",
      "Epoch 4785/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3062 - acc: 0.9812 - val_loss: 0.6611 - val_acc: 0.7288\n",
      "Epoch 4786/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3062 - acc: 0.9803 - val_loss: 0.6619 - val_acc: 0.7281\n",
      "Epoch 4787/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3068 - acc: 0.9789 - val_loss: 0.6587 - val_acc: 0.7292\n",
      "Epoch 4788/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3073 - acc: 0.9741 - val_loss: 0.6638 - val_acc: 0.7277\n",
      "Epoch 4789/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3083 - acc: 0.9735 - val_loss: 0.6762 - val_acc: 0.7266\n",
      "Epoch 4790/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3098 - acc: 0.9692 - val_loss: 0.6716 - val_acc: 0.7288\n",
      "Epoch 4791/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3088 - acc: 0.9741 - val_loss: 0.6666 - val_acc: 0.7281\n",
      "Epoch 4792/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3074 - acc: 0.9782 - val_loss: 0.6653 - val_acc: 0.7350\n",
      "Epoch 4793/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3069 - acc: 0.9804 - val_loss: 0.6628 - val_acc: 0.7350\n",
      "Epoch 4794/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3066 - acc: 0.9822 - val_loss: 0.6635 - val_acc: 0.7346\n",
      "Epoch 4795/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3065 - acc: 0.9836 - val_loss: 0.6632 - val_acc: 0.7328\n",
      "Epoch 4796/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3064 - acc: 0.9840 - val_loss: 0.6626 - val_acc: 0.7361\n",
      "Epoch 4797/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3064 - acc: 0.9840 - val_loss: 0.6630 - val_acc: 0.7332\n",
      "Epoch 4798/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3064 - acc: 0.9851 - val_loss: 0.6629 - val_acc: 0.7343\n",
      "Epoch 4799/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3063 - acc: 0.9849 - val_loss: 0.6630 - val_acc: 0.7339\n",
      "Epoch 4800/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3065 - acc: 0.9829 - val_loss: 0.6642 - val_acc: 0.7346\n",
      "Epoch 4801/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9848 - val_loss: 0.6640 - val_acc: 0.7354\n",
      "Epoch 4802/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3059 - acc: 0.9860 - val_loss: 0.6643 - val_acc: 0.7357\n",
      "Epoch 4803/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3058 - acc: 0.9857 - val_loss: 0.6643 - val_acc: 0.7343\n",
      "Epoch 4804/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3058 - acc: 0.9862 - val_loss: 0.6644 - val_acc: 0.7350\n",
      "Epoch 4805/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3058 - acc: 0.9860 - val_loss: 0.6646 - val_acc: 0.7361\n",
      "Epoch 4806/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3058 - acc: 0.9856 - val_loss: 0.6643 - val_acc: 0.7339\n",
      "Epoch 4807/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3058 - acc: 0.9863 - val_loss: 0.6646 - val_acc: 0.7339\n",
      "Epoch 4808/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6645 - val_acc: 0.7343\n",
      "Epoch 4809/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3058 - acc: 0.9857 - val_loss: 0.6648 - val_acc: 0.7365\n",
      "Epoch 4810/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3058 - acc: 0.9856 - val_loss: 0.6647 - val_acc: 0.7354\n",
      "Epoch 4811/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3058 - acc: 0.9862 - val_loss: 0.6645 - val_acc: 0.7339\n",
      "Epoch 4812/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3058 - acc: 0.9865 - val_loss: 0.6648 - val_acc: 0.7361\n",
      "Epoch 4813/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3058 - acc: 0.9855 - val_loss: 0.6648 - val_acc: 0.7321\n",
      "Epoch 4814/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3058 - acc: 0.9856 - val_loss: 0.6642 - val_acc: 0.7354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4815/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6645 - val_acc: 0.7336\n",
      "Epoch 4816/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6644 - val_acc: 0.7325\n",
      "Epoch 4817/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6647 - val_acc: 0.7314\n",
      "Epoch 4818/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6647 - val_acc: 0.7321\n",
      "Epoch 4819/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9828 - val_loss: 0.6645 - val_acc: 0.7317\n",
      "Epoch 4820/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6645 - val_acc: 0.7325\n",
      "Epoch 4821/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9823 - val_loss: 0.6630 - val_acc: 0.7317\n",
      "Epoch 4822/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6655 - val_acc: 0.7336\n",
      "Epoch 4823/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6635 - val_acc: 0.7325\n",
      "Epoch 4824/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6640 - val_acc: 0.7332\n",
      "Epoch 4825/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9835 - val_loss: 0.6633 - val_acc: 0.7357\n",
      "Epoch 4826/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6628 - val_acc: 0.7339\n",
      "Epoch 4827/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6640 - val_acc: 0.7368\n",
      "Epoch 4828/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6647 - val_acc: 0.7339\n",
      "Epoch 4829/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3060 - acc: 0.9815 - val_loss: 0.6625 - val_acc: 0.7328\n",
      "Epoch 4830/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9814 - val_loss: 0.6644 - val_acc: 0.7317\n",
      "Epoch 4831/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9813 - val_loss: 0.6646 - val_acc: 0.7310\n",
      "Epoch 4832/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6631 - val_acc: 0.7266\n",
      "Epoch 4833/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6648 - val_acc: 0.7328\n",
      "Epoch 4834/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9804 - val_loss: 0.6631 - val_acc: 0.7317\n",
      "Epoch 4835/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9810 - val_loss: 0.6636 - val_acc: 0.7321\n",
      "Epoch 4836/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9802 - val_loss: 0.6626 - val_acc: 0.7317\n",
      "Epoch 4837/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9803 - val_loss: 0.6629 - val_acc: 0.7321\n",
      "Epoch 4838/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9815 - val_loss: 0.6618 - val_acc: 0.7339\n",
      "Epoch 4839/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9838 - val_loss: 0.6619 - val_acc: 0.7339\n",
      "Epoch 4840/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9822 - val_loss: 0.6617 - val_acc: 0.7325\n",
      "Epoch 4841/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6639 - val_acc: 0.7339\n",
      "Epoch 4842/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6614 - val_acc: 0.7303\n",
      "Epoch 4843/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6635 - val_acc: 0.7321\n",
      "Epoch 4844/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9803 - val_loss: 0.6625 - val_acc: 0.7350\n",
      "Epoch 4845/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9817 - val_loss: 0.6623 - val_acc: 0.7288\n",
      "Epoch 4846/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9812 - val_loss: 0.6612 - val_acc: 0.7317\n",
      "Epoch 4847/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9822 - val_loss: 0.6625 - val_acc: 0.7314\n",
      "Epoch 4848/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6623 - val_acc: 0.7303\n",
      "Epoch 4849/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6627 - val_acc: 0.7277\n",
      "Epoch 4850/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6629 - val_acc: 0.7295\n",
      "Epoch 4851/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6614 - val_acc: 0.7332\n",
      "Epoch 4852/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9814 - val_loss: 0.6599 - val_acc: 0.7321\n",
      "Epoch 4853/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6627 - val_acc: 0.7292\n",
      "Epoch 4854/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9807 - val_loss: 0.6622 - val_acc: 0.7306\n",
      "Epoch 4855/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9811 - val_loss: 0.6618 - val_acc: 0.7273\n",
      "Epoch 4856/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6616 - val_acc: 0.7310\n",
      "Epoch 4857/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6593 - val_acc: 0.7314\n",
      "Epoch 4858/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6611 - val_acc: 0.7306\n",
      "Epoch 4859/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9817 - val_loss: 0.6633 - val_acc: 0.7303\n",
      "Epoch 4860/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9811 - val_loss: 0.6606 - val_acc: 0.7317\n",
      "Epoch 4861/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9800 - val_loss: 0.6636 - val_acc: 0.7314\n",
      "Epoch 4862/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9774 - val_loss: 0.6623 - val_acc: 0.7288\n",
      "Epoch 4863/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3065 - acc: 0.9797 - val_loss: 0.6630 - val_acc: 0.7343\n",
      "Epoch 4864/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3067 - acc: 0.9786 - val_loss: 0.6691 - val_acc: 0.7368\n",
      "Epoch 4865/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3064 - acc: 0.9805 - val_loss: 0.6636 - val_acc: 0.7321\n",
      "Epoch 4866/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9818 - val_loss: 0.6653 - val_acc: 0.7325\n",
      "Epoch 4867/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3067 - acc: 0.9797 - val_loss: 0.6636 - val_acc: 0.7273\n",
      "Epoch 4868/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3075 - acc: 0.9767 - val_loss: 0.6649 - val_acc: 0.7310\n",
      "Epoch 4869/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3068 - acc: 0.9797 - val_loss: 0.6673 - val_acc: 0.7321\n",
      "Epoch 4870/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3065 - acc: 0.9835 - val_loss: 0.6664 - val_acc: 0.7314\n",
      "Epoch 4871/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3064 - acc: 0.9843 - val_loss: 0.6660 - val_acc: 0.7314\n",
      "Epoch 4872/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3063 - acc: 0.9848 - val_loss: 0.6657 - val_acc: 0.7339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4873/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9849 - val_loss: 0.6658 - val_acc: 0.7328\n",
      "Epoch 4874/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9854 - val_loss: 0.6659 - val_acc: 0.7303\n",
      "Epoch 4875/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9858 - val_loss: 0.6656 - val_acc: 0.7325\n",
      "Epoch 4876/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3063 - acc: 0.9859 - val_loss: 0.6657 - val_acc: 0.7317\n",
      "Epoch 4877/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3063 - acc: 0.9865 - val_loss: 0.6658 - val_acc: 0.7310\n",
      "Epoch 4878/10000\n",
      "4259/4259 [==============================] - 2s 481us/step - loss: 0.3063 - acc: 0.9858 - val_loss: 0.6656 - val_acc: 0.7284\n",
      "Epoch 4879/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9861 - val_loss: 0.6657 - val_acc: 0.7303\n",
      "Epoch 4880/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3063 - acc: 0.9864 - val_loss: 0.6660 - val_acc: 0.7292\n",
      "Epoch 4881/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9858 - val_loss: 0.6655 - val_acc: 0.7299\n",
      "Epoch 4882/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3063 - acc: 0.9850 - val_loss: 0.6651 - val_acc: 0.7288\n",
      "Epoch 4883/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3064 - acc: 0.9845 - val_loss: 0.6647 - val_acc: 0.7325\n",
      "Epoch 4884/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3064 - acc: 0.9822 - val_loss: 0.6645 - val_acc: 0.7314\n",
      "Epoch 4885/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3065 - acc: 0.9822 - val_loss: 0.6659 - val_acc: 0.7306\n",
      "Epoch 4886/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3066 - acc: 0.9814 - val_loss: 0.6663 - val_acc: 0.7266\n",
      "Epoch 4887/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3066 - acc: 0.9807 - val_loss: 0.6669 - val_acc: 0.7317\n",
      "Epoch 4888/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3068 - acc: 0.9803 - val_loss: 0.6662 - val_acc: 0.7321\n",
      "Epoch 4889/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3067 - acc: 0.9808 - val_loss: 0.6647 - val_acc: 0.7336\n",
      "Epoch 4890/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3066 - acc: 0.9811 - val_loss: 0.6648 - val_acc: 0.7314\n",
      "Epoch 4891/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3075 - acc: 0.9775 - val_loss: 0.6772 - val_acc: 0.7310\n",
      "Epoch 4892/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3098 - acc: 0.9695 - val_loss: 0.6703 - val_acc: 0.7270\n",
      "Epoch 4893/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3089 - acc: 0.9710 - val_loss: 0.6753 - val_acc: 0.7292\n",
      "Epoch 4894/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3076 - acc: 0.9770 - val_loss: 0.6692 - val_acc: 0.7266\n",
      "Epoch 4895/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3069 - acc: 0.9789 - val_loss: 0.6703 - val_acc: 0.7281\n",
      "Epoch 4896/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3067 - acc: 0.9817 - val_loss: 0.6696 - val_acc: 0.7281\n",
      "Epoch 4897/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3065 - acc: 0.9822 - val_loss: 0.6692 - val_acc: 0.7273\n",
      "Epoch 4898/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9830 - val_loss: 0.6685 - val_acc: 0.7277\n",
      "Epoch 4899/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9829 - val_loss: 0.6676 - val_acc: 0.7292\n",
      "Epoch 4900/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9836 - val_loss: 0.6672 - val_acc: 0.7277\n",
      "Epoch 4901/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9845 - val_loss: 0.6668 - val_acc: 0.7284\n",
      "Epoch 4902/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9843 - val_loss: 0.6668 - val_acc: 0.7270\n",
      "Epoch 4903/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3063 - acc: 0.9851 - val_loss: 0.6664 - val_acc: 0.7284\n",
      "Epoch 4904/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9844 - val_loss: 0.6665 - val_acc: 0.7288\n",
      "Epoch 4905/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9851 - val_loss: 0.6662 - val_acc: 0.7284\n",
      "Epoch 4906/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9852 - val_loss: 0.6658 - val_acc: 0.7281\n",
      "Epoch 4907/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3063 - acc: 0.9852 - val_loss: 0.6657 - val_acc: 0.7273\n",
      "Epoch 4908/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3063 - acc: 0.9855 - val_loss: 0.6658 - val_acc: 0.7273\n",
      "Epoch 4909/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3063 - acc: 0.9857 - val_loss: 0.6656 - val_acc: 0.7288\n",
      "Epoch 4910/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9859 - val_loss: 0.6651 - val_acc: 0.7270\n",
      "Epoch 4911/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9858 - val_loss: 0.6655 - val_acc: 0.7310\n",
      "Epoch 4912/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9861 - val_loss: 0.6647 - val_acc: 0.7262\n",
      "Epoch 4913/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9858 - val_loss: 0.6653 - val_acc: 0.7288\n",
      "Epoch 4914/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9859 - val_loss: 0.6643 - val_acc: 0.7292\n",
      "Epoch 4915/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9854 - val_loss: 0.6652 - val_acc: 0.7306\n",
      "Epoch 4916/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9850 - val_loss: 0.6648 - val_acc: 0.7299\n",
      "Epoch 4917/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9852 - val_loss: 0.6646 - val_acc: 0.7292\n",
      "Epoch 4918/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3064 - acc: 0.9836 - val_loss: 0.6639 - val_acc: 0.7299\n",
      "Epoch 4919/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3065 - acc: 0.9830 - val_loss: 0.6668 - val_acc: 0.7284\n",
      "Epoch 4920/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3065 - acc: 0.9816 - val_loss: 0.6648 - val_acc: 0.7284\n",
      "Epoch 4921/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3066 - acc: 0.9818 - val_loss: 0.6633 - val_acc: 0.7277\n",
      "Epoch 4922/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3066 - acc: 0.9807 - val_loss: 0.6610 - val_acc: 0.7314\n",
      "Epoch 4923/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9825 - val_loss: 0.6619 - val_acc: 0.7303\n",
      "Epoch 4924/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9815 - val_loss: 0.6630 - val_acc: 0.7299\n",
      "Epoch 4925/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9835 - val_loss: 0.6604 - val_acc: 0.7299\n",
      "Epoch 4926/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3064 - acc: 0.9823 - val_loss: 0.6625 - val_acc: 0.7284\n",
      "Epoch 4927/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9837 - val_loss: 0.6630 - val_acc: 0.7321\n",
      "Epoch 4928/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3064 - acc: 0.9824 - val_loss: 0.6619 - val_acc: 0.7321\n",
      "Epoch 4929/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9830 - val_loss: 0.6615 - val_acc: 0.7303\n",
      "Epoch 4930/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9833 - val_loss: 0.6639 - val_acc: 0.7281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4931/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9822 - val_loss: 0.6635 - val_acc: 0.7288\n",
      "Epoch 4932/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9817 - val_loss: 0.6614 - val_acc: 0.7314\n",
      "Epoch 4933/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9820 - val_loss: 0.6630 - val_acc: 0.7288\n",
      "Epoch 4934/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3066 - acc: 0.9825 - val_loss: 0.6619 - val_acc: 0.7325\n",
      "Epoch 4935/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9816 - val_loss: 0.6640 - val_acc: 0.7310\n",
      "Epoch 4936/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3065 - acc: 0.9813 - val_loss: 0.6634 - val_acc: 0.7317\n",
      "Epoch 4937/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3065 - acc: 0.9823 - val_loss: 0.6618 - val_acc: 0.7306\n",
      "Epoch 4938/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9817 - val_loss: 0.6628 - val_acc: 0.7299\n",
      "Epoch 4939/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9825 - val_loss: 0.6633 - val_acc: 0.7303\n",
      "Epoch 4940/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9826 - val_loss: 0.6616 - val_acc: 0.7277\n",
      "Epoch 4941/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9834 - val_loss: 0.6629 - val_acc: 0.7321\n",
      "Epoch 4942/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9813 - val_loss: 0.6631 - val_acc: 0.7310\n",
      "Epoch 4943/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3065 - acc: 0.9825 - val_loss: 0.6632 - val_acc: 0.7317\n",
      "Epoch 4944/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9817 - val_loss: 0.6626 - val_acc: 0.7343\n",
      "Epoch 4945/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9824 - val_loss: 0.6635 - val_acc: 0.7306\n",
      "Epoch 4946/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9818 - val_loss: 0.6624 - val_acc: 0.7306\n",
      "Epoch 4947/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9818 - val_loss: 0.6624 - val_acc: 0.7284\n",
      "Epoch 4948/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3065 - acc: 0.9830 - val_loss: 0.6628 - val_acc: 0.7325\n",
      "Epoch 4949/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9818 - val_loss: 0.6633 - val_acc: 0.7336\n",
      "Epoch 4950/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3065 - acc: 0.9825 - val_loss: 0.6626 - val_acc: 0.7303\n",
      "Epoch 4951/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3066 - acc: 0.9798 - val_loss: 0.6645 - val_acc: 0.7248\n",
      "Epoch 4952/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3080 - acc: 0.9727 - val_loss: 0.6606 - val_acc: 0.7251\n",
      "Epoch 4953/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3073 - acc: 0.9753 - val_loss: 0.6704 - val_acc: 0.7244\n",
      "Epoch 4954/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3070 - acc: 0.9787 - val_loss: 0.6622 - val_acc: 0.7306\n",
      "Epoch 4955/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9817 - val_loss: 0.6605 - val_acc: 0.7273\n",
      "Epoch 4956/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9836 - val_loss: 0.6601 - val_acc: 0.7292\n",
      "Epoch 4957/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9847 - val_loss: 0.6599 - val_acc: 0.7299\n",
      "Epoch 4958/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9844 - val_loss: 0.6598 - val_acc: 0.7273\n",
      "Epoch 4959/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9851 - val_loss: 0.6598 - val_acc: 0.7270\n",
      "Epoch 4960/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9857 - val_loss: 0.6588 - val_acc: 0.7284\n",
      "Epoch 4961/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9854 - val_loss: 0.6597 - val_acc: 0.7277\n",
      "Epoch 4962/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9853 - val_loss: 0.6596 - val_acc: 0.7277\n",
      "Epoch 4963/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9862 - val_loss: 0.6588 - val_acc: 0.7277\n",
      "Epoch 4964/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9854 - val_loss: 0.6592 - val_acc: 0.7299\n",
      "Epoch 4965/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9851 - val_loss: 0.6593 - val_acc: 0.7295\n",
      "Epoch 4966/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9854 - val_loss: 0.6587 - val_acc: 0.7270\n",
      "Epoch 4967/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9840 - val_loss: 0.6602 - val_acc: 0.7281\n",
      "Epoch 4968/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9835 - val_loss: 0.6597 - val_acc: 0.7281\n",
      "Epoch 4969/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9811 - val_loss: 0.6584 - val_acc: 0.7339\n",
      "Epoch 4970/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3067 - acc: 0.9801 - val_loss: 0.6599 - val_acc: 0.7248\n",
      "Epoch 4971/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3067 - acc: 0.9807 - val_loss: 0.6590 - val_acc: 0.7303\n",
      "Epoch 4972/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3067 - acc: 0.9807 - val_loss: 0.6577 - val_acc: 0.7310\n",
      "Epoch 4973/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3066 - acc: 0.9803 - val_loss: 0.6605 - val_acc: 0.7306\n",
      "Epoch 4974/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9814 - val_loss: 0.6607 - val_acc: 0.7277\n",
      "Epoch 4975/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9835 - val_loss: 0.6579 - val_acc: 0.7306\n",
      "Epoch 4976/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9824 - val_loss: 0.6598 - val_acc: 0.7343\n",
      "Epoch 4977/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3081 - acc: 0.9760 - val_loss: 0.6623 - val_acc: 0.7321\n",
      "Epoch 4978/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3074 - acc: 0.9761 - val_loss: 0.6588 - val_acc: 0.7339\n",
      "Epoch 4979/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3067 - acc: 0.9814 - val_loss: 0.6567 - val_acc: 0.7299\n",
      "Epoch 4980/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9840 - val_loss: 0.6587 - val_acc: 0.7321\n",
      "Epoch 4981/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9849 - val_loss: 0.6583 - val_acc: 0.7317\n",
      "Epoch 4982/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9853 - val_loss: 0.6587 - val_acc: 0.7295\n",
      "Epoch 4983/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9851 - val_loss: 0.6586 - val_acc: 0.7314\n",
      "Epoch 4984/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9856 - val_loss: 0.6586 - val_acc: 0.7336\n",
      "Epoch 4985/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9856 - val_loss: 0.6584 - val_acc: 0.7336\n",
      "Epoch 4986/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9861 - val_loss: 0.6586 - val_acc: 0.7336\n",
      "Epoch 4987/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9865 - val_loss: 0.6582 - val_acc: 0.7336\n",
      "Epoch 4988/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9855 - val_loss: 0.6582 - val_acc: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4989/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9861 - val_loss: 0.6583 - val_acc: 0.7332\n",
      "Epoch 4990/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9858 - val_loss: 0.6587 - val_acc: 0.7346\n",
      "Epoch 4991/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9854 - val_loss: 0.6573 - val_acc: 0.7339\n",
      "Epoch 4992/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9845 - val_loss: 0.6577 - val_acc: 0.7336\n",
      "Epoch 4993/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9837 - val_loss: 0.6579 - val_acc: 0.7339\n",
      "Epoch 4994/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9798 - val_loss: 0.6586 - val_acc: 0.7361\n",
      "Epoch 4995/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3066 - acc: 0.9819 - val_loss: 0.6632 - val_acc: 0.7336\n",
      "Epoch 4996/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3066 - acc: 0.9799 - val_loss: 0.6589 - val_acc: 0.7328\n",
      "Epoch 4997/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3066 - acc: 0.9818 - val_loss: 0.6595 - val_acc: 0.7292\n",
      "Epoch 4998/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3066 - acc: 0.9804 - val_loss: 0.6555 - val_acc: 0.7310\n",
      "Epoch 4999/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9821 - val_loss: 0.6558 - val_acc: 0.7288\n",
      "Epoch 5000/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9833 - val_loss: 0.6569 - val_acc: 0.7314\n",
      "Epoch 5001/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9836 - val_loss: 0.6555 - val_acc: 0.7299\n",
      "Epoch 5002/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9824 - val_loss: 0.6582 - val_acc: 0.7281\n",
      "Epoch 5003/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9847 - val_loss: 0.6550 - val_acc: 0.7339\n",
      "Epoch 5004/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9840 - val_loss: 0.6553 - val_acc: 0.7292\n",
      "Epoch 5005/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9830 - val_loss: 0.6564 - val_acc: 0.7332\n",
      "Epoch 5006/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9833 - val_loss: 0.6569 - val_acc: 0.7299\n",
      "Epoch 5007/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3065 - acc: 0.9818 - val_loss: 0.6572 - val_acc: 0.7295\n",
      "Epoch 5008/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9815 - val_loss: 0.6557 - val_acc: 0.7317\n",
      "Epoch 5009/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3078 - acc: 0.9763 - val_loss: 0.6589 - val_acc: 0.7361\n",
      "Epoch 5010/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3123 - acc: 0.9650 - val_loss: 0.6623 - val_acc: 0.7332\n",
      "Epoch 5011/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3220 - acc: 0.9550 - val_loss: 0.6876 - val_acc: 0.7204\n",
      "Epoch 5012/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3198 - acc: 0.9516 - val_loss: 0.6721 - val_acc: 0.7266\n",
      "Epoch 5013/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3118 - acc: 0.9620 - val_loss: 0.6649 - val_acc: 0.7248\n",
      "Epoch 5014/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3098 - acc: 0.9666 - val_loss: 0.6596 - val_acc: 0.7248\n",
      "Epoch 5015/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3089 - acc: 0.9687 - val_loss: 0.6579 - val_acc: 0.7281\n",
      "Epoch 5016/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3085 - acc: 0.9704 - val_loss: 0.6574 - val_acc: 0.7288\n",
      "Epoch 5017/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3082 - acc: 0.9726 - val_loss: 0.6571 - val_acc: 0.7270\n",
      "Epoch 5018/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3080 - acc: 0.9734 - val_loss: 0.6565 - val_acc: 0.7255\n",
      "Epoch 5019/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3078 - acc: 0.9753 - val_loss: 0.6559 - val_acc: 0.7270\n",
      "Epoch 5020/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3076 - acc: 0.9752 - val_loss: 0.6564 - val_acc: 0.7255\n",
      "Epoch 5021/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3075 - acc: 0.9766 - val_loss: 0.6567 - val_acc: 0.7277\n",
      "Epoch 5022/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3074 - acc: 0.9776 - val_loss: 0.6568 - val_acc: 0.7292\n",
      "Epoch 5023/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3073 - acc: 0.9780 - val_loss: 0.6566 - val_acc: 0.7281\n",
      "Epoch 5024/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3072 - acc: 0.9790 - val_loss: 0.6571 - val_acc: 0.7277\n",
      "Epoch 5025/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3071 - acc: 0.9788 - val_loss: 0.6564 - val_acc: 0.7292\n",
      "Epoch 5026/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3070 - acc: 0.9791 - val_loss: 0.6568 - val_acc: 0.7284\n",
      "Epoch 5027/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3070 - acc: 0.9794 - val_loss: 0.6567 - val_acc: 0.7288\n",
      "Epoch 5028/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3069 - acc: 0.9796 - val_loss: 0.6566 - val_acc: 0.7288\n",
      "Epoch 5029/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3069 - acc: 0.9797 - val_loss: 0.6563 - val_acc: 0.7295\n",
      "Epoch 5030/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3068 - acc: 0.9804 - val_loss: 0.6566 - val_acc: 0.7292\n",
      "Epoch 5031/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3068 - acc: 0.9813 - val_loss: 0.6563 - val_acc: 0.7303\n",
      "Epoch 5032/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9815 - val_loss: 0.6559 - val_acc: 0.7306\n",
      "Epoch 5033/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9811 - val_loss: 0.6568 - val_acc: 0.7292\n",
      "Epoch 5034/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9823 - val_loss: 0.6564 - val_acc: 0.7292\n",
      "Epoch 5035/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3064 - acc: 0.9820 - val_loss: 0.6561 - val_acc: 0.7284\n",
      "Epoch 5036/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9821 - val_loss: 0.6567 - val_acc: 0.7270\n",
      "Epoch 5037/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9821 - val_loss: 0.6569 - val_acc: 0.7303\n",
      "Epoch 5038/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9823 - val_loss: 0.6567 - val_acc: 0.7281\n",
      "Epoch 5039/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9825 - val_loss: 0.6571 - val_acc: 0.7281\n",
      "Epoch 5040/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3063 - acc: 0.9825 - val_loss: 0.6570 - val_acc: 0.7306\n",
      "Epoch 5041/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9828 - val_loss: 0.6574 - val_acc: 0.7273\n",
      "Epoch 5042/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9832 - val_loss: 0.6568 - val_acc: 0.7288\n",
      "Epoch 5043/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9829 - val_loss: 0.6573 - val_acc: 0.7288\n",
      "Epoch 5044/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9835 - val_loss: 0.6579 - val_acc: 0.7292\n",
      "Epoch 5045/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9836 - val_loss: 0.6574 - val_acc: 0.7284\n",
      "Epoch 5046/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9839 - val_loss: 0.6576 - val_acc: 0.7295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5047/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9837 - val_loss: 0.6585 - val_acc: 0.7288\n",
      "Epoch 5048/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9836 - val_loss: 0.6582 - val_acc: 0.7295\n",
      "Epoch 5049/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9841 - val_loss: 0.6589 - val_acc: 0.7299\n",
      "Epoch 5050/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9842 - val_loss: 0.6585 - val_acc: 0.7299\n",
      "Epoch 5051/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9850 - val_loss: 0.6588 - val_acc: 0.7306\n",
      "Epoch 5052/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9845 - val_loss: 0.6587 - val_acc: 0.7303\n",
      "Epoch 5053/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9847 - val_loss: 0.6589 - val_acc: 0.7310\n",
      "Epoch 5054/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3062 - acc: 0.9846 - val_loss: 0.6582 - val_acc: 0.7295\n",
      "Epoch 5055/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9847 - val_loss: 0.6584 - val_acc: 0.7299\n",
      "Epoch 5056/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9847 - val_loss: 0.6585 - val_acc: 0.7292\n",
      "Epoch 5057/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9850 - val_loss: 0.6584 - val_acc: 0.7306\n",
      "Epoch 5058/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9847 - val_loss: 0.6586 - val_acc: 0.7303\n",
      "Epoch 5059/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9846 - val_loss: 0.6582 - val_acc: 0.7317\n",
      "Epoch 5060/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9851 - val_loss: 0.6576 - val_acc: 0.7299\n",
      "Epoch 5061/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3072 - acc: 0.9795 - val_loss: 0.6618 - val_acc: 0.7332\n",
      "Epoch 5062/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3146 - acc: 0.9620 - val_loss: 0.6702 - val_acc: 0.7303\n",
      "Epoch 5063/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3097 - acc: 0.9681 - val_loss: 0.6672 - val_acc: 0.7306\n",
      "Epoch 5064/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3084 - acc: 0.9717 - val_loss: 0.6667 - val_acc: 0.7251\n",
      "Epoch 5065/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3074 - acc: 0.9746 - val_loss: 0.6638 - val_acc: 0.7288\n",
      "Epoch 5066/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3070 - acc: 0.9767 - val_loss: 0.6629 - val_acc: 0.7288\n",
      "Epoch 5067/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3068 - acc: 0.9784 - val_loss: 0.6620 - val_acc: 0.7288\n",
      "Epoch 5068/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3067 - acc: 0.9789 - val_loss: 0.6615 - val_acc: 0.7299\n",
      "Epoch 5069/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3066 - acc: 0.9805 - val_loss: 0.6611 - val_acc: 0.7273\n",
      "Epoch 5070/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9814 - val_loss: 0.6615 - val_acc: 0.7277\n",
      "Epoch 5071/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9822 - val_loss: 0.6617 - val_acc: 0.7284\n",
      "Epoch 5072/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9825 - val_loss: 0.6618 - val_acc: 0.7284\n",
      "Epoch 5073/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9827 - val_loss: 0.6615 - val_acc: 0.7273\n",
      "Epoch 5074/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9833 - val_loss: 0.6614 - val_acc: 0.7292\n",
      "Epoch 5075/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9834 - val_loss: 0.6612 - val_acc: 0.7255\n",
      "Epoch 5076/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3063 - acc: 0.9833 - val_loss: 0.6612 - val_acc: 0.7273\n",
      "Epoch 5077/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9840 - val_loss: 0.6610 - val_acc: 0.7259\n",
      "Epoch 5078/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9840 - val_loss: 0.6609 - val_acc: 0.7262\n",
      "Epoch 5079/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9846 - val_loss: 0.6606 - val_acc: 0.7266\n",
      "Epoch 5080/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9839 - val_loss: 0.6604 - val_acc: 0.7262\n",
      "Epoch 5081/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9843 - val_loss: 0.6606 - val_acc: 0.7240\n",
      "Epoch 5082/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9848 - val_loss: 0.6609 - val_acc: 0.7266\n",
      "Epoch 5083/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9845 - val_loss: 0.6603 - val_acc: 0.7255\n",
      "Epoch 5084/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9847 - val_loss: 0.6604 - val_acc: 0.7255\n",
      "Epoch 5085/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9850 - val_loss: 0.6603 - val_acc: 0.7259\n",
      "Epoch 5086/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9851 - val_loss: 0.6597 - val_acc: 0.7259\n",
      "Epoch 5087/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9844 - val_loss: 0.6602 - val_acc: 0.7266\n",
      "Epoch 5088/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3062 - acc: 0.9842 - val_loss: 0.6596 - val_acc: 0.7259\n",
      "Epoch 5089/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9854 - val_loss: 0.6601 - val_acc: 0.7266\n",
      "Epoch 5090/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9849 - val_loss: 0.6602 - val_acc: 0.7259\n",
      "Epoch 5091/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9845 - val_loss: 0.6602 - val_acc: 0.7255\n",
      "Epoch 5092/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9841 - val_loss: 0.6594 - val_acc: 0.7273\n",
      "Epoch 5093/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9836 - val_loss: 0.6605 - val_acc: 0.7277\n",
      "Epoch 5094/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9838 - val_loss: 0.6603 - val_acc: 0.7262\n",
      "Epoch 5095/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9839 - val_loss: 0.6590 - val_acc: 0.7251\n",
      "Epoch 5096/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9833 - val_loss: 0.6593 - val_acc: 0.7284\n",
      "Epoch 5097/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9823 - val_loss: 0.6605 - val_acc: 0.7259\n",
      "Epoch 5098/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9824 - val_loss: 0.6598 - val_acc: 0.7277\n",
      "Epoch 5099/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3066 - acc: 0.9812 - val_loss: 0.6673 - val_acc: 0.7237\n",
      "Epoch 5100/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3076 - acc: 0.9789 - val_loss: 0.6669 - val_acc: 0.7244\n",
      "Epoch 5101/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3126 - acc: 0.9681 - val_loss: 0.6718 - val_acc: 0.7215\n",
      "Epoch 5102/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3128 - acc: 0.9656 - val_loss: 0.6665 - val_acc: 0.7233\n",
      "Epoch 5103/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3093 - acc: 0.9732 - val_loss: 0.6693 - val_acc: 0.7266\n",
      "Epoch 5104/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3075 - acc: 0.9764 - val_loss: 0.6691 - val_acc: 0.7251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5105/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3071 - acc: 0.9786 - val_loss: 0.6690 - val_acc: 0.7266\n",
      "Epoch 5106/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3069 - acc: 0.9789 - val_loss: 0.6690 - val_acc: 0.7237\n",
      "Epoch 5107/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3068 - acc: 0.9793 - val_loss: 0.6685 - val_acc: 0.7240\n",
      "Epoch 5108/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3068 - acc: 0.9804 - val_loss: 0.6686 - val_acc: 0.7259\n",
      "Epoch 5109/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3066 - acc: 0.9817 - val_loss: 0.6689 - val_acc: 0.7259\n",
      "Epoch 5110/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9819 - val_loss: 0.6687 - val_acc: 0.7240\n",
      "Epoch 5111/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9818 - val_loss: 0.6686 - val_acc: 0.7259\n",
      "Epoch 5112/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9821 - val_loss: 0.6690 - val_acc: 0.7251\n",
      "Epoch 5113/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9828 - val_loss: 0.6691 - val_acc: 0.7244\n",
      "Epoch 5114/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9826 - val_loss: 0.6692 - val_acc: 0.7244\n",
      "Epoch 5115/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9827 - val_loss: 0.6690 - val_acc: 0.7259\n",
      "Epoch 5116/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9829 - val_loss: 0.6690 - val_acc: 0.7255\n",
      "Epoch 5117/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3063 - acc: 0.9837 - val_loss: 0.6692 - val_acc: 0.7251\n",
      "Epoch 5118/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9836 - val_loss: 0.6690 - val_acc: 0.7262\n",
      "Epoch 5119/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9841 - val_loss: 0.6693 - val_acc: 0.7259\n",
      "Epoch 5120/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9845 - val_loss: 0.6690 - val_acc: 0.7259\n",
      "Epoch 5121/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9841 - val_loss: 0.6692 - val_acc: 0.7266\n",
      "Epoch 5122/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9852 - val_loss: 0.6691 - val_acc: 0.7273\n",
      "Epoch 5123/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9852 - val_loss: 0.6689 - val_acc: 0.7266\n",
      "Epoch 5124/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9853 - val_loss: 0.6685 - val_acc: 0.7262\n",
      "Epoch 5125/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9826 - val_loss: 0.6698 - val_acc: 0.7281\n",
      "Epoch 5126/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3067 - acc: 0.9796 - val_loss: 0.6744 - val_acc: 0.7193\n",
      "Epoch 5127/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3072 - acc: 0.9800 - val_loss: 0.6737 - val_acc: 0.7193\n",
      "Epoch 5128/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3148 - acc: 0.9657 - val_loss: 0.6654 - val_acc: 0.7325\n",
      "Epoch 5129/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3090 - acc: 0.9746 - val_loss: 0.6652 - val_acc: 0.7321\n",
      "Epoch 5130/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3084 - acc: 0.9753 - val_loss: 0.6642 - val_acc: 0.7357\n",
      "Epoch 5131/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3075 - acc: 0.9776 - val_loss: 0.6638 - val_acc: 0.7317\n",
      "Epoch 5132/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3070 - acc: 0.9800 - val_loss: 0.6647 - val_acc: 0.7325\n",
      "Epoch 5133/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3068 - acc: 0.9805 - val_loss: 0.6651 - val_acc: 0.7325\n",
      "Epoch 5134/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3067 - acc: 0.9815 - val_loss: 0.6645 - val_acc: 0.7328\n",
      "Epoch 5135/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9816 - val_loss: 0.6647 - val_acc: 0.7325\n",
      "Epoch 5136/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9825 - val_loss: 0.6649 - val_acc: 0.7339\n",
      "Epoch 5137/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9833 - val_loss: 0.6646 - val_acc: 0.7328\n",
      "Epoch 5138/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9834 - val_loss: 0.6649 - val_acc: 0.7321\n",
      "Epoch 5139/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3065 - acc: 0.9837 - val_loss: 0.6648 - val_acc: 0.7325\n",
      "Epoch 5140/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3064 - acc: 0.9842 - val_loss: 0.6646 - val_acc: 0.7306\n",
      "Epoch 5141/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9833 - val_loss: 0.6647 - val_acc: 0.7310\n",
      "Epoch 5142/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3064 - acc: 0.9837 - val_loss: 0.6637 - val_acc: 0.7321\n",
      "Epoch 5143/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3064 - acc: 0.9848 - val_loss: 0.6642 - val_acc: 0.7295\n",
      "Epoch 5144/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9848 - val_loss: 0.6639 - val_acc: 0.7295\n",
      "Epoch 5145/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3064 - acc: 0.9849 - val_loss: 0.6642 - val_acc: 0.7325\n",
      "Epoch 5146/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9846 - val_loss: 0.6640 - val_acc: 0.7310\n",
      "Epoch 5147/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3063 - acc: 0.9841 - val_loss: 0.6639 - val_acc: 0.7306\n",
      "Epoch 5148/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9853 - val_loss: 0.6640 - val_acc: 0.7310\n",
      "Epoch 5149/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9853 - val_loss: 0.6641 - val_acc: 0.7292\n",
      "Epoch 5150/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9848 - val_loss: 0.6638 - val_acc: 0.7299\n",
      "Epoch 5151/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9857 - val_loss: 0.6637 - val_acc: 0.7306\n",
      "Epoch 5152/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9861 - val_loss: 0.6642 - val_acc: 0.7288\n",
      "Epoch 5153/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3063 - acc: 0.9854 - val_loss: 0.6637 - val_acc: 0.7303\n",
      "Epoch 5154/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3063 - acc: 0.9857 - val_loss: 0.6633 - val_acc: 0.7292\n",
      "Epoch 5155/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9854 - val_loss: 0.6631 - val_acc: 0.7314\n",
      "Epoch 5156/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9857 - val_loss: 0.6632 - val_acc: 0.7295\n",
      "Epoch 5157/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9847 - val_loss: 0.6631 - val_acc: 0.7295\n",
      "Epoch 5158/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3063 - acc: 0.9849 - val_loss: 0.6629 - val_acc: 0.7288\n",
      "Epoch 5159/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9857 - val_loss: 0.6632 - val_acc: 0.7325\n",
      "Epoch 5160/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3063 - acc: 0.9854 - val_loss: 0.6630 - val_acc: 0.7288\n",
      "Epoch 5161/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9852 - val_loss: 0.6642 - val_acc: 0.7288\n",
      "Epoch 5162/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9842 - val_loss: 0.6633 - val_acc: 0.7321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5163/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9841 - val_loss: 0.6646 - val_acc: 0.7321\n",
      "Epoch 5164/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9846 - val_loss: 0.6617 - val_acc: 0.7332\n",
      "Epoch 5165/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9835 - val_loss: 0.6630 - val_acc: 0.7281\n",
      "Epoch 5166/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9826 - val_loss: 0.6644 - val_acc: 0.7295\n",
      "Epoch 5167/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9820 - val_loss: 0.6613 - val_acc: 0.7284\n",
      "Epoch 5168/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9830 - val_loss: 0.6645 - val_acc: 0.7273\n",
      "Epoch 5169/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9824 - val_loss: 0.6657 - val_acc: 0.7321\n",
      "Epoch 5170/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9833 - val_loss: 0.6658 - val_acc: 0.7306\n",
      "Epoch 5171/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9836 - val_loss: 0.6652 - val_acc: 0.7299\n",
      "Epoch 5172/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9828 - val_loss: 0.6618 - val_acc: 0.7295\n",
      "Epoch 5173/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3071 - acc: 0.9785 - val_loss: 0.6613 - val_acc: 0.7277\n",
      "Epoch 5174/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3095 - acc: 0.9710 - val_loss: 0.6684 - val_acc: 0.7270\n",
      "Epoch 5175/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3097 - acc: 0.9701 - val_loss: 0.6747 - val_acc: 0.7255\n",
      "Epoch 5176/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3118 - acc: 0.9663 - val_loss: 0.6752 - val_acc: 0.7240\n",
      "Epoch 5177/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3102 - acc: 0.9685 - val_loss: 0.6786 - val_acc: 0.7208\n",
      "Epoch 5178/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3106 - acc: 0.9696 - val_loss: 0.6746 - val_acc: 0.7240\n",
      "Epoch 5179/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3085 - acc: 0.9734 - val_loss: 0.6748 - val_acc: 0.7270\n",
      "Epoch 5180/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3077 - acc: 0.9746 - val_loss: 0.6732 - val_acc: 0.7270\n",
      "Epoch 5181/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3069 - acc: 0.9762 - val_loss: 0.6733 - val_acc: 0.7277\n",
      "Epoch 5182/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3067 - acc: 0.9774 - val_loss: 0.6737 - val_acc: 0.7295\n",
      "Epoch 5183/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3066 - acc: 0.9785 - val_loss: 0.6741 - val_acc: 0.7273\n",
      "Epoch 5184/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9794 - val_loss: 0.6738 - val_acc: 0.7303\n",
      "Epoch 5185/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9797 - val_loss: 0.6739 - val_acc: 0.7306\n",
      "Epoch 5186/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9797 - val_loss: 0.6741 - val_acc: 0.7317\n",
      "Epoch 5187/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6738 - val_acc: 0.7310\n",
      "Epoch 5188/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9806 - val_loss: 0.6734 - val_acc: 0.7299\n",
      "Epoch 5189/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6745 - val_acc: 0.7306\n",
      "Epoch 5190/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9816 - val_loss: 0.6739 - val_acc: 0.7310\n",
      "Epoch 5191/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9816 - val_loss: 0.6743 - val_acc: 0.7310\n",
      "Epoch 5192/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9822 - val_loss: 0.6742 - val_acc: 0.7310\n",
      "Epoch 5193/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9828 - val_loss: 0.6746 - val_acc: 0.7299\n",
      "Epoch 5194/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9824 - val_loss: 0.6743 - val_acc: 0.7299\n",
      "Epoch 5195/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9824 - val_loss: 0.6739 - val_acc: 0.7325\n",
      "Epoch 5196/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6745 - val_acc: 0.7321\n",
      "Epoch 5197/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6745 - val_acc: 0.7314\n",
      "Epoch 5198/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9836 - val_loss: 0.6743 - val_acc: 0.7306\n",
      "Epoch 5199/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9831 - val_loss: 0.6738 - val_acc: 0.7317\n",
      "Epoch 5200/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6743 - val_acc: 0.7310\n",
      "Epoch 5201/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9838 - val_loss: 0.6736 - val_acc: 0.7295\n",
      "Epoch 5202/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9842 - val_loss: 0.6745 - val_acc: 0.7303\n",
      "Epoch 5203/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6743 - val_acc: 0.7306\n",
      "Epoch 5204/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9845 - val_loss: 0.6742 - val_acc: 0.7310\n",
      "Epoch 5205/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6738 - val_acc: 0.7328\n",
      "Epoch 5206/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6745 - val_acc: 0.7321\n",
      "Epoch 5207/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9847 - val_loss: 0.6744 - val_acc: 0.7303\n",
      "Epoch 5208/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6742 - val_acc: 0.7292\n",
      "Epoch 5209/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6742 - val_acc: 0.7332\n",
      "Epoch 5210/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6742 - val_acc: 0.7310\n",
      "Epoch 5211/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6738 - val_acc: 0.7303\n",
      "Epoch 5212/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9839 - val_loss: 0.6747 - val_acc: 0.7295\n",
      "Epoch 5213/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9842 - val_loss: 0.6738 - val_acc: 0.7306\n",
      "Epoch 5214/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9837 - val_loss: 0.6741 - val_acc: 0.7303\n",
      "Epoch 5215/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6734 - val_acc: 0.7306\n",
      "Epoch 5216/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6724 - val_acc: 0.7284\n",
      "Epoch 5217/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9821 - val_loss: 0.6740 - val_acc: 0.7314\n",
      "Epoch 5218/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9816 - val_loss: 0.6706 - val_acc: 0.7303\n",
      "Epoch 5219/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9832 - val_loss: 0.6743 - val_acc: 0.7310\n",
      "Epoch 5220/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9819 - val_loss: 0.6708 - val_acc: 0.7306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5221/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6727 - val_acc: 0.7277\n",
      "Epoch 5222/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6733 - val_acc: 0.7328\n",
      "Epoch 5223/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9837 - val_loss: 0.6719 - val_acc: 0.7314\n",
      "Epoch 5224/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9837 - val_loss: 0.6712 - val_acc: 0.7270\n",
      "Epoch 5225/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6718 - val_acc: 0.7303\n",
      "Epoch 5226/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6717 - val_acc: 0.7284\n",
      "Epoch 5227/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3062 - acc: 0.9816 - val_loss: 0.6718 - val_acc: 0.7277\n",
      "Epoch 5228/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9818 - val_loss: 0.6740 - val_acc: 0.7292\n",
      "Epoch 5229/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9807 - val_loss: 0.6723 - val_acc: 0.7295\n",
      "Epoch 5230/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9820 - val_loss: 0.6730 - val_acc: 0.7273\n",
      "Epoch 5231/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9810 - val_loss: 0.6705 - val_acc: 0.7281\n",
      "Epoch 5232/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9822 - val_loss: 0.6739 - val_acc: 0.7295\n",
      "Epoch 5233/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9824 - val_loss: 0.6732 - val_acc: 0.7314\n",
      "Epoch 5234/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6732 - val_acc: 0.7288\n",
      "Epoch 5235/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9833 - val_loss: 0.6716 - val_acc: 0.7292\n",
      "Epoch 5236/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6723 - val_acc: 0.7299\n",
      "Epoch 5237/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3063 - acc: 0.9819 - val_loss: 0.6707 - val_acc: 0.7262\n",
      "Epoch 5238/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9825 - val_loss: 0.6732 - val_acc: 0.7237\n",
      "Epoch 5239/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9810 - val_loss: 0.6708 - val_acc: 0.7288\n",
      "Epoch 5240/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9814 - val_loss: 0.6716 - val_acc: 0.7266\n",
      "Epoch 5241/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9826 - val_loss: 0.6714 - val_acc: 0.7281\n",
      "Epoch 5242/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6724 - val_acc: 0.7306\n",
      "Epoch 5243/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6709 - val_acc: 0.7281\n",
      "Epoch 5244/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6717 - val_acc: 0.7306\n",
      "Epoch 5245/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9831 - val_loss: 0.6701 - val_acc: 0.7288\n",
      "Epoch 5246/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9820 - val_loss: 0.6710 - val_acc: 0.7321\n",
      "Epoch 5247/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9811 - val_loss: 0.6671 - val_acc: 0.7284\n",
      "Epoch 5248/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3067 - acc: 0.9771 - val_loss: 0.6715 - val_acc: 0.7336\n",
      "Epoch 5249/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3101 - acc: 0.9676 - val_loss: 0.6753 - val_acc: 0.7346\n",
      "Epoch 5250/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3091 - acc: 0.9689 - val_loss: 0.6655 - val_acc: 0.7376\n",
      "Epoch 5251/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3083 - acc: 0.9732 - val_loss: 0.6749 - val_acc: 0.7365\n",
      "Epoch 5252/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3148 - acc: 0.9663 - val_loss: 0.6801 - val_acc: 0.7273\n",
      "Epoch 5253/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3117 - acc: 0.9710 - val_loss: 0.6855 - val_acc: 0.7325\n",
      "Epoch 5254/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3088 - acc: 0.9719 - val_loss: 0.6843 - val_acc: 0.7295\n",
      "Epoch 5255/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3080 - acc: 0.9757 - val_loss: 0.6838 - val_acc: 0.7310\n",
      "Epoch 5256/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3069 - acc: 0.9763 - val_loss: 0.6838 - val_acc: 0.7332\n",
      "Epoch 5257/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3067 - acc: 0.9776 - val_loss: 0.6823 - val_acc: 0.7325\n",
      "Epoch 5258/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9790 - val_loss: 0.6822 - val_acc: 0.7339\n",
      "Epoch 5259/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9792 - val_loss: 0.6826 - val_acc: 0.7332\n",
      "Epoch 5260/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9809 - val_loss: 0.6815 - val_acc: 0.7346\n",
      "Epoch 5261/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6815 - val_acc: 0.7339\n",
      "Epoch 5262/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9818 - val_loss: 0.6810 - val_acc: 0.7332\n",
      "Epoch 5263/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9822 - val_loss: 0.6807 - val_acc: 0.7346\n",
      "Epoch 5264/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6809 - val_acc: 0.7325\n",
      "Epoch 5265/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6804 - val_acc: 0.7325\n",
      "Epoch 5266/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6809 - val_acc: 0.7332\n",
      "Epoch 5267/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6801 - val_acc: 0.7332\n",
      "Epoch 5268/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6803 - val_acc: 0.7339\n",
      "Epoch 5269/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6802 - val_acc: 0.7328\n",
      "Epoch 5270/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6803 - val_acc: 0.7336\n",
      "Epoch 5271/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6799 - val_acc: 0.7350\n",
      "Epoch 5272/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6804 - val_acc: 0.7339\n",
      "Epoch 5273/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6803 - val_acc: 0.7336\n",
      "Epoch 5274/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6804 - val_acc: 0.7339\n",
      "Epoch 5275/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6803 - val_acc: 0.7328\n",
      "Epoch 5276/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6808 - val_acc: 0.7325\n",
      "Epoch 5277/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6805 - val_acc: 0.7328\n",
      "Epoch 5278/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6808 - val_acc: 0.7325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5279/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6808 - val_acc: 0.7328\n",
      "Epoch 5280/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6802 - val_acc: 0.7303\n",
      "Epoch 5281/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6808 - val_acc: 0.7321\n",
      "Epoch 5282/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6803 - val_acc: 0.7321\n",
      "Epoch 5283/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6806 - val_acc: 0.7321\n",
      "Epoch 5284/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6804 - val_acc: 0.7321\n",
      "Epoch 5285/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6805 - val_acc: 0.7325\n",
      "Epoch 5286/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9861 - val_loss: 0.6795 - val_acc: 0.7321\n",
      "Epoch 5287/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6810 - val_acc: 0.7317\n",
      "Epoch 5288/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3069 - acc: 0.9804 - val_loss: 0.6869 - val_acc: 0.7266\n",
      "Epoch 5289/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3092 - acc: 0.9687 - val_loss: 0.6928 - val_acc: 0.7189\n",
      "Epoch 5290/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3102 - acc: 0.9682 - val_loss: 0.6954 - val_acc: 0.7164\n",
      "Epoch 5291/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3081 - acc: 0.9745 - val_loss: 0.6921 - val_acc: 0.7219\n",
      "Epoch 5292/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3071 - acc: 0.9793 - val_loss: 0.6913 - val_acc: 0.7251\n",
      "Epoch 5293/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3068 - acc: 0.9805 - val_loss: 0.6909 - val_acc: 0.7248\n",
      "Epoch 5294/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3066 - acc: 0.9819 - val_loss: 0.6888 - val_acc: 0.7244\n",
      "Epoch 5295/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3065 - acc: 0.9838 - val_loss: 0.6892 - val_acc: 0.7230\n",
      "Epoch 5296/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9840 - val_loss: 0.6883 - val_acc: 0.7230\n",
      "Epoch 5297/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3063 - acc: 0.9843 - val_loss: 0.6892 - val_acc: 0.7244\n",
      "Epoch 5298/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9837 - val_loss: 0.6886 - val_acc: 0.7248\n",
      "Epoch 5299/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9848 - val_loss: 0.6892 - val_acc: 0.7262\n",
      "Epoch 5300/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9852 - val_loss: 0.6895 - val_acc: 0.7262\n",
      "Epoch 5301/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9854 - val_loss: 0.6896 - val_acc: 0.7255\n",
      "Epoch 5302/10000\n",
      "4259/4259 [==============================] - 2s 476us/step - loss: 0.3062 - acc: 0.9856 - val_loss: 0.6892 - val_acc: 0.7259\n",
      "Epoch 5303/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9858 - val_loss: 0.6893 - val_acc: 0.7262\n",
      "Epoch 5304/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3062 - acc: 0.9859 - val_loss: 0.6895 - val_acc: 0.7255\n",
      "Epoch 5305/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9865 - val_loss: 0.6893 - val_acc: 0.7259\n",
      "Epoch 5306/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9866 - val_loss: 0.6891 - val_acc: 0.7259\n",
      "Epoch 5307/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9869 - val_loss: 0.6892 - val_acc: 0.7259\n",
      "Epoch 5308/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9860 - val_loss: 0.6891 - val_acc: 0.7255\n",
      "Epoch 5309/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9859 - val_loss: 0.6893 - val_acc: 0.7277\n",
      "Epoch 5310/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9860 - val_loss: 0.6884 - val_acc: 0.7262\n",
      "Epoch 5311/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9871 - val_loss: 0.6889 - val_acc: 0.7277\n",
      "Epoch 5312/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9861 - val_loss: 0.6890 - val_acc: 0.7266\n",
      "Epoch 5313/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9857 - val_loss: 0.6886 - val_acc: 0.7251\n",
      "Epoch 5314/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9858 - val_loss: 0.6876 - val_acc: 0.7266\n",
      "Epoch 5315/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9847 - val_loss: 0.6882 - val_acc: 0.7259\n",
      "Epoch 5316/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9831 - val_loss: 0.6866 - val_acc: 0.7230\n",
      "Epoch 5317/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9833 - val_loss: 0.6869 - val_acc: 0.7255\n",
      "Epoch 5318/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9856 - val_loss: 0.6878 - val_acc: 0.7237\n",
      "Epoch 5319/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9836 - val_loss: 0.6843 - val_acc: 0.7259\n",
      "Epoch 5320/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9841 - val_loss: 0.6860 - val_acc: 0.7259\n",
      "Epoch 5321/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9847 - val_loss: 0.6861 - val_acc: 0.7244\n",
      "Epoch 5322/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6858 - val_acc: 0.7284\n",
      "Epoch 5323/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9836 - val_loss: 0.6848 - val_acc: 0.7288\n",
      "Epoch 5324/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9837 - val_loss: 0.6875 - val_acc: 0.7259\n",
      "Epoch 5325/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9833 - val_loss: 0.6852 - val_acc: 0.7266\n",
      "Epoch 5326/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9829 - val_loss: 0.6842 - val_acc: 0.7270\n",
      "Epoch 5327/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9836 - val_loss: 0.6851 - val_acc: 0.7303\n",
      "Epoch 5328/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9819 - val_loss: 0.6861 - val_acc: 0.7277\n",
      "Epoch 5329/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9838 - val_loss: 0.6872 - val_acc: 0.7262\n",
      "Epoch 5330/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3091 - acc: 0.9758 - val_loss: 0.6826 - val_acc: 0.7273\n",
      "Epoch 5331/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3121 - acc: 0.9667 - val_loss: 0.6805 - val_acc: 0.7273\n",
      "Epoch 5332/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3103 - acc: 0.9676 - val_loss: 0.6865 - val_acc: 0.7303\n",
      "Epoch 5333/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3089 - acc: 0.9735 - val_loss: 0.6758 - val_acc: 0.7273\n",
      "Epoch 5334/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3074 - acc: 0.9757 - val_loss: 0.6709 - val_acc: 0.7255\n",
      "Epoch 5335/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3076 - acc: 0.9753 - val_loss: 0.6740 - val_acc: 0.7255\n",
      "Epoch 5336/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3066 - acc: 0.9782 - val_loss: 0.6733 - val_acc: 0.7259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5337/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3064 - acc: 0.9805 - val_loss: 0.6730 - val_acc: 0.7251\n",
      "Epoch 5338/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6723 - val_acc: 0.7273\n",
      "Epoch 5339/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9805 - val_loss: 0.6723 - val_acc: 0.7240\n",
      "Epoch 5340/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6718 - val_acc: 0.7244\n",
      "Epoch 5341/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6718 - val_acc: 0.7259\n",
      "Epoch 5342/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6716 - val_acc: 0.7277\n",
      "Epoch 5343/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6719 - val_acc: 0.7259\n",
      "Epoch 5344/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6719 - val_acc: 0.7259\n",
      "Epoch 5345/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6714 - val_acc: 0.7259\n",
      "Epoch 5346/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6715 - val_acc: 0.7262\n",
      "Epoch 5347/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6716 - val_acc: 0.7251\n",
      "Epoch 5348/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6715 - val_acc: 0.7244\n",
      "Epoch 5349/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6713 - val_acc: 0.7255\n",
      "Epoch 5350/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6719 - val_acc: 0.7251\n",
      "Epoch 5351/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6718 - val_acc: 0.7262\n",
      "Epoch 5352/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6718 - val_acc: 0.7270\n",
      "Epoch 5353/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6718 - val_acc: 0.7273\n",
      "Epoch 5354/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6721 - val_acc: 0.7259\n",
      "Epoch 5355/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6715 - val_acc: 0.7270\n",
      "Epoch 5356/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6716 - val_acc: 0.7259\n",
      "Epoch 5357/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3058 - acc: 0.9853 - val_loss: 0.6720 - val_acc: 0.7248\n",
      "Epoch 5358/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9859 - val_loss: 0.6722 - val_acc: 0.7251\n",
      "Epoch 5359/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9857 - val_loss: 0.6728 - val_acc: 0.7248\n",
      "Epoch 5360/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9857 - val_loss: 0.6719 - val_acc: 0.7259\n",
      "Epoch 5361/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6725 - val_acc: 0.7255\n",
      "Epoch 5362/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9846 - val_loss: 0.6749 - val_acc: 0.7244\n",
      "Epoch 5363/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6713 - val_acc: 0.7281\n",
      "Epoch 5364/10000\n",
      "4259/4259 [==============================] - 2s 479us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6752 - val_acc: 0.7284\n",
      "Epoch 5365/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9832 - val_loss: 0.6731 - val_acc: 0.7273\n",
      "Epoch 5366/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6753 - val_acc: 0.7262\n",
      "Epoch 5367/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6759 - val_acc: 0.7295\n",
      "Epoch 5368/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9814 - val_loss: 0.6735 - val_acc: 0.7266\n",
      "Epoch 5369/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6766 - val_acc: 0.7303\n",
      "Epoch 5370/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3067 - acc: 0.9785 - val_loss: 0.6714 - val_acc: 0.7295\n",
      "Epoch 5371/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9782 - val_loss: 0.6674 - val_acc: 0.7248\n",
      "Epoch 5372/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6688 - val_acc: 0.7284\n",
      "Epoch 5373/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9834 - val_loss: 0.6705 - val_acc: 0.7281\n",
      "Epoch 5374/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6691 - val_acc: 0.7299\n",
      "Epoch 5375/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9843 - val_loss: 0.6689 - val_acc: 0.7295\n",
      "Epoch 5376/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6691 - val_acc: 0.7295\n",
      "Epoch 5377/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9840 - val_loss: 0.6687 - val_acc: 0.7292\n",
      "Epoch 5378/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9845 - val_loss: 0.6690 - val_acc: 0.7262\n",
      "Epoch 5379/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6682 - val_acc: 0.7281\n",
      "Epoch 5380/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6683 - val_acc: 0.7266\n",
      "Epoch 5381/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6699 - val_acc: 0.7314\n",
      "Epoch 5382/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6698 - val_acc: 0.7292\n",
      "Epoch 5383/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9811 - val_loss: 0.6749 - val_acc: 0.7251\n",
      "Epoch 5384/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9808 - val_loss: 0.6672 - val_acc: 0.7266\n",
      "Epoch 5385/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3080 - acc: 0.9737 - val_loss: 0.6840 - val_acc: 0.7303\n",
      "Epoch 5386/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3126 - acc: 0.9655 - val_loss: 0.6810 - val_acc: 0.7270\n",
      "Epoch 5387/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3104 - acc: 0.9735 - val_loss: 0.6718 - val_acc: 0.7284\n",
      "Epoch 5388/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3092 - acc: 0.9736 - val_loss: 0.6819 - val_acc: 0.7332\n",
      "Epoch 5389/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3107 - acc: 0.9730 - val_loss: 0.6802 - val_acc: 0.7306\n",
      "Epoch 5390/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3087 - acc: 0.9751 - val_loss: 0.6795 - val_acc: 0.7270\n",
      "Epoch 5391/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3078 - acc: 0.9788 - val_loss: 0.6790 - val_acc: 0.7240\n",
      "Epoch 5392/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3076 - acc: 0.9790 - val_loss: 0.6790 - val_acc: 0.7233\n",
      "Epoch 5393/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3074 - acc: 0.9794 - val_loss: 0.6782 - val_acc: 0.7284\n",
      "Epoch 5394/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3073 - acc: 0.9800 - val_loss: 0.6778 - val_acc: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5395/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3072 - acc: 0.9802 - val_loss: 0.6768 - val_acc: 0.7244\n",
      "Epoch 5396/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3072 - acc: 0.9814 - val_loss: 0.6767 - val_acc: 0.7251\n",
      "Epoch 5397/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3071 - acc: 0.9809 - val_loss: 0.6765 - val_acc: 0.7248\n",
      "Epoch 5398/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3071 - acc: 0.9820 - val_loss: 0.6765 - val_acc: 0.7266\n",
      "Epoch 5399/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3070 - acc: 0.9819 - val_loss: 0.6758 - val_acc: 0.7262\n",
      "Epoch 5400/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3070 - acc: 0.9825 - val_loss: 0.6759 - val_acc: 0.7248\n",
      "Epoch 5401/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3070 - acc: 0.9824 - val_loss: 0.6759 - val_acc: 0.7255\n",
      "Epoch 5402/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3070 - acc: 0.9830 - val_loss: 0.6763 - val_acc: 0.7281\n",
      "Epoch 5403/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3069 - acc: 0.9829 - val_loss: 0.6758 - val_acc: 0.7237\n",
      "Epoch 5404/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3069 - acc: 0.9830 - val_loss: 0.6759 - val_acc: 0.7259\n",
      "Epoch 5405/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3069 - acc: 0.9831 - val_loss: 0.6757 - val_acc: 0.7251\n",
      "Epoch 5406/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3069 - acc: 0.9831 - val_loss: 0.6756 - val_acc: 0.7248\n",
      "Epoch 5407/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3069 - acc: 0.9840 - val_loss: 0.6758 - val_acc: 0.7259\n",
      "Epoch 5408/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3069 - acc: 0.9836 - val_loss: 0.6759 - val_acc: 0.7255\n",
      "Epoch 5409/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3069 - acc: 0.9844 - val_loss: 0.6756 - val_acc: 0.7266\n",
      "Epoch 5410/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3068 - acc: 0.9840 - val_loss: 0.6752 - val_acc: 0.7259\n",
      "Epoch 5411/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3068 - acc: 0.9842 - val_loss: 0.6754 - val_acc: 0.7240\n",
      "Epoch 5412/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3068 - acc: 0.9844 - val_loss: 0.6754 - val_acc: 0.7262\n",
      "Epoch 5413/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3068 - acc: 0.9841 - val_loss: 0.6758 - val_acc: 0.7281\n",
      "Epoch 5414/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3068 - acc: 0.9848 - val_loss: 0.6754 - val_acc: 0.7262\n",
      "Epoch 5415/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3068 - acc: 0.9850 - val_loss: 0.6760 - val_acc: 0.7266\n",
      "Epoch 5416/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3069 - acc: 0.9844 - val_loss: 0.6765 - val_acc: 0.7273\n",
      "Epoch 5417/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3069 - acc: 0.9845 - val_loss: 0.6772 - val_acc: 0.7248\n",
      "Epoch 5418/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3069 - acc: 0.9836 - val_loss: 0.6762 - val_acc: 0.7255\n",
      "Epoch 5419/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3073 - acc: 0.9807 - val_loss: 0.6770 - val_acc: 0.7222\n",
      "Epoch 5420/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3083 - acc: 0.9741 - val_loss: 0.6878 - val_acc: 0.7259\n",
      "Epoch 5421/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3085 - acc: 0.9760 - val_loss: 0.6913 - val_acc: 0.7277\n",
      "Epoch 5422/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3100 - acc: 0.9743 - val_loss: 0.6891 - val_acc: 0.7299\n",
      "Epoch 5423/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3207 - acc: 0.9562 - val_loss: 0.6901 - val_acc: 0.7226\n",
      "Epoch 5424/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3112 - acc: 0.9649 - val_loss: 0.6841 - val_acc: 0.7219\n",
      "Epoch 5425/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3091 - acc: 0.9706 - val_loss: 0.6827 - val_acc: 0.7273\n",
      "Epoch 5426/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3079 - acc: 0.9744 - val_loss: 0.6834 - val_acc: 0.7240\n",
      "Epoch 5427/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3081 - acc: 0.9741 - val_loss: 0.6835 - val_acc: 0.7270\n",
      "Epoch 5428/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3076 - acc: 0.9772 - val_loss: 0.6852 - val_acc: 0.7255\n",
      "Epoch 5429/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3073 - acc: 0.9783 - val_loss: 0.6853 - val_acc: 0.7248\n",
      "Epoch 5430/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3072 - acc: 0.9789 - val_loss: 0.6844 - val_acc: 0.7262\n",
      "Epoch 5431/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3070 - acc: 0.9797 - val_loss: 0.6849 - val_acc: 0.7277\n",
      "Epoch 5432/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3070 - acc: 0.9800 - val_loss: 0.6853 - val_acc: 0.7266\n",
      "Epoch 5433/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3069 - acc: 0.9809 - val_loss: 0.6849 - val_acc: 0.7281\n",
      "Epoch 5434/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3068 - acc: 0.9815 - val_loss: 0.6839 - val_acc: 0.7262\n",
      "Epoch 5435/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3068 - acc: 0.9821 - val_loss: 0.6847 - val_acc: 0.7251\n",
      "Epoch 5436/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3067 - acc: 0.9821 - val_loss: 0.6846 - val_acc: 0.7273\n",
      "Epoch 5437/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3067 - acc: 0.9823 - val_loss: 0.6843 - val_acc: 0.7262\n",
      "Epoch 5438/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3067 - acc: 0.9832 - val_loss: 0.6836 - val_acc: 0.7266\n",
      "Epoch 5439/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3066 - acc: 0.9831 - val_loss: 0.6835 - val_acc: 0.7233\n",
      "Epoch 5440/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3066 - acc: 0.9831 - val_loss: 0.6839 - val_acc: 0.7262\n",
      "Epoch 5441/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3066 - acc: 0.9834 - val_loss: 0.6833 - val_acc: 0.7237\n",
      "Epoch 5442/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9836 - val_loss: 0.6831 - val_acc: 0.7230\n",
      "Epoch 5443/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9838 - val_loss: 0.6831 - val_acc: 0.7248\n",
      "Epoch 5444/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3065 - acc: 0.9840 - val_loss: 0.6835 - val_acc: 0.7244\n",
      "Epoch 5445/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3065 - acc: 0.9845 - val_loss: 0.6836 - val_acc: 0.7240\n",
      "Epoch 5446/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9835 - val_loss: 0.6833 - val_acc: 0.7259\n",
      "Epoch 5447/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9840 - val_loss: 0.6830 - val_acc: 0.7262\n",
      "Epoch 5448/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9846 - val_loss: 0.6831 - val_acc: 0.7262\n",
      "Epoch 5449/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9841 - val_loss: 0.6834 - val_acc: 0.7255\n",
      "Epoch 5450/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9841 - val_loss: 0.6827 - val_acc: 0.7273\n",
      "Epoch 5451/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9847 - val_loss: 0.6828 - val_acc: 0.7230\n",
      "Epoch 5452/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9850 - val_loss: 0.6827 - val_acc: 0.7248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5453/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9844 - val_loss: 0.6828 - val_acc: 0.7251\n",
      "Epoch 5454/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9850 - val_loss: 0.6832 - val_acc: 0.7240\n",
      "Epoch 5455/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9845 - val_loss: 0.6821 - val_acc: 0.7262\n",
      "Epoch 5456/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3064 - acc: 0.9852 - val_loss: 0.6825 - val_acc: 0.7240\n",
      "Epoch 5457/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9845 - val_loss: 0.6821 - val_acc: 0.7237\n",
      "Epoch 5458/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9845 - val_loss: 0.6818 - val_acc: 0.7259\n",
      "Epoch 5459/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3064 - acc: 0.9845 - val_loss: 0.6820 - val_acc: 0.7266\n",
      "Epoch 5460/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3064 - acc: 0.9849 - val_loss: 0.6836 - val_acc: 0.7255\n",
      "Epoch 5461/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3064 - acc: 0.9837 - val_loss: 0.6832 - val_acc: 0.7237\n",
      "Epoch 5462/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9842 - val_loss: 0.6828 - val_acc: 0.7259\n",
      "Epoch 5463/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3064 - acc: 0.9833 - val_loss: 0.6827 - val_acc: 0.7237\n",
      "Epoch 5464/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3065 - acc: 0.9836 - val_loss: 0.6822 - val_acc: 0.7259\n",
      "Epoch 5465/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3066 - acc: 0.9846 - val_loss: 0.6810 - val_acc: 0.7240\n",
      "Epoch 5466/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9832 - val_loss: 0.6819 - val_acc: 0.7219\n",
      "Epoch 5467/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3074 - acc: 0.9761 - val_loss: 0.6814 - val_acc: 0.7244\n",
      "Epoch 5468/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3079 - acc: 0.9743 - val_loss: 0.6876 - val_acc: 0.7171\n",
      "Epoch 5469/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3087 - acc: 0.9728 - val_loss: 0.6835 - val_acc: 0.7226\n",
      "Epoch 5470/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3075 - acc: 0.9775 - val_loss: 0.6849 - val_acc: 0.7211\n",
      "Epoch 5471/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3068 - acc: 0.9801 - val_loss: 0.6838 - val_acc: 0.7233\n",
      "Epoch 5472/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9813 - val_loss: 0.6830 - val_acc: 0.7222\n",
      "Epoch 5473/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3066 - acc: 0.9821 - val_loss: 0.6835 - val_acc: 0.7266\n",
      "Epoch 5474/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3065 - acc: 0.9829 - val_loss: 0.6857 - val_acc: 0.7240\n",
      "Epoch 5475/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3064 - acc: 0.9838 - val_loss: 0.6849 - val_acc: 0.7226\n",
      "Epoch 5476/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9833 - val_loss: 0.6855 - val_acc: 0.7255\n",
      "Epoch 5477/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3064 - acc: 0.9844 - val_loss: 0.6857 - val_acc: 0.7230\n",
      "Epoch 5478/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3063 - acc: 0.9849 - val_loss: 0.6852 - val_acc: 0.7240\n",
      "Epoch 5479/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9827 - val_loss: 0.6860 - val_acc: 0.7244\n",
      "Epoch 5480/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3084 - acc: 0.9743 - val_loss: 0.6849 - val_acc: 0.7233\n",
      "Epoch 5481/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3102 - acc: 0.9707 - val_loss: 0.6756 - val_acc: 0.7281\n",
      "Epoch 5482/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3092 - acc: 0.9721 - val_loss: 0.6778 - val_acc: 0.7262\n",
      "Epoch 5483/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3070 - acc: 0.9779 - val_loss: 0.6774 - val_acc: 0.7306\n",
      "Epoch 5484/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9804 - val_loss: 0.6779 - val_acc: 0.7328\n",
      "Epoch 5485/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9806 - val_loss: 0.6783 - val_acc: 0.7303\n",
      "Epoch 5486/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6778 - val_acc: 0.7325\n",
      "Epoch 5487/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3061 - acc: 0.9828 - val_loss: 0.6777 - val_acc: 0.7339\n",
      "Epoch 5488/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6775 - val_acc: 0.7336\n",
      "Epoch 5489/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6784 - val_acc: 0.7343\n",
      "Epoch 5490/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6782 - val_acc: 0.7306\n",
      "Epoch 5491/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9834 - val_loss: 0.6782 - val_acc: 0.7310\n",
      "Epoch 5492/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9831 - val_loss: 0.6781 - val_acc: 0.7321\n",
      "Epoch 5493/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9832 - val_loss: 0.6783 - val_acc: 0.7321\n",
      "Epoch 5494/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9840 - val_loss: 0.6785 - val_acc: 0.7310\n",
      "Epoch 5495/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6787 - val_acc: 0.7292\n",
      "Epoch 5496/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9843 - val_loss: 0.6789 - val_acc: 0.7303\n",
      "Epoch 5497/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3058 - acc: 0.9844 - val_loss: 0.6786 - val_acc: 0.7299\n",
      "Epoch 5498/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6797 - val_acc: 0.7288\n",
      "Epoch 5499/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6784 - val_acc: 0.7288\n",
      "Epoch 5500/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9844 - val_loss: 0.6793 - val_acc: 0.7277\n",
      "Epoch 5501/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6786 - val_acc: 0.7288\n",
      "Epoch 5502/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6795 - val_acc: 0.7295\n",
      "Epoch 5503/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6789 - val_acc: 0.7303\n",
      "Epoch 5504/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6804 - val_acc: 0.7299\n",
      "Epoch 5505/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3058 - acc: 0.9849 - val_loss: 0.6792 - val_acc: 0.7288\n",
      "Epoch 5506/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6796 - val_acc: 0.7273\n",
      "Epoch 5507/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6794 - val_acc: 0.7295\n",
      "Epoch 5508/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6803 - val_acc: 0.7270\n",
      "Epoch 5509/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6796 - val_acc: 0.7255\n",
      "Epoch 5510/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6806 - val_acc: 0.7288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5511/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9832 - val_loss: 0.6777 - val_acc: 0.7288\n",
      "Epoch 5512/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9801 - val_loss: 0.6787 - val_acc: 0.7306\n",
      "Epoch 5513/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6790 - val_acc: 0.7281\n",
      "Epoch 5514/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3061 - acc: 0.9813 - val_loss: 0.6801 - val_acc: 0.7273\n",
      "Epoch 5515/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9822 - val_loss: 0.6765 - val_acc: 0.7266\n",
      "Epoch 5516/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6775 - val_acc: 0.7266\n",
      "Epoch 5517/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6759 - val_acc: 0.7281\n",
      "Epoch 5518/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6787 - val_acc: 0.7262\n",
      "Epoch 5519/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9824 - val_loss: 0.6767 - val_acc: 0.7262\n",
      "Epoch 5520/10000\n",
      "4259/4259 [==============================] - 2s 465us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6768 - val_acc: 0.7288\n",
      "Epoch 5521/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9830 - val_loss: 0.6771 - val_acc: 0.7266\n",
      "Epoch 5522/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9828 - val_loss: 0.6754 - val_acc: 0.7314\n",
      "Epoch 5523/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6795 - val_acc: 0.7251\n",
      "Epoch 5524/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6775 - val_acc: 0.7273\n",
      "Epoch 5525/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9815 - val_loss: 0.6795 - val_acc: 0.7266\n",
      "Epoch 5526/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3062 - acc: 0.9797 - val_loss: 0.6802 - val_acc: 0.7292\n",
      "Epoch 5527/10000\n",
      "4259/4259 [==============================] - 2s 475us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6750 - val_acc: 0.7306\n",
      "Epoch 5528/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9797 - val_loss: 0.6747 - val_acc: 0.7273\n",
      "Epoch 5529/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6764 - val_acc: 0.7281\n",
      "Epoch 5530/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6771 - val_acc: 0.7270\n",
      "Epoch 5531/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6770 - val_acc: 0.7284\n",
      "Epoch 5532/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3059 - acc: 0.9825 - val_loss: 0.6760 - val_acc: 0.7310\n",
      "Epoch 5533/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3059 - acc: 0.9829 - val_loss: 0.6770 - val_acc: 0.7321\n",
      "Epoch 5534/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9815 - val_loss: 0.6763 - val_acc: 0.7292\n",
      "Epoch 5535/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9815 - val_loss: 0.6769 - val_acc: 0.7281\n",
      "Epoch 5536/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9812 - val_loss: 0.6745 - val_acc: 0.7266\n",
      "Epoch 5537/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9817 - val_loss: 0.6784 - val_acc: 0.7295\n",
      "Epoch 5538/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6752 - val_acc: 0.7284\n",
      "Epoch 5539/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3060 - acc: 0.9815 - val_loss: 0.6767 - val_acc: 0.7288\n",
      "Epoch 5540/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6751 - val_acc: 0.7284\n",
      "Epoch 5541/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3068 - acc: 0.9786 - val_loss: 0.6855 - val_acc: 0.7248\n",
      "Epoch 5542/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3092 - acc: 0.9706 - val_loss: 0.6700 - val_acc: 0.7306\n",
      "Epoch 5543/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3086 - acc: 0.9711 - val_loss: 0.6702 - val_acc: 0.7262\n",
      "Epoch 5544/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3147 - acc: 0.9651 - val_loss: 0.6751 - val_acc: 0.7317\n",
      "Epoch 5545/10000\n",
      "4259/4259 [==============================] - 2s 478us/step - loss: 0.3087 - acc: 0.9723 - val_loss: 0.6708 - val_acc: 0.7310\n",
      "Epoch 5546/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3076 - acc: 0.9745 - val_loss: 0.6704 - val_acc: 0.7317\n",
      "Epoch 5547/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3073 - acc: 0.9768 - val_loss: 0.6729 - val_acc: 0.7226\n",
      "Epoch 5548/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3069 - acc: 0.9765 - val_loss: 0.6743 - val_acc: 0.7270\n",
      "Epoch 5549/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3072 - acc: 0.9769 - val_loss: 0.6790 - val_acc: 0.7284\n",
      "Epoch 5550/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3068 - acc: 0.9783 - val_loss: 0.6782 - val_acc: 0.7259\n",
      "Epoch 5551/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3065 - acc: 0.9800 - val_loss: 0.6774 - val_acc: 0.7266\n",
      "Epoch 5552/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3064 - acc: 0.9807 - val_loss: 0.6788 - val_acc: 0.7259\n",
      "Epoch 5553/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9813 - val_loss: 0.6785 - val_acc: 0.7259\n",
      "Epoch 5554/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9810 - val_loss: 0.6775 - val_acc: 0.7255\n",
      "Epoch 5555/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6778 - val_acc: 0.7270\n",
      "Epoch 5556/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9826 - val_loss: 0.6773 - val_acc: 0.7262\n",
      "Epoch 5557/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9833 - val_loss: 0.6772 - val_acc: 0.7270\n",
      "Epoch 5558/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9831 - val_loss: 0.6772 - val_acc: 0.7255\n",
      "Epoch 5559/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9834 - val_loss: 0.6772 - val_acc: 0.7244\n",
      "Epoch 5560/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9838 - val_loss: 0.6771 - val_acc: 0.7244\n",
      "Epoch 5561/10000\n",
      "4259/4259 [==============================] - 2s 477us/step - loss: 0.3060 - acc: 0.9842 - val_loss: 0.6770 - val_acc: 0.7248\n",
      "Epoch 5562/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6772 - val_acc: 0.7259\n",
      "Epoch 5563/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6774 - val_acc: 0.7259\n",
      "Epoch 5564/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6773 - val_acc: 0.7251\n",
      "Epoch 5565/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3059 - acc: 0.9848 - val_loss: 0.6771 - val_acc: 0.7248\n",
      "Epoch 5566/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9857 - val_loss: 0.6775 - val_acc: 0.7259\n",
      "Epoch 5567/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9855 - val_loss: 0.6773 - val_acc: 0.7259\n",
      "Epoch 5568/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6775 - val_acc: 0.7266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5569/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6775 - val_acc: 0.7244\n",
      "Epoch 5570/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9856 - val_loss: 0.6775 - val_acc: 0.7259\n",
      "Epoch 5571/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9858 - val_loss: 0.6773 - val_acc: 0.7251\n",
      "Epoch 5572/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6776 - val_acc: 0.7273\n",
      "Epoch 5573/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9856 - val_loss: 0.6776 - val_acc: 0.7259\n",
      "Epoch 5574/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9859 - val_loss: 0.6776 - val_acc: 0.7248\n",
      "Epoch 5575/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9858 - val_loss: 0.6772 - val_acc: 0.7266\n",
      "Epoch 5576/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9863 - val_loss: 0.6781 - val_acc: 0.7270\n",
      "Epoch 5577/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9860 - val_loss: 0.6775 - val_acc: 0.7262\n",
      "Epoch 5578/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9859 - val_loss: 0.6788 - val_acc: 0.7244\n",
      "Epoch 5579/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9862 - val_loss: 0.6782 - val_acc: 0.7233\n",
      "Epoch 5580/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6772 - val_acc: 0.7284\n",
      "Epoch 5581/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3082 - acc: 0.9761 - val_loss: 0.6844 - val_acc: 0.7189\n",
      "Epoch 5582/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3097 - acc: 0.9709 - val_loss: 0.6726 - val_acc: 0.7222\n",
      "Epoch 5583/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3078 - acc: 0.9750 - val_loss: 0.6684 - val_acc: 0.7281\n",
      "Epoch 5584/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3066 - acc: 0.9806 - val_loss: 0.6691 - val_acc: 0.7295\n",
      "Epoch 5585/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9816 - val_loss: 0.6681 - val_acc: 0.7295\n",
      "Epoch 5586/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9832 - val_loss: 0.6687 - val_acc: 0.7262\n",
      "Epoch 5587/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9840 - val_loss: 0.6692 - val_acc: 0.7288\n",
      "Epoch 5588/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9847 - val_loss: 0.6696 - val_acc: 0.7277\n",
      "Epoch 5589/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9848 - val_loss: 0.6701 - val_acc: 0.7259\n",
      "Epoch 5590/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6702 - val_acc: 0.7295\n",
      "Epoch 5591/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6702 - val_acc: 0.7281\n",
      "Epoch 5592/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6705 - val_acc: 0.7281\n",
      "Epoch 5593/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9861 - val_loss: 0.6709 - val_acc: 0.7251\n",
      "Epoch 5594/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9855 - val_loss: 0.6714 - val_acc: 0.7259\n",
      "Epoch 5595/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6721 - val_acc: 0.7273\n",
      "Epoch 5596/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9855 - val_loss: 0.6714 - val_acc: 0.7259\n",
      "Epoch 5597/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9861 - val_loss: 0.6720 - val_acc: 0.7270\n",
      "Epoch 5598/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3059 - acc: 0.9858 - val_loss: 0.6723 - val_acc: 0.7262\n",
      "Epoch 5599/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9860 - val_loss: 0.6718 - val_acc: 0.7262\n",
      "Epoch 5600/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6726 - val_acc: 0.7288\n",
      "Epoch 5601/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9853 - val_loss: 0.6731 - val_acc: 0.7270\n",
      "Epoch 5602/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6732 - val_acc: 0.7266\n",
      "Epoch 5603/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6726 - val_acc: 0.7270\n",
      "Epoch 5604/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9862 - val_loss: 0.6729 - val_acc: 0.7240\n",
      "Epoch 5605/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6731 - val_acc: 0.7233\n",
      "Epoch 5606/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6730 - val_acc: 0.7255\n",
      "Epoch 5607/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6725 - val_acc: 0.7270\n",
      "Epoch 5608/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9850 - val_loss: 0.6731 - val_acc: 0.7281\n",
      "Epoch 5609/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9831 - val_loss: 0.6727 - val_acc: 0.7270\n",
      "Epoch 5610/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6727 - val_acc: 0.7270\n",
      "Epoch 5611/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9818 - val_loss: 0.6724 - val_acc: 0.7248\n",
      "Epoch 5612/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3062 - acc: 0.9816 - val_loss: 0.6720 - val_acc: 0.7266\n",
      "Epoch 5613/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3061 - acc: 0.9823 - val_loss: 0.6722 - val_acc: 0.7259\n",
      "Epoch 5614/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9842 - val_loss: 0.6729 - val_acc: 0.7237\n",
      "Epoch 5615/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6722 - val_acc: 0.7226\n",
      "Epoch 5616/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9839 - val_loss: 0.6718 - val_acc: 0.7266\n",
      "Epoch 5617/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6730 - val_acc: 0.7262\n",
      "Epoch 5618/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6719 - val_acc: 0.7251\n",
      "Epoch 5619/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9832 - val_loss: 0.6730 - val_acc: 0.7237\n",
      "Epoch 5620/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6719 - val_acc: 0.7248\n",
      "Epoch 5621/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6726 - val_acc: 0.7255\n",
      "Epoch 5622/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6716 - val_acc: 0.7255\n",
      "Epoch 5623/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6704 - val_acc: 0.7259\n",
      "Epoch 5624/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3061 - acc: 0.9828 - val_loss: 0.6716 - val_acc: 0.7266\n",
      "Epoch 5625/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3063 - acc: 0.9820 - val_loss: 0.6764 - val_acc: 0.7237\n",
      "Epoch 5626/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9782 - val_loss: 0.6687 - val_acc: 0.7270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5627/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3063 - acc: 0.9806 - val_loss: 0.6720 - val_acc: 0.7273\n",
      "Epoch 5628/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9834 - val_loss: 0.6735 - val_acc: 0.7259\n",
      "Epoch 5629/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6733 - val_acc: 0.7281\n",
      "Epoch 5630/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6731 - val_acc: 0.7262\n",
      "Epoch 5631/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6739 - val_acc: 0.7266\n",
      "Epoch 5632/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6720 - val_acc: 0.7226\n",
      "Epoch 5633/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6718 - val_acc: 0.7266\n",
      "Epoch 5634/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6724 - val_acc: 0.7248\n",
      "Epoch 5635/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6713 - val_acc: 0.7237\n",
      "Epoch 5636/10000\n",
      "4259/4259 [==============================] - 2s 466us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6724 - val_acc: 0.7270\n",
      "Epoch 5637/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6711 - val_acc: 0.7273\n",
      "Epoch 5638/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3063 - acc: 0.9804 - val_loss: 0.6734 - val_acc: 0.7219\n",
      "Epoch 5639/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3065 - acc: 0.9792 - val_loss: 0.6694 - val_acc: 0.7262\n",
      "Epoch 5640/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3064 - acc: 0.9817 - val_loss: 0.6732 - val_acc: 0.7251\n",
      "Epoch 5641/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3061 - acc: 0.9817 - val_loss: 0.6698 - val_acc: 0.7259\n",
      "Epoch 5642/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9842 - val_loss: 0.6692 - val_acc: 0.7295\n",
      "Epoch 5643/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6711 - val_acc: 0.7273\n",
      "Epoch 5644/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6689 - val_acc: 0.7255\n",
      "Epoch 5645/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9856 - val_loss: 0.6691 - val_acc: 0.7292\n",
      "Epoch 5646/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6691 - val_acc: 0.7281\n",
      "Epoch 5647/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3059 - acc: 0.9848 - val_loss: 0.6690 - val_acc: 0.7262\n",
      "Epoch 5648/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6691 - val_acc: 0.7273\n",
      "Epoch 5649/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3060 - acc: 0.9838 - val_loss: 0.6679 - val_acc: 0.7244\n",
      "Epoch 5650/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3060 - acc: 0.9838 - val_loss: 0.6689 - val_acc: 0.7292\n",
      "Epoch 5651/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6694 - val_acc: 0.7237\n",
      "Epoch 5652/10000\n",
      "4259/4259 [==============================] - 2s 467us/step - loss: 0.3062 - acc: 0.9825 - val_loss: 0.6669 - val_acc: 0.7281\n",
      "Epoch 5653/10000\n",
      "4259/4259 [==============================] - 2s 468us/step - loss: 0.3062 - acc: 0.9812 - val_loss: 0.6676 - val_acc: 0.7295\n",
      "Epoch 5654/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3061 - acc: 0.9826 - val_loss: 0.6694 - val_acc: 0.7277\n",
      "Epoch 5655/10000\n",
      "4259/4259 [==============================] - 2s 474us/step - loss: 0.3060 - acc: 0.9812 - val_loss: 0.6691 - val_acc: 0.7233\n",
      "Epoch 5656/10000\n",
      "4259/4259 [==============================] - 2s 480us/step - loss: 0.3062 - acc: 0.9818 - val_loss: 0.6673 - val_acc: 0.7281\n",
      "Epoch 5657/10000\n",
      "4259/4259 [==============================] - 2s 519us/step - loss: 0.3063 - acc: 0.9788 - val_loss: 0.6705 - val_acc: 0.7240\n",
      "Epoch 5658/10000\n",
      "4259/4259 [==============================] - 2s 532us/step - loss: 0.3062 - acc: 0.9809 - val_loss: 0.6686 - val_acc: 0.7295\n",
      "Epoch 5659/10000\n",
      "4259/4259 [==============================] - 2s 513us/step - loss: 0.3060 - acc: 0.9822 - val_loss: 0.6713 - val_acc: 0.7303\n",
      "Epoch 5660/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6726 - val_acc: 0.7255\n",
      "Epoch 5661/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6716 - val_acc: 0.7277\n",
      "Epoch 5662/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6691 - val_acc: 0.7255\n",
      "Epoch 5663/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3067 - acc: 0.9803 - val_loss: 0.6845 - val_acc: 0.7325\n",
      "Epoch 5664/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3096 - acc: 0.9727 - val_loss: 0.6767 - val_acc: 0.7233\n",
      "Epoch 5665/10000\n",
      "4259/4259 [==============================] - 2s 472us/step - loss: 0.3100 - acc: 0.9723 - val_loss: 0.6748 - val_acc: 0.7277\n",
      "Epoch 5666/10000\n",
      "4259/4259 [==============================] - 2s 469us/step - loss: 0.3084 - acc: 0.9726 - val_loss: 0.6765 - val_acc: 0.7255\n",
      "Epoch 5667/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3074 - acc: 0.9787 - val_loss: 0.6750 - val_acc: 0.7266\n",
      "Epoch 5668/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3071 - acc: 0.9803 - val_loss: 0.6759 - val_acc: 0.7288\n",
      "Epoch 5669/10000\n",
      "4259/4259 [==============================] - 2s 473us/step - loss: 0.3069 - acc: 0.9815 - val_loss: 0.6751 - val_acc: 0.7281\n",
      "Epoch 5670/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3068 - acc: 0.9820 - val_loss: 0.6751 - val_acc: 0.7262\n",
      "Epoch 5671/10000\n",
      "4259/4259 [==============================] - 2s 471us/step - loss: 0.3068 - acc: 0.9835 - val_loss: 0.6750 - val_acc: 0.7273\n",
      "Epoch 5672/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3067 - acc: 0.9840 - val_loss: 0.6747 - val_acc: 0.7248\n",
      "Epoch 5673/10000\n",
      "4259/4259 [==============================] - 2s 470us/step - loss: 0.3067 - acc: 0.9842 - val_loss: 0.6741 - val_acc: 0.7270\n",
      "Epoch 5674/10000\n",
      "4259/4259 [==============================] - 2s 508us/step - loss: 0.3066 - acc: 0.9851 - val_loss: 0.6742 - val_acc: 0.7273\n",
      "Epoch 5675/10000\n",
      "4259/4259 [==============================] - 2s 572us/step - loss: 0.3066 - acc: 0.9851 - val_loss: 0.6741 - val_acc: 0.7273\n",
      "Epoch 5676/10000\n",
      "4259/4259 [==============================] - 3s 589us/step - loss: 0.3066 - acc: 0.9860 - val_loss: 0.6740 - val_acc: 0.7255\n",
      "Epoch 5677/10000\n",
      "4259/4259 [==============================] - 2s 517us/step - loss: 0.3066 - acc: 0.9854 - val_loss: 0.6739 - val_acc: 0.7270\n",
      "Epoch 5678/10000\n",
      "4259/4259 [==============================] - 2s 505us/step - loss: 0.3066 - acc: 0.9858 - val_loss: 0.6741 - val_acc: 0.7259\n",
      "Epoch 5679/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3066 - acc: 0.9864 - val_loss: 0.6732 - val_acc: 0.7262\n",
      "Epoch 5680/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3065 - acc: 0.9861 - val_loss: 0.6733 - val_acc: 0.7251\n",
      "Epoch 5681/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3065 - acc: 0.9864 - val_loss: 0.6734 - val_acc: 0.7266\n",
      "Epoch 5682/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3065 - acc: 0.9868 - val_loss: 0.6731 - val_acc: 0.7273\n",
      "Epoch 5683/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3065 - acc: 0.9864 - val_loss: 0.6729 - val_acc: 0.7259\n",
      "Epoch 5684/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3065 - acc: 0.9869 - val_loss: 0.6726 - val_acc: 0.7262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5685/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3065 - acc: 0.9865 - val_loss: 0.6730 - val_acc: 0.7251\n",
      "Epoch 5686/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3065 - acc: 0.9866 - val_loss: 0.6732 - val_acc: 0.7259\n",
      "Epoch 5687/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3065 - acc: 0.9867 - val_loss: 0.6731 - val_acc: 0.7251\n",
      "Epoch 5688/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3065 - acc: 0.9863 - val_loss: 0.6728 - val_acc: 0.7262\n",
      "Epoch 5689/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3065 - acc: 0.9868 - val_loss: 0.6730 - val_acc: 0.7262\n",
      "Epoch 5690/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3065 - acc: 0.9868 - val_loss: 0.6726 - val_acc: 0.7251\n",
      "Epoch 5691/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3065 - acc: 0.9863 - val_loss: 0.6731 - val_acc: 0.7259\n",
      "Epoch 5692/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3065 - acc: 0.9858 - val_loss: 0.6727 - val_acc: 0.7266\n",
      "Epoch 5693/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3066 - acc: 0.9851 - val_loss: 0.6731 - val_acc: 0.7259\n",
      "Epoch 5694/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3066 - acc: 0.9846 - val_loss: 0.6708 - val_acc: 0.7281\n",
      "Epoch 5695/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3066 - acc: 0.9845 - val_loss: 0.6737 - val_acc: 0.7262\n",
      "Epoch 5696/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3067 - acc: 0.9833 - val_loss: 0.6728 - val_acc: 0.7262\n",
      "Epoch 5697/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3068 - acc: 0.9829 - val_loss: 0.6721 - val_acc: 0.7219\n",
      "Epoch 5698/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3069 - acc: 0.9822 - val_loss: 0.6686 - val_acc: 0.7270\n",
      "Epoch 5699/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3068 - acc: 0.9831 - val_loss: 0.6720 - val_acc: 0.7259\n",
      "Epoch 5700/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3067 - acc: 0.9833 - val_loss: 0.6747 - val_acc: 0.7259\n",
      "Epoch 5701/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3071 - acc: 0.9823 - val_loss: 0.6655 - val_acc: 0.7284\n",
      "Epoch 5702/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3120 - acc: 0.9701 - val_loss: 0.6770 - val_acc: 0.7204\n",
      "Epoch 5703/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3129 - acc: 0.9642 - val_loss: 0.6679 - val_acc: 0.7226\n",
      "Epoch 5704/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3079 - acc: 0.9738 - val_loss: 0.6638 - val_acc: 0.7281\n",
      "Epoch 5705/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3071 - acc: 0.9763 - val_loss: 0.6610 - val_acc: 0.7255\n",
      "Epoch 5706/10000\n",
      "4259/4259 [==============================] - 2s 507us/step - loss: 0.3067 - acc: 0.9775 - val_loss: 0.6582 - val_acc: 0.7240\n",
      "Epoch 5707/10000\n",
      "4259/4259 [==============================] - 2s 505us/step - loss: 0.3065 - acc: 0.9797 - val_loss: 0.6587 - val_acc: 0.7259\n",
      "Epoch 5708/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3063 - acc: 0.9803 - val_loss: 0.6583 - val_acc: 0.7277\n",
      "Epoch 5709/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3062 - acc: 0.9810 - val_loss: 0.6579 - val_acc: 0.7259\n",
      "Epoch 5710/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3062 - acc: 0.9817 - val_loss: 0.6578 - val_acc: 0.7255\n",
      "Epoch 5711/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6583 - val_acc: 0.7270\n",
      "Epoch 5712/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6578 - val_acc: 0.7273\n",
      "Epoch 5713/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6583 - val_acc: 0.7262\n",
      "Epoch 5714/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6580 - val_acc: 0.7251\n",
      "Epoch 5715/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3059 - acc: 0.9829 - val_loss: 0.6580 - val_acc: 0.7273\n",
      "Epoch 5716/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6580 - val_acc: 0.7259\n",
      "Epoch 5717/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6590 - val_acc: 0.7255\n",
      "Epoch 5718/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6588 - val_acc: 0.7270\n",
      "Epoch 5719/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9844 - val_loss: 0.6605 - val_acc: 0.7284\n",
      "Epoch 5720/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6613 - val_acc: 0.7284\n",
      "Epoch 5721/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3058 - acc: 0.9845 - val_loss: 0.6616 - val_acc: 0.7288\n",
      "Epoch 5722/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9846 - val_loss: 0.6617 - val_acc: 0.7277\n",
      "Epoch 5723/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6617 - val_acc: 0.7277\n",
      "Epoch 5724/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9843 - val_loss: 0.6617 - val_acc: 0.7281\n",
      "Epoch 5725/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6617 - val_acc: 0.7284\n",
      "Epoch 5726/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3058 - acc: 0.9856 - val_loss: 0.6616 - val_acc: 0.7295\n",
      "Epoch 5727/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6613 - val_acc: 0.7277\n",
      "Epoch 5728/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6617 - val_acc: 0.7277\n",
      "Epoch 5729/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9848 - val_loss: 0.6618 - val_acc: 0.7292\n",
      "Epoch 5730/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6618 - val_acc: 0.7281\n",
      "Epoch 5731/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9856 - val_loss: 0.6616 - val_acc: 0.7288\n",
      "Epoch 5732/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6620 - val_acc: 0.7281\n",
      "Epoch 5733/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6616 - val_acc: 0.7288\n",
      "Epoch 5734/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6613 - val_acc: 0.7303\n",
      "Epoch 5735/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6611 - val_acc: 0.7284\n",
      "Epoch 5736/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9857 - val_loss: 0.6612 - val_acc: 0.7281\n",
      "Epoch 5737/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6604 - val_acc: 0.7288\n",
      "Epoch 5738/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9849 - val_loss: 0.6614 - val_acc: 0.7295\n",
      "Epoch 5739/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6614 - val_acc: 0.7284\n",
      "Epoch 5740/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3058 - acc: 0.9845 - val_loss: 0.6606 - val_acc: 0.7303\n",
      "Epoch 5741/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6597 - val_acc: 0.7284\n",
      "Epoch 5742/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3071 - acc: 0.9756 - val_loss: 0.6623 - val_acc: 0.7277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5743/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3065 - acc: 0.9777 - val_loss: 0.6657 - val_acc: 0.7299\n",
      "Epoch 5744/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6679 - val_acc: 0.7248\n",
      "Epoch 5745/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6679 - val_acc: 0.7248\n",
      "Epoch 5746/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6666 - val_acc: 0.7248\n",
      "Epoch 5747/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9861 - val_loss: 0.6667 - val_acc: 0.7240\n",
      "Epoch 5748/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3057 - acc: 0.9869 - val_loss: 0.6669 - val_acc: 0.7251\n",
      "Epoch 5749/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3057 - acc: 0.9869 - val_loss: 0.6668 - val_acc: 0.7259\n",
      "Epoch 5750/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3057 - acc: 0.9874 - val_loss: 0.6656 - val_acc: 0.7255\n",
      "Epoch 5751/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3057 - acc: 0.9866 - val_loss: 0.6653 - val_acc: 0.7251\n",
      "Epoch 5752/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3057 - acc: 0.9868 - val_loss: 0.6654 - val_acc: 0.7259\n",
      "Epoch 5753/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3057 - acc: 0.9868 - val_loss: 0.6657 - val_acc: 0.7277\n",
      "Epoch 5754/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3057 - acc: 0.9867 - val_loss: 0.6653 - val_acc: 0.7226\n",
      "Epoch 5755/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3057 - acc: 0.9858 - val_loss: 0.6655 - val_acc: 0.7255\n",
      "Epoch 5756/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9861 - val_loss: 0.6662 - val_acc: 0.7255\n",
      "Epoch 5757/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9842 - val_loss: 0.6650 - val_acc: 0.7299\n",
      "Epoch 5758/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9831 - val_loss: 0.6662 - val_acc: 0.7240\n",
      "Epoch 5759/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3061 - acc: 0.9802 - val_loss: 0.6637 - val_acc: 0.7270\n",
      "Epoch 5760/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3062 - acc: 0.9815 - val_loss: 0.6654 - val_acc: 0.7273\n",
      "Epoch 5761/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3062 - acc: 0.9804 - val_loss: 0.6636 - val_acc: 0.7251\n",
      "Epoch 5762/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9804 - val_loss: 0.6644 - val_acc: 0.7273\n",
      "Epoch 5763/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6648 - val_acc: 0.7277\n",
      "Epoch 5764/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9822 - val_loss: 0.6644 - val_acc: 0.7270\n",
      "Epoch 5765/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6633 - val_acc: 0.7270\n",
      "Epoch 5766/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9840 - val_loss: 0.6619 - val_acc: 0.7284\n",
      "Epoch 5767/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9840 - val_loss: 0.6642 - val_acc: 0.7259\n",
      "Epoch 5768/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6622 - val_acc: 0.7284\n",
      "Epoch 5769/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6621 - val_acc: 0.7288\n",
      "Epoch 5770/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6622 - val_acc: 0.7284\n",
      "Epoch 5771/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6647 - val_acc: 0.7299\n",
      "Epoch 5772/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6620 - val_acc: 0.7292\n",
      "Epoch 5773/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3059 - acc: 0.9825 - val_loss: 0.6637 - val_acc: 0.7284\n",
      "Epoch 5774/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3059 - acc: 0.9829 - val_loss: 0.6613 - val_acc: 0.7295\n",
      "Epoch 5775/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6660 - val_acc: 0.7259\n",
      "Epoch 5776/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6611 - val_acc: 0.7273\n",
      "Epoch 5777/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6625 - val_acc: 0.7281\n",
      "Epoch 5778/10000\n",
      "4259/4259 [==============================] - 2s 501us/step - loss: 0.3060 - acc: 0.9816 - val_loss: 0.6642 - val_acc: 0.7244\n",
      "Epoch 5779/10000\n",
      "4259/4259 [==============================] - 2s 508us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6624 - val_acc: 0.7273\n",
      "Epoch 5780/10000\n",
      "4259/4259 [==============================] - 2s 505us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6647 - val_acc: 0.7321\n",
      "Epoch 5781/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9819 - val_loss: 0.6628 - val_acc: 0.7266\n",
      "Epoch 5782/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6634 - val_acc: 0.7277\n",
      "Epoch 5783/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9830 - val_loss: 0.6628 - val_acc: 0.7288\n",
      "Epoch 5784/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9831 - val_loss: 0.6650 - val_acc: 0.7288\n",
      "Epoch 5785/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6647 - val_acc: 0.7292\n",
      "Epoch 5786/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9815 - val_loss: 0.6620 - val_acc: 0.7292\n",
      "Epoch 5787/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6654 - val_acc: 0.7255\n",
      "Epoch 5788/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6621 - val_acc: 0.7277\n",
      "Epoch 5789/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9831 - val_loss: 0.6659 - val_acc: 0.7273\n",
      "Epoch 5790/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9832 - val_loss: 0.6625 - val_acc: 0.7273\n",
      "Epoch 5791/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3059 - acc: 0.9827 - val_loss: 0.6644 - val_acc: 0.7266\n",
      "Epoch 5792/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6616 - val_acc: 0.7270\n",
      "Epoch 5793/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6642 - val_acc: 0.7292\n",
      "Epoch 5794/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6625 - val_acc: 0.7284\n",
      "Epoch 5795/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9829 - val_loss: 0.6619 - val_acc: 0.7299\n",
      "Epoch 5796/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9826 - val_loss: 0.6640 - val_acc: 0.7277\n",
      "Epoch 5797/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9829 - val_loss: 0.6634 - val_acc: 0.7262\n",
      "Epoch 5798/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6628 - val_acc: 0.7306\n",
      "Epoch 5799/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6639 - val_acc: 0.7295\n",
      "Epoch 5800/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6621 - val_acc: 0.7284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5801/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9822 - val_loss: 0.6633 - val_acc: 0.7292\n",
      "Epoch 5802/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9825 - val_loss: 0.6617 - val_acc: 0.7292\n",
      "Epoch 5803/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6626 - val_acc: 0.7277\n",
      "Epoch 5804/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9813 - val_loss: 0.6639 - val_acc: 0.7266\n",
      "Epoch 5805/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6632 - val_acc: 0.7295\n",
      "Epoch 5806/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9832 - val_loss: 0.6609 - val_acc: 0.7314\n",
      "Epoch 5807/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9832 - val_loss: 0.6626 - val_acc: 0.7303\n",
      "Epoch 5808/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9838 - val_loss: 0.6626 - val_acc: 0.7288\n",
      "Epoch 5809/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9836 - val_loss: 0.6598 - val_acc: 0.7292\n",
      "Epoch 5810/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9837 - val_loss: 0.6622 - val_acc: 0.7314\n",
      "Epoch 5811/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6606 - val_acc: 0.7299\n",
      "Epoch 5812/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9840 - val_loss: 0.6617 - val_acc: 0.7314\n",
      "Epoch 5813/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6608 - val_acc: 0.7295\n",
      "Epoch 5814/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6617 - val_acc: 0.7266\n",
      "Epoch 5815/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9822 - val_loss: 0.6618 - val_acc: 0.7284\n",
      "Epoch 5816/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3060 - acc: 0.9816 - val_loss: 0.6610 - val_acc: 0.7299\n",
      "Epoch 5817/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6613 - val_acc: 0.7273\n",
      "Epoch 5818/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9827 - val_loss: 0.6623 - val_acc: 0.7288\n",
      "Epoch 5819/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9828 - val_loss: 0.6615 - val_acc: 0.7303\n",
      "Epoch 5820/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6627 - val_acc: 0.7317\n",
      "Epoch 5821/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3060 - acc: 0.9811 - val_loss: 0.6629 - val_acc: 0.7332\n",
      "Epoch 5822/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9841 - val_loss: 0.6604 - val_acc: 0.7281\n",
      "Epoch 5823/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6621 - val_acc: 0.7314\n",
      "Epoch 5824/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9848 - val_loss: 0.6622 - val_acc: 0.7310\n",
      "Epoch 5825/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9833 - val_loss: 0.6613 - val_acc: 0.7306\n",
      "Epoch 5826/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9843 - val_loss: 0.6615 - val_acc: 0.7317\n",
      "Epoch 5827/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9833 - val_loss: 0.6637 - val_acc: 0.7325\n",
      "Epoch 5828/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6646 - val_acc: 0.7292\n",
      "Epoch 5829/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6639 - val_acc: 0.7281\n",
      "Epoch 5830/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6634 - val_acc: 0.7292\n",
      "Epoch 5831/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9826 - val_loss: 0.6620 - val_acc: 0.7303\n",
      "Epoch 5832/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9823 - val_loss: 0.6644 - val_acc: 0.7317\n",
      "Epoch 5833/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9821 - val_loss: 0.6617 - val_acc: 0.7343\n",
      "Epoch 5834/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9831 - val_loss: 0.6630 - val_acc: 0.7314\n",
      "Epoch 5835/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9830 - val_loss: 0.6616 - val_acc: 0.7332\n",
      "Epoch 5836/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3115 - acc: 0.9695 - val_loss: 0.6730 - val_acc: 0.7255\n",
      "Epoch 5837/10000\n",
      "4259/4259 [==============================] - 2s 514us/step - loss: 0.3109 - acc: 0.9663 - val_loss: 0.6666 - val_acc: 0.7306\n",
      "Epoch 5838/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3080 - acc: 0.9743 - val_loss: 0.6636 - val_acc: 0.7248\n",
      "Epoch 5839/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3070 - acc: 0.9760 - val_loss: 0.6652 - val_acc: 0.7270\n",
      "Epoch 5840/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3066 - acc: 0.9784 - val_loss: 0.6639 - val_acc: 0.7248\n",
      "Epoch 5841/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3064 - acc: 0.9796 - val_loss: 0.6640 - val_acc: 0.7226\n",
      "Epoch 5842/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3063 - acc: 0.9812 - val_loss: 0.6641 - val_acc: 0.7230\n",
      "Epoch 5843/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3062 - acc: 0.9813 - val_loss: 0.6635 - val_acc: 0.7226\n",
      "Epoch 5844/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6637 - val_acc: 0.7259\n",
      "Epoch 5845/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6635 - val_acc: 0.7259\n",
      "Epoch 5846/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3061 - acc: 0.9826 - val_loss: 0.6623 - val_acc: 0.7262\n",
      "Epoch 5847/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6617 - val_acc: 0.7248\n",
      "Epoch 5848/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6617 - val_acc: 0.7240\n",
      "Epoch 5849/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6618 - val_acc: 0.7244\n",
      "Epoch 5850/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3060 - acc: 0.9834 - val_loss: 0.6612 - val_acc: 0.7244\n",
      "Epoch 5851/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3060 - acc: 0.9839 - val_loss: 0.6614 - val_acc: 0.7251\n",
      "Epoch 5852/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6610 - val_acc: 0.7251\n",
      "Epoch 5853/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6609 - val_acc: 0.7273\n",
      "Epoch 5854/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6610 - val_acc: 0.7248\n",
      "Epoch 5855/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6609 - val_acc: 0.7244\n",
      "Epoch 5856/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6606 - val_acc: 0.7259\n",
      "Epoch 5857/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6602 - val_acc: 0.7270\n",
      "Epoch 5858/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6607 - val_acc: 0.7255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5859/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6601 - val_acc: 0.7259\n",
      "Epoch 5860/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6607 - val_acc: 0.7255\n",
      "Epoch 5861/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6605 - val_acc: 0.7233\n",
      "Epoch 5862/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9852 - val_loss: 0.6612 - val_acc: 0.7251\n",
      "Epoch 5863/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6606 - val_acc: 0.7240\n",
      "Epoch 5864/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9850 - val_loss: 0.6608 - val_acc: 0.7251\n",
      "Epoch 5865/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9849 - val_loss: 0.6607 - val_acc: 0.7270\n",
      "Epoch 5866/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9858 - val_loss: 0.6609 - val_acc: 0.7251\n",
      "Epoch 5867/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6618 - val_acc: 0.7259\n",
      "Epoch 5868/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6612 - val_acc: 0.7262\n",
      "Epoch 5869/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6621 - val_acc: 0.7266\n",
      "Epoch 5870/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6613 - val_acc: 0.7244\n",
      "Epoch 5871/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6632 - val_acc: 0.7262\n",
      "Epoch 5872/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9835 - val_loss: 0.6610 - val_acc: 0.7255\n",
      "Epoch 5873/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6612 - val_acc: 0.7266\n",
      "Epoch 5874/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6616 - val_acc: 0.7251\n",
      "Epoch 5875/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6611 - val_acc: 0.7244\n",
      "Epoch 5876/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3061 - acc: 0.9830 - val_loss: 0.6599 - val_acc: 0.7240\n",
      "Epoch 5877/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6614 - val_acc: 0.7226\n",
      "Epoch 5878/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3061 - acc: 0.9824 - val_loss: 0.6604 - val_acc: 0.7277\n",
      "Epoch 5879/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6585 - val_acc: 0.7255\n",
      "Epoch 5880/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6602 - val_acc: 0.7281\n",
      "Epoch 5881/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9831 - val_loss: 0.6607 - val_acc: 0.7262\n",
      "Epoch 5882/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6588 - val_acc: 0.7273\n",
      "Epoch 5883/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6606 - val_acc: 0.7270\n",
      "Epoch 5884/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6582 - val_acc: 0.7262\n",
      "Epoch 5885/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6582 - val_acc: 0.7259\n",
      "Epoch 5886/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3062 - acc: 0.9819 - val_loss: 0.6597 - val_acc: 0.7255\n",
      "Epoch 5887/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3065 - acc: 0.9800 - val_loss: 0.6607 - val_acc: 0.7295\n",
      "Epoch 5888/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3063 - acc: 0.9786 - val_loss: 0.6614 - val_acc: 0.7248\n",
      "Epoch 5889/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6583 - val_acc: 0.7251\n",
      "Epoch 5890/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9843 - val_loss: 0.6591 - val_acc: 0.7248\n",
      "Epoch 5891/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6587 - val_acc: 0.7277\n",
      "Epoch 5892/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9854 - val_loss: 0.6590 - val_acc: 0.7251\n",
      "Epoch 5893/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9849 - val_loss: 0.6584 - val_acc: 0.7262\n",
      "Epoch 5894/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3060 - acc: 0.9844 - val_loss: 0.6601 - val_acc: 0.7255\n",
      "Epoch 5895/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9851 - val_loss: 0.6601 - val_acc: 0.7284\n",
      "Epoch 5896/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3060 - acc: 0.9839 - val_loss: 0.6602 - val_acc: 0.7230\n",
      "Epoch 5897/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3060 - acc: 0.9842 - val_loss: 0.6596 - val_acc: 0.7266\n",
      "Epoch 5898/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3060 - acc: 0.9838 - val_loss: 0.6590 - val_acc: 0.7255\n",
      "Epoch 5899/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3061 - acc: 0.9838 - val_loss: 0.6570 - val_acc: 0.7259\n",
      "Epoch 5900/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9829 - val_loss: 0.6586 - val_acc: 0.7262\n",
      "Epoch 5901/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3062 - acc: 0.9820 - val_loss: 0.6603 - val_acc: 0.7255\n",
      "Epoch 5902/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3062 - acc: 0.9809 - val_loss: 0.6597 - val_acc: 0.7273\n",
      "Epoch 5903/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3061 - acc: 0.9816 - val_loss: 0.6588 - val_acc: 0.7262\n",
      "Epoch 5904/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6579 - val_acc: 0.7262\n",
      "Epoch 5905/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3062 - acc: 0.9822 - val_loss: 0.6597 - val_acc: 0.7240\n",
      "Epoch 5906/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6568 - val_acc: 0.7248\n",
      "Epoch 5907/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6575 - val_acc: 0.7259\n",
      "Epoch 5908/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6586 - val_acc: 0.7255\n",
      "Epoch 5909/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3060 - acc: 0.9845 - val_loss: 0.6572 - val_acc: 0.7237\n",
      "Epoch 5910/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6563 - val_acc: 0.7284\n",
      "Epoch 5911/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9822 - val_loss: 0.6589 - val_acc: 0.7284\n",
      "Epoch 5912/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6593 - val_acc: 0.7295\n",
      "Epoch 5913/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3075 - acc: 0.9756 - val_loss: 0.6611 - val_acc: 0.7240\n",
      "Epoch 5914/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3121 - acc: 0.9695 - val_loss: 0.6638 - val_acc: 0.7200\n",
      "Epoch 5915/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3134 - acc: 0.9664 - val_loss: 0.6764 - val_acc: 0.7314\n",
      "Epoch 5916/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3106 - acc: 0.9711 - val_loss: 0.6751 - val_acc: 0.7270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5917/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3101 - acc: 0.9725 - val_loss: 0.6709 - val_acc: 0.7284\n",
      "Epoch 5918/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3090 - acc: 0.9754 - val_loss: 0.6687 - val_acc: 0.7270\n",
      "Epoch 5919/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3090 - acc: 0.9734 - val_loss: 0.6708 - val_acc: 0.7277\n",
      "Epoch 5920/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3077 - acc: 0.9751 - val_loss: 0.6690 - val_acc: 0.7240\n",
      "Epoch 5921/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3071 - acc: 0.9778 - val_loss: 0.6698 - val_acc: 0.7266\n",
      "Epoch 5922/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3067 - acc: 0.9784 - val_loss: 0.6688 - val_acc: 0.7270\n",
      "Epoch 5923/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3065 - acc: 0.9789 - val_loss: 0.6685 - val_acc: 0.7259\n",
      "Epoch 5924/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3064 - acc: 0.9793 - val_loss: 0.6682 - val_acc: 0.7248\n",
      "Epoch 5925/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3063 - acc: 0.9804 - val_loss: 0.6682 - val_acc: 0.7248\n",
      "Epoch 5926/10000\n",
      "4259/4259 [==============================] - 2s 499us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6676 - val_acc: 0.7259\n",
      "Epoch 5927/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3062 - acc: 0.9817 - val_loss: 0.6673 - val_acc: 0.7266\n",
      "Epoch 5928/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3061 - acc: 0.9821 - val_loss: 0.6673 - val_acc: 0.7259\n",
      "Epoch 5929/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3061 - acc: 0.9825 - val_loss: 0.6676 - val_acc: 0.7288\n",
      "Epoch 5930/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3061 - acc: 0.9827 - val_loss: 0.6668 - val_acc: 0.7270\n",
      "Epoch 5931/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6668 - val_acc: 0.7270\n",
      "Epoch 5932/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3060 - acc: 0.9838 - val_loss: 0.6667 - val_acc: 0.7273\n",
      "Epoch 5933/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3060 - acc: 0.9840 - val_loss: 0.6671 - val_acc: 0.7284\n",
      "Epoch 5934/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3060 - acc: 0.9846 - val_loss: 0.6665 - val_acc: 0.7273\n",
      "Epoch 5935/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3060 - acc: 0.9842 - val_loss: 0.6667 - val_acc: 0.7284\n",
      "Epoch 5936/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3059 - acc: 0.9844 - val_loss: 0.6669 - val_acc: 0.7273\n",
      "Epoch 5937/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6670 - val_acc: 0.7273\n",
      "Epoch 5938/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3059 - acc: 0.9846 - val_loss: 0.6666 - val_acc: 0.7273\n",
      "Epoch 5939/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6668 - val_acc: 0.7273\n",
      "Epoch 5940/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6668 - val_acc: 0.7281\n",
      "Epoch 5941/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6668 - val_acc: 0.7262\n",
      "Epoch 5942/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6667 - val_acc: 0.7262\n",
      "Epoch 5943/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3059 - acc: 0.9853 - val_loss: 0.6666 - val_acc: 0.7251\n",
      "Epoch 5944/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3059 - acc: 0.9865 - val_loss: 0.6668 - val_acc: 0.7255\n",
      "Epoch 5945/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6672 - val_acc: 0.7255\n",
      "Epoch 5946/10000\n",
      "4259/4259 [==============================] - 2s 499us/step - loss: 0.3058 - acc: 0.9853 - val_loss: 0.6666 - val_acc: 0.7277\n",
      "Epoch 5947/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3058 - acc: 0.9861 - val_loss: 0.6668 - val_acc: 0.7266\n",
      "Epoch 5948/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3058 - acc: 0.9849 - val_loss: 0.6667 - val_acc: 0.7259\n",
      "Epoch 5949/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3058 - acc: 0.9856 - val_loss: 0.6670 - val_acc: 0.7262\n",
      "Epoch 5950/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3058 - acc: 0.9865 - val_loss: 0.6673 - val_acc: 0.7255\n",
      "Epoch 5951/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3058 - acc: 0.9860 - val_loss: 0.6668 - val_acc: 0.7273\n",
      "Epoch 5952/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3058 - acc: 0.9862 - val_loss: 0.6666 - val_acc: 0.7262\n",
      "Epoch 5953/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3058 - acc: 0.9859 - val_loss: 0.6669 - val_acc: 0.7251\n",
      "Epoch 5954/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3058 - acc: 0.9863 - val_loss: 0.6669 - val_acc: 0.7259\n",
      "Epoch 5955/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3058 - acc: 0.9857 - val_loss: 0.6664 - val_acc: 0.7262\n",
      "Epoch 5956/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6671 - val_acc: 0.7251\n",
      "Epoch 5957/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9851 - val_loss: 0.6688 - val_acc: 0.7248\n",
      "Epoch 5958/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6675 - val_acc: 0.7251\n",
      "Epoch 5959/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3069 - acc: 0.9811 - val_loss: 0.6634 - val_acc: 0.7346\n",
      "Epoch 5960/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3099 - acc: 0.9689 - val_loss: 0.6707 - val_acc: 0.7255\n",
      "Epoch 5961/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3077 - acc: 0.9752 - val_loss: 0.6712 - val_acc: 0.7281\n",
      "Epoch 5962/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3068 - acc: 0.9787 - val_loss: 0.6711 - val_acc: 0.7284\n",
      "Epoch 5963/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3063 - acc: 0.9787 - val_loss: 0.6697 - val_acc: 0.7295\n",
      "Epoch 5964/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6700 - val_acc: 0.7306\n",
      "Epoch 5965/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9827 - val_loss: 0.6695 - val_acc: 0.7295\n",
      "Epoch 5966/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6697 - val_acc: 0.7306\n",
      "Epoch 5967/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6695 - val_acc: 0.7262\n",
      "Epoch 5968/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6696 - val_acc: 0.7259\n",
      "Epoch 5969/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3058 - acc: 0.9840 - val_loss: 0.6693 - val_acc: 0.7288\n",
      "Epoch 5970/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6696 - val_acc: 0.7273\n",
      "Epoch 5971/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6692 - val_acc: 0.7266\n",
      "Epoch 5972/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6695 - val_acc: 0.7262\n",
      "Epoch 5973/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6694 - val_acc: 0.7259\n",
      "Epoch 5974/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9860 - val_loss: 0.6692 - val_acc: 0.7255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5975/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9859 - val_loss: 0.6691 - val_acc: 0.7255\n",
      "Epoch 5976/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3058 - acc: 0.9861 - val_loss: 0.6688 - val_acc: 0.7266\n",
      "Epoch 5977/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3057 - acc: 0.9862 - val_loss: 0.6686 - val_acc: 0.7259\n",
      "Epoch 5978/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3057 - acc: 0.9861 - val_loss: 0.6688 - val_acc: 0.7259\n",
      "Epoch 5979/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3057 - acc: 0.9864 - val_loss: 0.6682 - val_acc: 0.7259\n",
      "Epoch 5980/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3057 - acc: 0.9866 - val_loss: 0.6682 - val_acc: 0.7262\n",
      "Epoch 5981/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3057 - acc: 0.9868 - val_loss: 0.6681 - val_acc: 0.7259\n",
      "Epoch 5982/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3057 - acc: 0.9868 - val_loss: 0.6683 - val_acc: 0.7270\n",
      "Epoch 5983/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9861 - val_loss: 0.6675 - val_acc: 0.7259\n",
      "Epoch 5984/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3057 - acc: 0.9863 - val_loss: 0.6680 - val_acc: 0.7240\n",
      "Epoch 5985/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3057 - acc: 0.9859 - val_loss: 0.6672 - val_acc: 0.7259\n",
      "Epoch 5986/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3057 - acc: 0.9861 - val_loss: 0.6683 - val_acc: 0.7259\n",
      "Epoch 5987/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6676 - val_acc: 0.7244\n",
      "Epoch 5988/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6665 - val_acc: 0.7248\n",
      "Epoch 5989/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9849 - val_loss: 0.6661 - val_acc: 0.7248\n",
      "Epoch 5990/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9840 - val_loss: 0.6664 - val_acc: 0.7251\n",
      "Epoch 5991/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6670 - val_acc: 0.7240\n",
      "Epoch 5992/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6661 - val_acc: 0.7270\n",
      "Epoch 5993/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6663 - val_acc: 0.7262\n",
      "Epoch 5994/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6651 - val_acc: 0.7255\n",
      "Epoch 5995/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6653 - val_acc: 0.7262\n",
      "Epoch 5996/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6646 - val_acc: 0.7270\n",
      "Epoch 5997/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6651 - val_acc: 0.7266\n",
      "Epoch 5998/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6639 - val_acc: 0.7270\n",
      "Epoch 5999/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6651 - val_acc: 0.7277\n",
      "Epoch 6000/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6648 - val_acc: 0.7259\n",
      "Epoch 6001/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6647 - val_acc: 0.7248\n",
      "Epoch 6002/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6642 - val_acc: 0.7281\n",
      "Epoch 6003/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3059 - acc: 0.9825 - val_loss: 0.6649 - val_acc: 0.7288\n",
      "Epoch 6004/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6611 - val_acc: 0.7262\n",
      "Epoch 6005/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6655 - val_acc: 0.7325\n",
      "Epoch 6006/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3081 - acc: 0.9746 - val_loss: 0.6631 - val_acc: 0.7288\n",
      "Epoch 6007/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3124 - acc: 0.9642 - val_loss: 0.6615 - val_acc: 0.7350\n",
      "Epoch 6008/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3077 - acc: 0.9734 - val_loss: 0.6705 - val_acc: 0.7295\n",
      "Epoch 6009/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3132 - acc: 0.9664 - val_loss: 0.6753 - val_acc: 0.7281\n",
      "Epoch 6010/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3112 - acc: 0.9685 - val_loss: 0.6708 - val_acc: 0.7310\n",
      "Epoch 6011/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3099 - acc: 0.9707 - val_loss: 0.6691 - val_acc: 0.7303\n",
      "Epoch 6012/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3080 - acc: 0.9753 - val_loss: 0.6682 - val_acc: 0.7303\n",
      "Epoch 6013/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3073 - acc: 0.9769 - val_loss: 0.6710 - val_acc: 0.7328\n",
      "Epoch 6014/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3069 - acc: 0.9781 - val_loss: 0.6703 - val_acc: 0.7350\n",
      "Epoch 6015/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3067 - acc: 0.9782 - val_loss: 0.6698 - val_acc: 0.7339\n",
      "Epoch 6016/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3066 - acc: 0.9791 - val_loss: 0.6696 - val_acc: 0.7346\n",
      "Epoch 6017/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3065 - acc: 0.9795 - val_loss: 0.6689 - val_acc: 0.7346\n",
      "Epoch 6018/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3064 - acc: 0.9795 - val_loss: 0.6685 - val_acc: 0.7339\n",
      "Epoch 6019/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3063 - acc: 0.9806 - val_loss: 0.6686 - val_acc: 0.7336\n",
      "Epoch 6020/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3063 - acc: 0.9810 - val_loss: 0.6683 - val_acc: 0.7321\n",
      "Epoch 6021/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3062 - acc: 0.9802 - val_loss: 0.6675 - val_acc: 0.7343\n",
      "Epoch 6022/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3062 - acc: 0.9820 - val_loss: 0.6670 - val_acc: 0.7350\n",
      "Epoch 6023/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3061 - acc: 0.9822 - val_loss: 0.6643 - val_acc: 0.7350\n",
      "Epoch 6024/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3061 - acc: 0.9820 - val_loss: 0.6644 - val_acc: 0.7350\n",
      "Epoch 6025/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6644 - val_acc: 0.7332\n",
      "Epoch 6026/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6647 - val_acc: 0.7346\n",
      "Epoch 6027/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9833 - val_loss: 0.6644 - val_acc: 0.7357\n",
      "Epoch 6028/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6643 - val_acc: 0.7343\n",
      "Epoch 6029/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6646 - val_acc: 0.7361\n",
      "Epoch 6030/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9829 - val_loss: 0.6643 - val_acc: 0.7343\n",
      "Epoch 6031/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6639 - val_acc: 0.7354\n",
      "Epoch 6032/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6641 - val_acc: 0.7343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6033/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6639 - val_acc: 0.7346\n",
      "Epoch 6034/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6639 - val_acc: 0.7350\n",
      "Epoch 6035/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6641 - val_acc: 0.7357\n",
      "Epoch 6036/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6640 - val_acc: 0.7357\n",
      "Epoch 6037/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6634 - val_acc: 0.7357\n",
      "Epoch 6038/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6631 - val_acc: 0.7354\n",
      "Epoch 6039/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9849 - val_loss: 0.6633 - val_acc: 0.7339\n",
      "Epoch 6040/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9856 - val_loss: 0.6632 - val_acc: 0.7368\n",
      "Epoch 6041/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6634 - val_acc: 0.7343\n",
      "Epoch 6042/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6630 - val_acc: 0.7357\n",
      "Epoch 6043/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6629 - val_acc: 0.7343\n",
      "Epoch 6044/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6629 - val_acc: 0.7346\n",
      "Epoch 6045/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6630 - val_acc: 0.7354\n",
      "Epoch 6046/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6630 - val_acc: 0.7343\n",
      "Epoch 6047/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9849 - val_loss: 0.6620 - val_acc: 0.7350\n",
      "Epoch 6048/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9849 - val_loss: 0.6618 - val_acc: 0.7339\n",
      "Epoch 6049/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6631 - val_acc: 0.7328\n",
      "Epoch 6050/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3064 - acc: 0.9808 - val_loss: 0.6679 - val_acc: 0.7343\n",
      "Epoch 6051/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3068 - acc: 0.9798 - val_loss: 0.6684 - val_acc: 0.7299\n",
      "Epoch 6052/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3078 - acc: 0.9755 - val_loss: 0.6726 - val_acc: 0.7251\n",
      "Epoch 6053/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3078 - acc: 0.9763 - val_loss: 0.6735 - val_acc: 0.7284\n",
      "Epoch 6054/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3076 - acc: 0.9746 - val_loss: 0.6722 - val_acc: 0.7288\n",
      "Epoch 6055/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3063 - acc: 0.9798 - val_loss: 0.6747 - val_acc: 0.7306\n",
      "Epoch 6056/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3060 - acc: 0.9815 - val_loss: 0.6736 - val_acc: 0.7325\n",
      "Epoch 6057/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9830 - val_loss: 0.6729 - val_acc: 0.7317\n",
      "Epoch 6058/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9830 - val_loss: 0.6728 - val_acc: 0.7295\n",
      "Epoch 6059/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9834 - val_loss: 0.6727 - val_acc: 0.7299\n",
      "Epoch 6060/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9840 - val_loss: 0.6729 - val_acc: 0.7299\n",
      "Epoch 6061/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9843 - val_loss: 0.6727 - val_acc: 0.7303\n",
      "Epoch 6062/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9846 - val_loss: 0.6731 - val_acc: 0.7299\n",
      "Epoch 6063/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6725 - val_acc: 0.7303\n",
      "Epoch 6064/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9836 - val_loss: 0.6705 - val_acc: 0.7306\n",
      "Epoch 6065/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9842 - val_loss: 0.6720 - val_acc: 0.7310\n",
      "Epoch 6066/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9856 - val_loss: 0.6722 - val_acc: 0.7310\n",
      "Epoch 6067/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6721 - val_acc: 0.7292\n",
      "Epoch 6068/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3057 - acc: 0.9853 - val_loss: 0.6719 - val_acc: 0.7317\n",
      "Epoch 6069/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3057 - acc: 0.9858 - val_loss: 0.6713 - val_acc: 0.7295\n",
      "Epoch 6070/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3057 - acc: 0.9856 - val_loss: 0.6720 - val_acc: 0.7303\n",
      "Epoch 6071/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3057 - acc: 0.9862 - val_loss: 0.6712 - val_acc: 0.7303\n",
      "Epoch 6072/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3057 - acc: 0.9853 - val_loss: 0.6716 - val_acc: 0.7306\n",
      "Epoch 6073/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3057 - acc: 0.9860 - val_loss: 0.6712 - val_acc: 0.7317\n",
      "Epoch 6074/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3057 - acc: 0.9860 - val_loss: 0.6713 - val_acc: 0.7314\n",
      "Epoch 6075/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3057 - acc: 0.9861 - val_loss: 0.6711 - val_acc: 0.7310\n",
      "Epoch 6076/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9855 - val_loss: 0.6696 - val_acc: 0.7306\n",
      "Epoch 6077/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6701 - val_acc: 0.7310\n",
      "Epoch 6078/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3062 - acc: 0.9815 - val_loss: 0.6699 - val_acc: 0.7303\n",
      "Epoch 6079/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3063 - acc: 0.9797 - val_loss: 0.6673 - val_acc: 0.7321\n",
      "Epoch 6080/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9817 - val_loss: 0.6668 - val_acc: 0.7343\n",
      "Epoch 6081/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9822 - val_loss: 0.6671 - val_acc: 0.7325\n",
      "Epoch 6082/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9829 - val_loss: 0.6680 - val_acc: 0.7332\n",
      "Epoch 6083/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9833 - val_loss: 0.6674 - val_acc: 0.7332\n",
      "Epoch 6084/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9828 - val_loss: 0.6669 - val_acc: 0.7317\n",
      "Epoch 6085/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9838 - val_loss: 0.6678 - val_acc: 0.7336\n",
      "Epoch 6086/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9832 - val_loss: 0.6669 - val_acc: 0.7325\n",
      "Epoch 6087/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9831 - val_loss: 0.6667 - val_acc: 0.7325\n",
      "Epoch 6088/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9835 - val_loss: 0.6666 - val_acc: 0.7325\n",
      "Epoch 6089/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9822 - val_loss: 0.6679 - val_acc: 0.7325\n",
      "Epoch 6090/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9808 - val_loss: 0.6651 - val_acc: 0.7339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6091/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6676 - val_acc: 0.7321\n",
      "Epoch 6092/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9823 - val_loss: 0.6647 - val_acc: 0.7314\n",
      "Epoch 6093/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9815 - val_loss: 0.6656 - val_acc: 0.7321\n",
      "Epoch 6094/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3061 - acc: 0.9802 - val_loss: 0.6650 - val_acc: 0.7343\n",
      "Epoch 6095/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6647 - val_acc: 0.7361\n",
      "Epoch 6096/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6648 - val_acc: 0.7303\n",
      "Epoch 6097/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9829 - val_loss: 0.6651 - val_acc: 0.7325\n",
      "Epoch 6098/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9821 - val_loss: 0.6651 - val_acc: 0.7303\n",
      "Epoch 6099/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9823 - val_loss: 0.6665 - val_acc: 0.7306\n",
      "Epoch 6100/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9825 - val_loss: 0.6655 - val_acc: 0.7314\n",
      "Epoch 6101/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9820 - val_loss: 0.6640 - val_acc: 0.7310\n",
      "Epoch 6102/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9829 - val_loss: 0.6652 - val_acc: 0.7306\n",
      "Epoch 6103/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6626 - val_acc: 0.7306\n",
      "Epoch 6104/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9818 - val_loss: 0.6655 - val_acc: 0.7284\n",
      "Epoch 6105/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9812 - val_loss: 0.6648 - val_acc: 0.7346\n",
      "Epoch 6106/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9811 - val_loss: 0.6639 - val_acc: 0.7317\n",
      "Epoch 6107/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9816 - val_loss: 0.6625 - val_acc: 0.7295\n",
      "Epoch 6108/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3060 - acc: 0.9831 - val_loss: 0.6660 - val_acc: 0.7259\n",
      "Epoch 6109/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9805 - val_loss: 0.6659 - val_acc: 0.7328\n",
      "Epoch 6110/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3060 - acc: 0.9810 - val_loss: 0.6618 - val_acc: 0.7292\n",
      "Epoch 6111/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9804 - val_loss: 0.6633 - val_acc: 0.7270\n",
      "Epoch 6112/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3060 - acc: 0.9823 - val_loss: 0.6624 - val_acc: 0.7321\n",
      "Epoch 6113/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3060 - acc: 0.9814 - val_loss: 0.6669 - val_acc: 0.7310\n",
      "Epoch 6114/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3059 - acc: 0.9825 - val_loss: 0.6639 - val_acc: 0.7303\n",
      "Epoch 6115/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9813 - val_loss: 0.6636 - val_acc: 0.7314\n",
      "Epoch 6116/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9825 - val_loss: 0.6612 - val_acc: 0.7295\n",
      "Epoch 6117/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9819 - val_loss: 0.6624 - val_acc: 0.7281\n",
      "Epoch 6118/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3059 - acc: 0.9831 - val_loss: 0.6622 - val_acc: 0.7292\n",
      "Epoch 6119/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9820 - val_loss: 0.6636 - val_acc: 0.7270\n",
      "Epoch 6120/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9817 - val_loss: 0.6624 - val_acc: 0.7328\n",
      "Epoch 6121/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9815 - val_loss: 0.6636 - val_acc: 0.7284\n",
      "Epoch 6122/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9803 - val_loss: 0.6635 - val_acc: 0.7332\n",
      "Epoch 6123/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9808 - val_loss: 0.6636 - val_acc: 0.7284\n",
      "Epoch 6124/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9813 - val_loss: 0.6623 - val_acc: 0.7310\n",
      "Epoch 6125/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9807 - val_loss: 0.6619 - val_acc: 0.7325\n",
      "Epoch 6126/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9817 - val_loss: 0.6605 - val_acc: 0.7277\n",
      "Epoch 6127/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9791 - val_loss: 0.6620 - val_acc: 0.7325\n",
      "Epoch 6128/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9819 - val_loss: 0.6623 - val_acc: 0.7317\n",
      "Epoch 6129/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9809 - val_loss: 0.6608 - val_acc: 0.7262\n",
      "Epoch 6130/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3063 - acc: 0.9797 - val_loss: 0.6582 - val_acc: 0.7284\n",
      "Epoch 6131/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3093 - acc: 0.9688 - val_loss: 0.6682 - val_acc: 0.7284\n",
      "Epoch 6132/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3092 - acc: 0.9674 - val_loss: 0.6712 - val_acc: 0.7317\n",
      "Epoch 6133/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3072 - acc: 0.9740 - val_loss: 0.6610 - val_acc: 0.7332\n",
      "Epoch 6134/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3066 - acc: 0.9775 - val_loss: 0.6656 - val_acc: 0.7336\n",
      "Epoch 6135/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3063 - acc: 0.9786 - val_loss: 0.6639 - val_acc: 0.7346\n",
      "Epoch 6136/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3061 - acc: 0.9796 - val_loss: 0.6636 - val_acc: 0.7343\n",
      "Epoch 6137/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6639 - val_acc: 0.7343\n",
      "Epoch 6138/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9811 - val_loss: 0.6638 - val_acc: 0.7361\n",
      "Epoch 6139/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9825 - val_loss: 0.6633 - val_acc: 0.7339\n",
      "Epoch 6140/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9826 - val_loss: 0.6630 - val_acc: 0.7350\n",
      "Epoch 6141/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6626 - val_acc: 0.7372\n",
      "Epoch 6142/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9838 - val_loss: 0.6625 - val_acc: 0.7365\n",
      "Epoch 6143/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9844 - val_loss: 0.6620 - val_acc: 0.7368\n",
      "Epoch 6144/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9839 - val_loss: 0.6625 - val_acc: 0.7383\n",
      "Epoch 6145/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9840 - val_loss: 0.6626 - val_acc: 0.7372\n",
      "Epoch 6146/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6626 - val_acc: 0.7365\n",
      "Epoch 6147/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3058 - acc: 0.9848 - val_loss: 0.6623 - val_acc: 0.7365\n",
      "Epoch 6148/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6621 - val_acc: 0.7354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6149/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9848 - val_loss: 0.6622 - val_acc: 0.7361\n",
      "Epoch 6150/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9840 - val_loss: 0.6604 - val_acc: 0.7292\n",
      "Epoch 6151/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9825 - val_loss: 0.6598 - val_acc: 0.7350\n",
      "Epoch 6152/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9843 - val_loss: 0.6597 - val_acc: 0.7346\n",
      "Epoch 6153/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6598 - val_acc: 0.7350\n",
      "Epoch 6154/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9843 - val_loss: 0.6593 - val_acc: 0.7357\n",
      "Epoch 6155/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9845 - val_loss: 0.6596 - val_acc: 0.7346\n",
      "Epoch 6156/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9853 - val_loss: 0.6599 - val_acc: 0.7350\n",
      "Epoch 6157/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6602 - val_acc: 0.7350\n",
      "Epoch 6158/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6607 - val_acc: 0.7357\n",
      "Epoch 6159/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3057 - acc: 0.9858 - val_loss: 0.6603 - val_acc: 0.7350\n",
      "Epoch 6160/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9848 - val_loss: 0.6609 - val_acc: 0.7354\n",
      "Epoch 6161/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6608 - val_acc: 0.7354\n",
      "Epoch 6162/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6605 - val_acc: 0.7339\n",
      "Epoch 6163/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9843 - val_loss: 0.6608 - val_acc: 0.7328\n",
      "Epoch 6164/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6593 - val_acc: 0.7332\n",
      "Epoch 6165/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9829 - val_loss: 0.6606 - val_acc: 0.7350\n",
      "Epoch 6166/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9825 - val_loss: 0.6612 - val_acc: 0.7336\n",
      "Epoch 6167/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9822 - val_loss: 0.6603 - val_acc: 0.7306\n",
      "Epoch 6168/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9820 - val_loss: 0.6602 - val_acc: 0.7365\n",
      "Epoch 6169/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9828 - val_loss: 0.6590 - val_acc: 0.7361\n",
      "Epoch 6170/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9821 - val_loss: 0.6606 - val_acc: 0.7346\n",
      "Epoch 6171/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9831 - val_loss: 0.6593 - val_acc: 0.7317\n",
      "Epoch 6172/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9832 - val_loss: 0.6586 - val_acc: 0.7361\n",
      "Epoch 6173/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9823 - val_loss: 0.6593 - val_acc: 0.7310\n",
      "Epoch 6174/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9827 - val_loss: 0.6582 - val_acc: 0.7343\n",
      "Epoch 6175/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9827 - val_loss: 0.6576 - val_acc: 0.7339\n",
      "Epoch 6176/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3059 - acc: 0.9829 - val_loss: 0.6580 - val_acc: 0.7350\n",
      "Epoch 6177/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3059 - acc: 0.9819 - val_loss: 0.6570 - val_acc: 0.7332\n",
      "Epoch 6178/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9825 - val_loss: 0.6580 - val_acc: 0.7314\n",
      "Epoch 6179/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9822 - val_loss: 0.6572 - val_acc: 0.7325\n",
      "Epoch 6180/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6576 - val_acc: 0.7332\n",
      "Epoch 6181/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6574 - val_acc: 0.7339\n",
      "Epoch 6182/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9818 - val_loss: 0.6566 - val_acc: 0.7336\n",
      "Epoch 6183/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9815 - val_loss: 0.6556 - val_acc: 0.7339\n",
      "Epoch 6184/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9828 - val_loss: 0.6586 - val_acc: 0.7325\n",
      "Epoch 6185/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9817 - val_loss: 0.6562 - val_acc: 0.7350\n",
      "Epoch 6186/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9825 - val_loss: 0.6580 - val_acc: 0.7325\n",
      "Epoch 6187/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3061 - acc: 0.9815 - val_loss: 0.6561 - val_acc: 0.7325\n",
      "Epoch 6188/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3085 - acc: 0.9717 - val_loss: 0.6677 - val_acc: 0.7303\n",
      "Epoch 6189/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3084 - acc: 0.9755 - val_loss: 0.6637 - val_acc: 0.7292\n",
      "Epoch 6190/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3082 - acc: 0.9775 - val_loss: 0.6626 - val_acc: 0.7306\n",
      "Epoch 6191/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3077 - acc: 0.9782 - val_loss: 0.6621 - val_acc: 0.7321\n",
      "Epoch 6192/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3064 - acc: 0.9808 - val_loss: 0.6609 - val_acc: 0.7328\n",
      "Epoch 6193/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3061 - acc: 0.9819 - val_loss: 0.6610 - val_acc: 0.7357\n",
      "Epoch 6194/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6615 - val_acc: 0.7357\n",
      "Epoch 6195/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9832 - val_loss: 0.6615 - val_acc: 0.7361\n",
      "Epoch 6196/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6618 - val_acc: 0.7361\n",
      "Epoch 6197/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6620 - val_acc: 0.7357\n",
      "Epoch 6198/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3059 - acc: 0.9843 - val_loss: 0.6614 - val_acc: 0.7361\n",
      "Epoch 6199/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9849 - val_loss: 0.6618 - val_acc: 0.7357\n",
      "Epoch 6200/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6612 - val_acc: 0.7354\n",
      "Epoch 6201/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6615 - val_acc: 0.7365\n",
      "Epoch 6202/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9853 - val_loss: 0.6613 - val_acc: 0.7361\n",
      "Epoch 6203/10000\n",
      "4259/4259 [==============================] - 2s 503us/step - loss: 0.3058 - acc: 0.9861 - val_loss: 0.6614 - val_acc: 0.7372\n",
      "Epoch 6204/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6614 - val_acc: 0.7368\n",
      "Epoch 6205/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9859 - val_loss: 0.6612 - val_acc: 0.7361\n",
      "Epoch 6206/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9864 - val_loss: 0.6607 - val_acc: 0.7372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6207/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9860 - val_loss: 0.6608 - val_acc: 0.7361\n",
      "Epoch 6208/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9872 - val_loss: 0.6607 - val_acc: 0.7379\n",
      "Epoch 6209/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9869 - val_loss: 0.6606 - val_acc: 0.7368\n",
      "Epoch 6210/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3058 - acc: 0.9861 - val_loss: 0.6608 - val_acc: 0.7365\n",
      "Epoch 6211/10000\n",
      "4259/4259 [==============================] - 2s 500us/step - loss: 0.3058 - acc: 0.9861 - val_loss: 0.6602 - val_acc: 0.7365\n",
      "Epoch 6212/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3057 - acc: 0.9862 - val_loss: 0.6607 - val_acc: 0.7372\n",
      "Epoch 6213/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9865 - val_loss: 0.6601 - val_acc: 0.7372\n",
      "Epoch 6214/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9866 - val_loss: 0.6609 - val_acc: 0.7365\n",
      "Epoch 6215/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9855 - val_loss: 0.6609 - val_acc: 0.7361\n",
      "Epoch 6216/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6617 - val_acc: 0.7387\n",
      "Epoch 6217/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9849 - val_loss: 0.6615 - val_acc: 0.7346\n",
      "Epoch 6218/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6598 - val_acc: 0.7346\n",
      "Epoch 6219/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3059 - acc: 0.9834 - val_loss: 0.6616 - val_acc: 0.7354\n",
      "Epoch 6220/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6600 - val_acc: 0.7357\n",
      "Epoch 6221/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6608 - val_acc: 0.7336\n",
      "Epoch 6222/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9829 - val_loss: 0.6588 - val_acc: 0.7357\n",
      "Epoch 6223/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9821 - val_loss: 0.6601 - val_acc: 0.7354\n",
      "Epoch 6224/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9836 - val_loss: 0.6611 - val_acc: 0.7372\n",
      "Epoch 6225/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9831 - val_loss: 0.6601 - val_acc: 0.7350\n",
      "Epoch 6226/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6613 - val_acc: 0.7365\n",
      "Epoch 6227/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9829 - val_loss: 0.6613 - val_acc: 0.7372\n",
      "Epoch 6228/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9841 - val_loss: 0.6610 - val_acc: 0.7357\n",
      "Epoch 6229/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3058 - acc: 0.9848 - val_loss: 0.6624 - val_acc: 0.7361\n",
      "Epoch 6230/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6618 - val_acc: 0.7365\n",
      "Epoch 6231/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6583 - val_acc: 0.7368\n",
      "Epoch 6232/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6617 - val_acc: 0.7343\n",
      "Epoch 6233/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9837 - val_loss: 0.6610 - val_acc: 0.7372\n",
      "Epoch 6234/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6609 - val_acc: 0.7332\n",
      "Epoch 6235/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6606 - val_acc: 0.7368\n",
      "Epoch 6236/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9817 - val_loss: 0.6574 - val_acc: 0.7332\n",
      "Epoch 6237/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9822 - val_loss: 0.6597 - val_acc: 0.7354\n",
      "Epoch 6238/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3098 - acc: 0.9717 - val_loss: 0.6743 - val_acc: 0.7288\n",
      "Epoch 6239/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3128 - acc: 0.9639 - val_loss: 0.6746 - val_acc: 0.7321\n",
      "Epoch 6240/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3099 - acc: 0.9709 - val_loss: 0.6693 - val_acc: 0.7273\n",
      "Epoch 6241/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3094 - acc: 0.9714 - val_loss: 0.6719 - val_acc: 0.7354\n",
      "Epoch 6242/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3080 - acc: 0.9743 - val_loss: 0.6697 - val_acc: 0.7292\n",
      "Epoch 6243/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3075 - acc: 0.9764 - val_loss: 0.6668 - val_acc: 0.7325\n",
      "Epoch 6244/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3072 - acc: 0.9766 - val_loss: 0.6667 - val_acc: 0.7306\n",
      "Epoch 6245/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3070 - acc: 0.9771 - val_loss: 0.6663 - val_acc: 0.7317\n",
      "Epoch 6246/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3069 - acc: 0.9782 - val_loss: 0.6672 - val_acc: 0.7317\n",
      "Epoch 6247/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3068 - acc: 0.9787 - val_loss: 0.6675 - val_acc: 0.7303\n",
      "Epoch 6248/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3068 - acc: 0.9795 - val_loss: 0.6669 - val_acc: 0.7303\n",
      "Epoch 6249/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3067 - acc: 0.9808 - val_loss: 0.6669 - val_acc: 0.7314\n",
      "Epoch 6250/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3067 - acc: 0.9806 - val_loss: 0.6674 - val_acc: 0.7314\n",
      "Epoch 6251/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3067 - acc: 0.9811 - val_loss: 0.6668 - val_acc: 0.7299\n",
      "Epoch 6252/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3066 - acc: 0.9817 - val_loss: 0.6672 - val_acc: 0.7288\n",
      "Epoch 6253/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3066 - acc: 0.9819 - val_loss: 0.6672 - val_acc: 0.7306\n",
      "Epoch 6254/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3066 - acc: 0.9825 - val_loss: 0.6670 - val_acc: 0.7321\n",
      "Epoch 6255/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3065 - acc: 0.9829 - val_loss: 0.6670 - val_acc: 0.7306\n",
      "Epoch 6256/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3065 - acc: 0.9840 - val_loss: 0.6669 - val_acc: 0.7317\n",
      "Epoch 6257/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3065 - acc: 0.9829 - val_loss: 0.6669 - val_acc: 0.7303\n",
      "Epoch 6258/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3065 - acc: 0.9833 - val_loss: 0.6665 - val_acc: 0.7303\n",
      "Epoch 6259/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3065 - acc: 0.9834 - val_loss: 0.6670 - val_acc: 0.7303\n",
      "Epoch 6260/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3065 - acc: 0.9837 - val_loss: 0.6662 - val_acc: 0.7299\n",
      "Epoch 6261/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3065 - acc: 0.9843 - val_loss: 0.6668 - val_acc: 0.7310\n",
      "Epoch 6262/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3065 - acc: 0.9842 - val_loss: 0.6663 - val_acc: 0.7317\n",
      "Epoch 6263/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3065 - acc: 0.9840 - val_loss: 0.6660 - val_acc: 0.7321\n",
      "Epoch 6264/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3064 - acc: 0.9851 - val_loss: 0.6655 - val_acc: 0.7317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6265/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3064 - acc: 0.9843 - val_loss: 0.6656 - val_acc: 0.7314\n",
      "Epoch 6266/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3064 - acc: 0.9847 - val_loss: 0.6658 - val_acc: 0.7303\n",
      "Epoch 6267/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3064 - acc: 0.9850 - val_loss: 0.6654 - val_acc: 0.7314\n",
      "Epoch 6268/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3065 - acc: 0.9844 - val_loss: 0.6588 - val_acc: 0.7328\n",
      "Epoch 6269/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3064 - acc: 0.9843 - val_loss: 0.6603 - val_acc: 0.7317\n",
      "Epoch 6270/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3064 - acc: 0.9832 - val_loss: 0.6631 - val_acc: 0.7321\n",
      "Epoch 6271/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3064 - acc: 0.9835 - val_loss: 0.6645 - val_acc: 0.7336\n",
      "Epoch 6272/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3064 - acc: 0.9837 - val_loss: 0.6633 - val_acc: 0.7310\n",
      "Epoch 6273/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3063 - acc: 0.9851 - val_loss: 0.6628 - val_acc: 0.7317\n",
      "Epoch 6274/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3063 - acc: 0.9843 - val_loss: 0.6628 - val_acc: 0.7310\n",
      "Epoch 6275/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3063 - acc: 0.9852 - val_loss: 0.6625 - val_acc: 0.7332\n",
      "Epoch 6276/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3063 - acc: 0.9846 - val_loss: 0.6623 - val_acc: 0.7303\n",
      "Epoch 6277/10000\n",
      "4259/4259 [==============================] - 2s 483us/step - loss: 0.3063 - acc: 0.9853 - val_loss: 0.6629 - val_acc: 0.7317\n",
      "Epoch 6278/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3063 - acc: 0.9847 - val_loss: 0.6629 - val_acc: 0.7321\n",
      "Epoch 6279/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3063 - acc: 0.9847 - val_loss: 0.6628 - val_acc: 0.7343\n",
      "Epoch 6280/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3063 - acc: 0.9852 - val_loss: 0.6628 - val_acc: 0.7317\n",
      "Epoch 6281/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3063 - acc: 0.9838 - val_loss: 0.6632 - val_acc: 0.7332\n",
      "Epoch 6282/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3064 - acc: 0.9840 - val_loss: 0.6617 - val_acc: 0.7299\n",
      "Epoch 6283/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3064 - acc: 0.9833 - val_loss: 0.6625 - val_acc: 0.7306\n",
      "Epoch 6284/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3064 - acc: 0.9834 - val_loss: 0.6635 - val_acc: 0.7310\n",
      "Epoch 6285/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3064 - acc: 0.9840 - val_loss: 0.6614 - val_acc: 0.7321\n",
      "Epoch 6286/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3065 - acc: 0.9829 - val_loss: 0.6613 - val_acc: 0.7299\n",
      "Epoch 6287/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3072 - acc: 0.9801 - val_loss: 0.6687 - val_acc: 0.7288\n",
      "Epoch 6288/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3128 - acc: 0.9668 - val_loss: 0.6761 - val_acc: 0.7270\n",
      "Epoch 6289/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3101 - acc: 0.9705 - val_loss: 0.6772 - val_acc: 0.7244\n",
      "Epoch 6290/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3086 - acc: 0.9749 - val_loss: 0.6733 - val_acc: 0.7237\n",
      "Epoch 6291/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3078 - acc: 0.9769 - val_loss: 0.6723 - val_acc: 0.7255\n",
      "Epoch 6292/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3074 - acc: 0.9785 - val_loss: 0.6737 - val_acc: 0.7262\n",
      "Epoch 6293/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3072 - acc: 0.9797 - val_loss: 0.6727 - val_acc: 0.7284\n",
      "Epoch 6294/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3070 - acc: 0.9809 - val_loss: 0.6738 - val_acc: 0.7277\n",
      "Epoch 6295/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3069 - acc: 0.9814 - val_loss: 0.6734 - val_acc: 0.7288\n",
      "Epoch 6296/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3069 - acc: 0.9828 - val_loss: 0.6729 - val_acc: 0.7281\n",
      "Epoch 6297/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3068 - acc: 0.9831 - val_loss: 0.6739 - val_acc: 0.7262\n",
      "Epoch 6298/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3068 - acc: 0.9828 - val_loss: 0.6734 - val_acc: 0.7281\n",
      "Epoch 6299/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3068 - acc: 0.9840 - val_loss: 0.6736 - val_acc: 0.7277\n",
      "Epoch 6300/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3067 - acc: 0.9840 - val_loss: 0.6735 - val_acc: 0.7273\n",
      "Epoch 6301/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3067 - acc: 0.9842 - val_loss: 0.6736 - val_acc: 0.7273\n",
      "Epoch 6302/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3067 - acc: 0.9843 - val_loss: 0.6744 - val_acc: 0.7273\n",
      "Epoch 6303/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3067 - acc: 0.9850 - val_loss: 0.6742 - val_acc: 0.7277\n",
      "Epoch 6304/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3067 - acc: 0.9846 - val_loss: 0.6743 - val_acc: 0.7281\n",
      "Epoch 6305/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3067 - acc: 0.9848 - val_loss: 0.6740 - val_acc: 0.7288\n",
      "Epoch 6306/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3067 - acc: 0.9847 - val_loss: 0.6741 - val_acc: 0.7266\n",
      "Epoch 6307/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3066 - acc: 0.9847 - val_loss: 0.6742 - val_acc: 0.7277\n",
      "Epoch 6308/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3066 - acc: 0.9849 - val_loss: 0.6746 - val_acc: 0.7273\n",
      "Epoch 6309/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3066 - acc: 0.9853 - val_loss: 0.6746 - val_acc: 0.7270\n",
      "Epoch 6310/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3066 - acc: 0.9851 - val_loss: 0.6749 - val_acc: 0.7292\n",
      "Epoch 6311/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3066 - acc: 0.9857 - val_loss: 0.6746 - val_acc: 0.7281\n",
      "Epoch 6312/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3066 - acc: 0.9857 - val_loss: 0.6749 - val_acc: 0.7273\n",
      "Epoch 6313/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3066 - acc: 0.9860 - val_loss: 0.6754 - val_acc: 0.7281\n",
      "Epoch 6314/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3066 - acc: 0.9860 - val_loss: 0.6752 - val_acc: 0.7281\n",
      "Epoch 6315/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3066 - acc: 0.9851 - val_loss: 0.6755 - val_acc: 0.7277\n",
      "Epoch 6316/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3066 - acc: 0.9859 - val_loss: 0.6752 - val_acc: 0.7266\n",
      "Epoch 6317/10000\n",
      "4259/4259 [==============================] - 2s 545us/step - loss: 0.3066 - acc: 0.9860 - val_loss: 0.6753 - val_acc: 0.7284\n",
      "Epoch 6318/10000\n",
      "4259/4259 [==============================] - 2s 505us/step - loss: 0.3066 - acc: 0.9865 - val_loss: 0.6751 - val_acc: 0.7262\n",
      "Epoch 6319/10000\n",
      "4259/4259 [==============================] - 2s 504us/step - loss: 0.3066 - acc: 0.9861 - val_loss: 0.6753 - val_acc: 0.7266\n",
      "Epoch 6320/10000\n",
      "4259/4259 [==============================] - 2s 506us/step - loss: 0.3066 - acc: 0.9853 - val_loss: 0.6754 - val_acc: 0.7266\n",
      "Epoch 6321/10000\n",
      "4259/4259 [==============================] - 2s 508us/step - loss: 0.3068 - acc: 0.9836 - val_loss: 0.6756 - val_acc: 0.7270\n",
      "Epoch 6322/10000\n",
      "4259/4259 [==============================] - 2s 513us/step - loss: 0.3098 - acc: 0.9722 - val_loss: 0.6698 - val_acc: 0.7273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6323/10000\n",
      "4259/4259 [==============================] - 2s 499us/step - loss: 0.3100 - acc: 0.9726 - val_loss: 0.6769 - val_acc: 0.7281\n",
      "Epoch 6324/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3083 - acc: 0.9746 - val_loss: 0.6696 - val_acc: 0.7303\n",
      "Epoch 6325/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3081 - acc: 0.9779 - val_loss: 0.6765 - val_acc: 0.7328\n",
      "Epoch 6326/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3069 - acc: 0.9775 - val_loss: 0.6722 - val_acc: 0.7314\n",
      "Epoch 6327/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3064 - acc: 0.9791 - val_loss: 0.6743 - val_acc: 0.7317\n",
      "Epoch 6328/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3063 - acc: 0.9792 - val_loss: 0.6700 - val_acc: 0.7303\n",
      "Epoch 6329/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3061 - acc: 0.9807 - val_loss: 0.6707 - val_acc: 0.7306\n",
      "Epoch 6330/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9819 - val_loss: 0.6702 - val_acc: 0.7310\n",
      "Epoch 6331/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6708 - val_acc: 0.7321\n",
      "Epoch 6332/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6698 - val_acc: 0.7325\n",
      "Epoch 6333/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6701 - val_acc: 0.7306\n",
      "Epoch 6334/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9839 - val_loss: 0.6699 - val_acc: 0.7321\n",
      "Epoch 6335/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9841 - val_loss: 0.6705 - val_acc: 0.7328\n",
      "Epoch 6336/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9842 - val_loss: 0.6700 - val_acc: 0.7321\n",
      "Epoch 6337/10000\n",
      "4259/4259 [==============================] - 2s 484us/step - loss: 0.3059 - acc: 0.9848 - val_loss: 0.6703 - val_acc: 0.7325\n",
      "Epoch 6338/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3059 - acc: 0.9847 - val_loss: 0.6707 - val_acc: 0.7325\n",
      "Epoch 6339/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6704 - val_acc: 0.7310\n",
      "Epoch 6340/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9853 - val_loss: 0.6706 - val_acc: 0.7325\n",
      "Epoch 6341/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6708 - val_acc: 0.7317\n",
      "Epoch 6342/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9855 - val_loss: 0.6708 - val_acc: 0.7299\n",
      "Epoch 6343/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6709 - val_acc: 0.7328\n",
      "Epoch 6344/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6704 - val_acc: 0.7321\n",
      "Epoch 6345/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9858 - val_loss: 0.6710 - val_acc: 0.7317\n",
      "Epoch 6346/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9848 - val_loss: 0.6707 - val_acc: 0.7321\n",
      "Epoch 6347/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9851 - val_loss: 0.6704 - val_acc: 0.7306\n",
      "Epoch 6348/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6711 - val_acc: 0.7317\n",
      "Epoch 6349/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3058 - acc: 0.9855 - val_loss: 0.6709 - val_acc: 0.7284\n",
      "Epoch 6350/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6710 - val_acc: 0.7321\n",
      "Epoch 6351/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6709 - val_acc: 0.7314\n",
      "Epoch 6352/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6711 - val_acc: 0.7310\n",
      "Epoch 6353/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9844 - val_loss: 0.6718 - val_acc: 0.7317\n",
      "Epoch 6354/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9845 - val_loss: 0.6719 - val_acc: 0.7306\n",
      "Epoch 6355/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9834 - val_loss: 0.6715 - val_acc: 0.7299\n",
      "Epoch 6356/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9814 - val_loss: 0.6707 - val_acc: 0.7321\n",
      "Epoch 6357/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3063 - acc: 0.9807 - val_loss: 0.6724 - val_acc: 0.7314\n",
      "Epoch 6358/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3062 - acc: 0.9811 - val_loss: 0.6735 - val_acc: 0.7328\n",
      "Epoch 6359/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6712 - val_acc: 0.7314\n",
      "Epoch 6360/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6723 - val_acc: 0.7292\n",
      "Epoch 6361/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9843 - val_loss: 0.6714 - val_acc: 0.7325\n",
      "Epoch 6362/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9844 - val_loss: 0.6717 - val_acc: 0.7325\n",
      "Epoch 6363/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9849 - val_loss: 0.6703 - val_acc: 0.7336\n",
      "Epoch 6364/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3058 - acc: 0.9854 - val_loss: 0.6705 - val_acc: 0.7343\n",
      "Epoch 6365/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9841 - val_loss: 0.6702 - val_acc: 0.7310\n",
      "Epoch 6366/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9850 - val_loss: 0.6703 - val_acc: 0.7310\n",
      "Epoch 6367/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3059 - acc: 0.9840 - val_loss: 0.6698 - val_acc: 0.7281\n",
      "Epoch 6368/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6726 - val_acc: 0.7277\n",
      "Epoch 6369/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9815 - val_loss: 0.6714 - val_acc: 0.7310\n",
      "Epoch 6370/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9818 - val_loss: 0.6739 - val_acc: 0.7332\n",
      "Epoch 6371/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9830 - val_loss: 0.6708 - val_acc: 0.7299\n",
      "Epoch 6372/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9818 - val_loss: 0.6716 - val_acc: 0.7277\n",
      "Epoch 6373/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9829 - val_loss: 0.6694 - val_acc: 0.7277\n",
      "Epoch 6374/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9835 - val_loss: 0.6696 - val_acc: 0.7310\n",
      "Epoch 6375/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3059 - acc: 0.9822 - val_loss: 0.6705 - val_acc: 0.7299\n",
      "Epoch 6376/10000\n",
      "4259/4259 [==============================] - 2s 503us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6678 - val_acc: 0.7314\n",
      "Epoch 6377/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3059 - acc: 0.9832 - val_loss: 0.6695 - val_acc: 0.7295\n",
      "Epoch 6378/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3059 - acc: 0.9833 - val_loss: 0.6696 - val_acc: 0.7328\n",
      "Epoch 6379/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3060 - acc: 0.9816 - val_loss: 0.6697 - val_acc: 0.7284\n",
      "Epoch 6380/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3060 - acc: 0.9824 - val_loss: 0.6704 - val_acc: 0.7325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6381/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9822 - val_loss: 0.6669 - val_acc: 0.7306\n",
      "Epoch 6382/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6669 - val_acc: 0.7328\n",
      "Epoch 6383/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3060 - acc: 0.9826 - val_loss: 0.6682 - val_acc: 0.7314\n",
      "Epoch 6384/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3060 - acc: 0.9817 - val_loss: 0.6666 - val_acc: 0.7317\n",
      "Epoch 6385/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3060 - acc: 0.9829 - val_loss: 0.6673 - val_acc: 0.7325\n",
      "Epoch 6386/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9823 - val_loss: 0.6687 - val_acc: 0.7328\n",
      "Epoch 6387/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3059 - acc: 0.9836 - val_loss: 0.6665 - val_acc: 0.7343\n",
      "Epoch 6388/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9827 - val_loss: 0.6666 - val_acc: 0.7343\n",
      "Epoch 6389/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9830 - val_loss: 0.6682 - val_acc: 0.7317\n",
      "Epoch 6390/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3060 - acc: 0.9821 - val_loss: 0.6688 - val_acc: 0.7339\n",
      "Epoch 6391/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3067 - acc: 0.9797 - val_loss: 0.6676 - val_acc: 0.7310\n",
      "Epoch 6392/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3062 - acc: 0.9783 - val_loss: 0.6649 - val_acc: 0.7273\n",
      "Epoch 6393/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3060 - acc: 0.9825 - val_loss: 0.6664 - val_acc: 0.7325\n",
      "Epoch 6394/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9833 - val_loss: 0.6653 - val_acc: 0.7314\n",
      "Epoch 6395/10000\n",
      "4259/4259 [==============================] - 2s 485us/step - loss: 0.3058 - acc: 0.9842 - val_loss: 0.6670 - val_acc: 0.7321\n",
      "Epoch 6396/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3058 - acc: 0.9844 - val_loss: 0.6656 - val_acc: 0.7310\n",
      "Epoch 6397/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9841 - val_loss: 0.6666 - val_acc: 0.7314\n",
      "Epoch 6398/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9847 - val_loss: 0.6671 - val_acc: 0.7332\n",
      "Epoch 6399/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3058 - acc: 0.9840 - val_loss: 0.6674 - val_acc: 0.7336\n",
      "Epoch 6400/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3058 - acc: 0.9852 - val_loss: 0.6660 - val_acc: 0.7325\n",
      "Epoch 6401/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3058 - acc: 0.9834 - val_loss: 0.6682 - val_acc: 0.7336\n",
      "Epoch 6402/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3058 - acc: 0.9833 - val_loss: 0.6667 - val_acc: 0.7325\n",
      "Epoch 6403/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3060 - acc: 0.9811 - val_loss: 0.6697 - val_acc: 0.7306\n",
      "Epoch 6404/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3063 - acc: 0.9797 - val_loss: 0.6660 - val_acc: 0.7314\n",
      "Epoch 6405/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3062 - acc: 0.9801 - val_loss: 0.6645 - val_acc: 0.7336\n",
      "Epoch 6406/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3098 - acc: 0.9759 - val_loss: 0.6774 - val_acc: 0.7215\n",
      "Epoch 6407/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3129 - acc: 0.9696 - val_loss: 0.6707 - val_acc: 0.7277\n",
      "Epoch 6408/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3098 - acc: 0.9728 - val_loss: 0.6762 - val_acc: 0.7255\n",
      "Epoch 6409/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3081 - acc: 0.9773 - val_loss: 0.6706 - val_acc: 0.7292\n",
      "Epoch 6410/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3073 - acc: 0.9787 - val_loss: 0.6746 - val_acc: 0.7303\n",
      "Epoch 6411/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3069 - acc: 0.9804 - val_loss: 0.6738 - val_acc: 0.7317\n",
      "Epoch 6412/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3067 - acc: 0.9815 - val_loss: 0.6740 - val_acc: 0.7310\n",
      "Epoch 6413/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3066 - acc: 0.9811 - val_loss: 0.6733 - val_acc: 0.7306\n",
      "Epoch 6414/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3065 - acc: 0.9823 - val_loss: 0.6736 - val_acc: 0.7306\n",
      "Epoch 6415/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3065 - acc: 0.9823 - val_loss: 0.6730 - val_acc: 0.7306\n",
      "Epoch 6416/10000\n",
      "4259/4259 [==============================] - 2s 498us/step - loss: 0.3064 - acc: 0.9826 - val_loss: 0.6726 - val_acc: 0.7303\n",
      "Epoch 6417/10000\n",
      "4259/4259 [==============================] - 2s 493us/step - loss: 0.3064 - acc: 0.9825 - val_loss: 0.6729 - val_acc: 0.7325\n",
      "Epoch 6418/10000\n",
      "4259/4259 [==============================] - 2s 494us/step - loss: 0.3064 - acc: 0.9833 - val_loss: 0.6730 - val_acc: 0.7306\n",
      "Epoch 6419/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3063 - acc: 0.9840 - val_loss: 0.6725 - val_acc: 0.7325\n",
      "Epoch 6420/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3064 - acc: 0.9828 - val_loss: 0.6768 - val_acc: 0.7273\n",
      "Epoch 6421/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3065 - acc: 0.9825 - val_loss: 0.6763 - val_acc: 0.7314\n",
      "Epoch 6422/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3063 - acc: 0.9825 - val_loss: 0.6790 - val_acc: 0.7314\n",
      "Epoch 6423/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3062 - acc: 0.9836 - val_loss: 0.6788 - val_acc: 0.7310\n",
      "Epoch 6424/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3062 - acc: 0.9844 - val_loss: 0.6787 - val_acc: 0.7314\n",
      "Epoch 6425/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3062 - acc: 0.9843 - val_loss: 0.6782 - val_acc: 0.7317\n",
      "Epoch 6426/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3062 - acc: 0.9847 - val_loss: 0.6785 - val_acc: 0.7317\n",
      "Epoch 6427/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9851 - val_loss: 0.6779 - val_acc: 0.7314\n",
      "Epoch 6428/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3061 - acc: 0.9854 - val_loss: 0.6773 - val_acc: 0.7314\n",
      "Epoch 6429/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9856 - val_loss: 0.6777 - val_acc: 0.7314\n",
      "Epoch 6430/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3061 - acc: 0.9855 - val_loss: 0.6775 - val_acc: 0.7317\n",
      "Epoch 6431/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3061 - acc: 0.9858 - val_loss: 0.6777 - val_acc: 0.7321\n",
      "Epoch 6432/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3061 - acc: 0.9856 - val_loss: 0.6767 - val_acc: 0.7321\n",
      "Epoch 6433/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3061 - acc: 0.9864 - val_loss: 0.6768 - val_acc: 0.7325\n",
      "Epoch 6434/10000\n",
      "4259/4259 [==============================] - 2s 490us/step - loss: 0.3061 - acc: 0.9865 - val_loss: 0.6778 - val_acc: 0.7343\n",
      "Epoch 6435/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9857 - val_loss: 0.6762 - val_acc: 0.7314\n",
      "Epoch 6436/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9858 - val_loss: 0.6760 - val_acc: 0.7325\n",
      "Epoch 6437/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3061 - acc: 0.9858 - val_loss: 0.6764 - val_acc: 0.7310\n",
      "Epoch 6438/10000\n",
      "4259/4259 [==============================] - 2s 496us/step - loss: 0.3061 - acc: 0.9861 - val_loss: 0.6768 - val_acc: 0.7332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6439/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3061 - acc: 0.9870 - val_loss: 0.6766 - val_acc: 0.7332\n",
      "Epoch 6440/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3061 - acc: 0.9854 - val_loss: 0.6761 - val_acc: 0.7339\n",
      "Epoch 6441/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3061 - acc: 0.9865 - val_loss: 0.6772 - val_acc: 0.7346\n",
      "Epoch 6442/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3061 - acc: 0.9859 - val_loss: 0.6762 - val_acc: 0.7350\n",
      "Epoch 6443/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3061 - acc: 0.9851 - val_loss: 0.6764 - val_acc: 0.7343\n",
      "Epoch 6444/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3061 - acc: 0.9851 - val_loss: 0.6755 - val_acc: 0.7332\n",
      "Epoch 6445/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3062 - acc: 0.9841 - val_loss: 0.6762 - val_acc: 0.7328\n",
      "Epoch 6446/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3062 - acc: 0.9843 - val_loss: 0.6753 - val_acc: 0.7339\n",
      "Epoch 6447/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3062 - acc: 0.9840 - val_loss: 0.6756 - val_acc: 0.7332\n",
      "Epoch 6448/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3062 - acc: 0.9844 - val_loss: 0.6744 - val_acc: 0.7328\n",
      "Epoch 6449/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3062 - acc: 0.9831 - val_loss: 0.6771 - val_acc: 0.7368\n",
      "Epoch 6450/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3062 - acc: 0.9840 - val_loss: 0.6745 - val_acc: 0.7336\n",
      "Epoch 6451/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3062 - acc: 0.9840 - val_loss: 0.6744 - val_acc: 0.7346\n",
      "Epoch 6452/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3062 - acc: 0.9827 - val_loss: 0.6692 - val_acc: 0.7354\n",
      "Epoch 6453/10000\n",
      "4259/4259 [==============================] - 2s 489us/step - loss: 0.3063 - acc: 0.9830 - val_loss: 0.6735 - val_acc: 0.7321\n",
      "Epoch 6454/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3100 - acc: 0.9754 - val_loss: 0.6756 - val_acc: 0.7193\n",
      "Epoch 6455/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3141 - acc: 0.9617 - val_loss: 0.6785 - val_acc: 0.7240\n",
      "Epoch 6456/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3098 - acc: 0.9709 - val_loss: 0.6729 - val_acc: 0.7336\n",
      "Epoch 6457/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3080 - acc: 0.9750 - val_loss: 0.6714 - val_acc: 0.7299\n",
      "Epoch 6458/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3075 - acc: 0.9778 - val_loss: 0.6710 - val_acc: 0.7332\n",
      "Epoch 6459/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3073 - acc: 0.9799 - val_loss: 0.6695 - val_acc: 0.7314\n",
      "Epoch 6460/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3075 - acc: 0.9786 - val_loss: 0.6733 - val_acc: 0.7306\n",
      "Epoch 6461/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3071 - acc: 0.9811 - val_loss: 0.6720 - val_acc: 0.7317\n",
      "Epoch 6462/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3070 - acc: 0.9815 - val_loss: 0.6712 - val_acc: 0.7325\n",
      "Epoch 6463/10000\n",
      "4259/4259 [==============================] - 2s 486us/step - loss: 0.3069 - acc: 0.9817 - val_loss: 0.6707 - val_acc: 0.7336\n",
      "Epoch 6464/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3069 - acc: 0.9823 - val_loss: 0.6700 - val_acc: 0.7343\n",
      "Epoch 6465/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3068 - acc: 0.9827 - val_loss: 0.6699 - val_acc: 0.7328\n",
      "Epoch 6466/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3068 - acc: 0.9828 - val_loss: 0.6696 - val_acc: 0.7336\n",
      "Epoch 6467/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3068 - acc: 0.9836 - val_loss: 0.6690 - val_acc: 0.7328\n",
      "Epoch 6468/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3067 - acc: 0.9838 - val_loss: 0.6683 - val_acc: 0.7339\n",
      "Epoch 6469/10000\n",
      "4259/4259 [==============================] - 2s 488us/step - loss: 0.3067 - acc: 0.9843 - val_loss: 0.6692 - val_acc: 0.7365\n",
      "Epoch 6470/10000\n",
      "4259/4259 [==============================] - 2s 487us/step - loss: 0.3067 - acc: 0.9849 - val_loss: 0.6686 - val_acc: 0.7336\n",
      "Epoch 6471/10000\n",
      "4259/4259 [==============================] - 2s 521us/step - loss: 0.3067 - acc: 0.9841 - val_loss: 0.6685 - val_acc: 0.7339\n",
      "Epoch 6472/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3067 - acc: 0.9844 - val_loss: 0.6687 - val_acc: 0.7339\n",
      "Epoch 6473/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3066 - acc: 0.9851 - val_loss: 0.6686 - val_acc: 0.7346\n",
      "Epoch 6474/10000\n",
      "4259/4259 [==============================] - 2s 541us/step - loss: 0.3066 - acc: 0.9858 - val_loss: 0.6685 - val_acc: 0.7328\n",
      "Epoch 6475/10000\n",
      "4259/4259 [==============================] - 2s 495us/step - loss: 0.3066 - acc: 0.9852 - val_loss: 0.6682 - val_acc: 0.7365\n",
      "Epoch 6476/10000\n",
      "4259/4259 [==============================] - 2s 497us/step - loss: 0.3068 - acc: 0.9843 - val_loss: 0.6662 - val_acc: 0.7372\n",
      "Epoch 6477/10000\n",
      "4259/4259 [==============================] - 2s 491us/step - loss: 0.3067 - acc: 0.9849 - val_loss: 0.6674 - val_acc: 0.7390\n",
      "Epoch 6478/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3066 - acc: 0.9843 - val_loss: 0.6670 - val_acc: 0.7354\n",
      "Epoch 6479/10000\n",
      "4259/4259 [==============================] - 2s 492us/step - loss: 0.3066 - acc: 0.9838 - val_loss: 0.6659 - val_acc: 0.7350\n",
      "Epoch 6480/10000\n",
      "4259/4259 [==============================] - 2s 502us/step - loss: 0.3066 - acc: 0.9851 - val_loss: 0.6661 - val_acc: 0.7361\n",
      "Epoch 6481/10000\n",
      "4259/4259 [==============================] - 2s 502us/step - loss: 0.3066 - acc: 0.9854 - val_loss: 0.6653 - val_acc: 0.7361\n",
      "Epoch 6482/10000\n",
      "4259/4259 [==============================] - 2s 502us/step - loss: 0.3066 - acc: 0.9853 - val_loss: 0.6660 - val_acc: 0.7372\n",
      "Epoch 6483/10000\n",
      "4259/4259 [==============================] - 2s 503us/step - loss: 0.3066 - acc: 0.9853 - val_loss: 0.6657 - val_acc: 0.7368\n",
      "Epoch 6484/10000\n",
      "2848/4259 [===================>..........] - ETA: 0s - loss: 0.2920 - acc: 0.9860"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-4ccfd73c384c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m history = model.fit(x=[x_train,decoder_in], y=y_train,\n\u001b[0;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m           shuffle=True, epochs = 10000)\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Jon\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\Jon\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Jon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Jon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Jon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "decoder_in = np.zeros((x_train.shape[0],1,n_a))\n",
    "decoder_val = np.zeros((x_val.shape[0],1,n_a))\n",
    "history = model.fit(x=[x_train,decoder_in], y=y_train,\n",
    "          validation_data = ([x_val, decoder_val], y_val),\n",
    "          shuffle=True, epochs = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"639.85\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14d413f1e48>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.epoch, history.history[\"loss\"], label='Train Loss')\n",
    "plt.plot(history.epoch, history.history[\"val_loss\"], label='Vali Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 1s 125us/step\n",
      "912/912 [==============================] - 0s 121us/step\n",
      "Test Error: [0.30656574020216015, 0.985755654393465]\n",
      "Val  Error: [0.6663678121148494, 0.7361111065797639]\n"
     ]
    }
   ],
   "source": [
    "decoder_in = np.zeros((x_train.shape[0],1,n_a))\n",
    "evalu_test = model.evaluate(x=[x_train,decoder_in], y=y_train)\n",
    "decoder_in = np.zeros((x_val.shape[0],1,n_a))\n",
    "evalu_val = model.evaluate(x=[x_val,decoder_in], y=y_val)\n",
    "print('Test Error: '+ str(evalu_test))\n",
    "print('Val  Error: '+ str(evalu_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[[-0.00504428  0.1397    ]\n",
      "  [-0.00135183  0.1428    ]\n",
      "  [-0.0023672   0.1544    ]\n",
      "  [-0.01492538  0.1666    ]\n",
      "  [ 0.00034374  0.1592    ]\n",
      "  [-0.00309752  0.1624    ]\n",
      "  [ 0.00448838  0.1492    ]\n",
      "  [ 0.01065716  0.1472    ]\n",
      "  [ 0.01496599  0.1355    ]\n",
      "  [ 0.00134047  0.1451    ]]]\n",
      "Y:\n",
      "[[[ 0.00334568  0.149     ]\n",
      "  [ 0.00433565  0.1332    ]\n",
      "  [-0.00199164  0.1476    ]]]\n",
      "LSTM Out:\n",
      "[[[ 0.2528681  -0.5908135 ]\n",
      "  [ 0.3418734  -0.78524613]\n",
      "  [-0.21405752 -0.6141538 ]]]\n",
      "Y pred:\n",
      "[[[ 0.00338144  0.14900089]\n",
      "  [ 0.00442499  0.13316257]\n",
      "  [-0.00209304  0.14709961]]]\n"
     ]
    }
   ],
   "source": [
    "data_set = (x_train, y_train)\n",
    "indexes = np.random.randint(0,data_set[0].shape[0], size=1)\n",
    "x_in = data_set[0][indexes,:,:]\n",
    "decoder_in = np.zeros((x_in.shape[0],1,n_a))\n",
    "y_true = data_set[1][indexes,:,:]\n",
    "y_pred = model.predict(x=[x_in,decoder_in])\n",
    "y_pred_denorm = denormalize_data(y_pred, x_norm_param)\n",
    "print('X:')\n",
    "print(denormalize_data(x_in,x_norm_param))\n",
    "print('Y:')\n",
    "print(denormalize_data(y_true,x_norm_param))\n",
    "print('LSTM Out:')\n",
    "print(y_pred)\n",
    "print('Y pred:')\n",
    "print(y_pred_denorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"639.85\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"639.85\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14d45213fd0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_in_returns = denormalize_data(x_in,x_norm_param)[:,:,0].transpose()\n",
    "x_in_vol = denormalize_data(x_in,x_norm_param)[:,:,1].transpose()\n",
    "y_true_returns = denormalize_data(y_true,x_norm_param)[:,:,0].transpose()\n",
    "y_true_vol = denormalize_data(y_true,x_norm_param)[:,:,1].transpose()\n",
    "y_pred_returns = denormalize_data(y_pred,x_norm_param)[:,:,0].transpose()\n",
    "y_pred_vol = denormalize_data(y_pred,x_norm_param)[:,:,1].transpose()\n",
    "plt.figure()\n",
    "plt.plot(range(0,T_x), x_in_returns, label='Input')\n",
    "plt.plot(range(T_x, T_x+T_y), y_true_returns, label='Truth')\n",
    "plt.plot(range(T_x, T_x+T_y), y_pred_returns, label='LSTM')\n",
    "plt.title('Returns')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(0,T_x), x_in_vol, label='Input')\n",
    "plt.plot(range(T_x, T_x+T_y), y_true_vol, label='Truth')\n",
    "plt.plot(range(T_x, T_x+T_y), y_pred_vol, label='LSTM')\n",
    "plt.title('Vol')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNIPPETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norm - Denorm Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a, b , m = gen_dataset(T_x,T_y,T_stride,retvol_table)\n",
    "x, x_norm_param = normalize_data(a)\n",
    "y, _ = normalize_data(b, x_norm_param)\n",
    "x = denormalize_data(x, x_norm_param)\n",
    "y = denormalize_data(y, x_norm_param)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist((b-y).flatten(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PlotHistory(keras.callbacks.History):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        super().on_train_begin(logs)\n",
    "        self.fig = plt.figure()\n",
    "        self.axes = plt.subplot(111)\n",
    "        self.trainloss_line, = self.axes.plot([],[], label='Train Loss')\n",
    "        self.fig.subplots_adjust(bottom=0.25, top=0.9, left=0.1,right=0.85, wspace=0, hspace=0) \n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        self.trainloss_line.set_data(self.epoch, self.history[\"loss\"])\n",
    "        self.axes.relim()\n",
    "        self.fig.canvas.draw()\n",
    "# Update of plot does not properly work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
